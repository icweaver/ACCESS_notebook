{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import juliet\n",
    "import seaborn as sns\n",
    "import mplcyberpunk\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import corner\n",
    "import pathlib\n",
    "import itertools\n",
    "import batman\n",
    "import json\n",
    "import re\n",
    "\n",
    "from astropy.io import fits, ascii\n",
    "from astropy import constants as c\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "from matplotlib.collections import LineCollection\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from PyAstronomy.pyTiming import pyPeriod\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# Display and backend\n",
    "#####################\n",
    "FIG_LARGE = (11, 8) # Default plot figure size for large figures\n",
    "FIG_WIDE = (11, 5)    \n",
    "%config InlineBackend.figure_format = \"retina\" # Crisp retina display on macs\n",
    "# Qt5 backend for interactive plotting\n",
    "%matplotlib qt5 \n",
    "\n",
    "################\n",
    "# Theme settings\n",
    "################\n",
    "def set_theme(notebook_mode=\"dark\"):\n",
    "    plt.style.use(\"default\") # Reset to default before layering on any changes\n",
    "    sns.set(palette=\"Paired\", color_codes=True, context=\"talk\")\n",
    "\n",
    "    if notebook_mode.lower() == \"paper\":\n",
    "        sns.set_style('ticks')\n",
    "        params = {\n",
    "            # xticks\n",
    "            \"xtick.top\":False,\n",
    "            \"xtick.direction\":\"out\",\n",
    "            \"xtick.major.size\":5,\n",
    "            \"xtick.minor.visible\":False,\n",
    "\n",
    "            # yticks\n",
    "            \"ytick.right\":False,\n",
    "            \"ytick.direction\":\"out\",\n",
    "            \"ytick.major.size\":5,\n",
    "            \"ytick.minor.visible\":False,\n",
    "\n",
    "            # pallete\n",
    "            \"axes.prop_cycle\":mpl.cycler(color=[\n",
    "                \"#fdbf6f\", # Yellow\n",
    "                \"#ff7f00\", # Orange\n",
    "                \"#a6cee3\", # Cyan\n",
    "                \"#1f78b4\", # Blue\n",
    "                \"#956cb4\", # Purple\n",
    "                \"#029e73\", # Green\n",
    "                \"#c44e52\", # Red\n",
    "            ]),\n",
    "        }\n",
    "        #sns.set_style(\"ticks\", tick_params)\n",
    "        #params = {\n",
    "        #    \"axes.formatter.limits\":(-3, 7),\n",
    "        #    #\"axes.spine.right\":False,\n",
    "        #    \"xtick.major.size\":2,\n",
    "        #}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "    elif notebook_mode.lower() == \"dark\":\n",
    "        sns.set(palette=\"colorblind\", color_codes=True, context=\"talk\")\n",
    "        plt.style.use(\"cyberpunk\")\n",
    "        # Re-order color cycle\n",
    "        params = {\n",
    "            \"axes.prop_cycle\":mpl.cycler(color=[\n",
    "                \"#F5D300\", # Yellow\n",
    "                'r',       # Red\n",
    "                \"#08F7FE\", # Cyan\n",
    "                \"b\", # Blue\n",
    "                \"g\", # Green\n",
    "            ]),\n",
    "        }\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "    else:\n",
    "        plt.style.use(\"default\")\n",
    "    \n",
    "HOURS = mdates.HourLocator() # For UTC plots with ticks every hour\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "set_theme(\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.palettes.color_palette('muted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palettes.color_palette('muted').as_hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Teq(Ts=None, albedo=None, aRs=None, Rs=None, a=None):\n",
    "    if (aRs is None):\n",
    "        return Ts * (1 - albedo)**0.25 * (0.5*Rs/a)**0.5\n",
    "    else:\n",
    "        return Ts * (1 - albedo)**0.25 * (0.5/aRs)**0.5\n",
    "\n",
    "def get_H(\n",
    "    Tp=None,\n",
    "    Mp=None,\n",
    "    Rp=None,\n",
    "    Ts=None,\n",
    "    Rs=None,\n",
    "    mu=None,\n",
    "    albedo=None,\n",
    "    aRs=None,\n",
    "    a=None,\n",
    "    RpRs=None,\n",
    "):\n",
    "    if isinstance(Mp, u.Quantity):\n",
    "        G_Mp = c.G * Mp\n",
    "    else:\n",
    "        # Default to Jupiter mass\n",
    "        G_Mp = c.GM_jup * Mp\n",
    "    if (RpRs is None) and (Rp is not None):\n",
    "        g = G_Mp / Rp**2\n",
    "    else:\n",
    "        g = G_Mp / (RpRs**2 * Rs**2)\n",
    "    if Tp is None:\n",
    "        Tp = get_Teq(Ts=Ts, albedo=0, aRs=aRs, Rs=Rs, a=a)\n",
    "    return c.k_B * Tp / (mu * g), Tp\n",
    "\n",
    "def get_depth(Tp=None,\n",
    "              Mp=None,\n",
    "              Rp=None,\n",
    "              Ts=None,\n",
    "              Rs=None,\n",
    "              mu=None,\n",
    "              H=None,\n",
    "              aRs=None,\n",
    "              a=None,\n",
    "              RpRs=None,\n",
    "):\n",
    "    if H is None:\n",
    "        H, Tp = get_H(Tp=Tp, Mp=Mp, Rp=Rp, Ts=Ts, Rs=Rs, mu=mu, aRs=aRs, a=a, RpRs=RpRs)\n",
    "    if RpRs is None:\n",
    "        Delta_D =  2 * H * Rp / Rs**2, H, Tp\n",
    "    else:\n",
    "        Delta_D =  2 * H * RpRs/Rs, H, Tp\n",
    "    return Delta_D\n",
    "\n",
    "D, H, Tp = get_depth(\n",
    "    #Rp=1.036*u.R_jup,\n",
    "    mu=2*u.Da,\n",
    "    Mp=1.97*u.M_jup,\n",
    "    Ts=5734*u.K,\n",
    "    Rs=1.1858169*u.R_sun,\n",
    "    RpRs = 0.1113,\n",
    "    aRs=4.26,\n",
    "    #a=0.01528*u.AU,\n",
    "    #Tp=1440*u.K,\n",
    ")\n",
    "\n",
    "print(f'Tp = {Tp.cgs:.3f}')\n",
    "print(f'H = {H.to(\"km\"):.3f},')\n",
    "n = 5\n",
    "print(f'Delta D = {n * D.cgs * 1e6:.3f} ppm at {n} scale heights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = glob.glob(\"./data/HATP23/ut160720/ift*c1.fits\")\n",
    "#fpaths = glob(\"./data/HATP23/ut160621/ift*c1.fits\")\n",
    "\n",
    "object_names = []\n",
    "for fpath in fpaths:\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        header = fits.open(f, de)[0].header\n",
    "        name = header[\"OBJECT\"]\n",
    "        object_names.append(name)\n",
    "        \n",
    "len(object_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config:\n",
    "images_dir = '../atmospheres_meeting/figs'\n",
    "result_grid_filename = '/Users/mango/Desktop/grid.png'\n",
    "result_figsize_resolution = 40 # 1 = 100px\n",
    "\n",
    "images_list = glob.glob(f\"{images_dir}/*raw_lc.png\")\n",
    "\n",
    "# Create plt plot:\n",
    "fig, axes = plt.subplots(5, 2, figsize=(8, 40))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img in zip(axes, images_list):\n",
    "    plt_image = plt.imread(img)\n",
    "    plt_image = np.array(Image.open(img))\n",
    "    ax.imshow(plt_image, aspect=\"auto\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=.0, hspace=.0)\n",
    "#plt.savefig(\"/Users/mango/Desktop/grid.png\", dpi=250, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-334f329e1abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/HATP26/ut190313'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_dir}/ift*c1.fits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gen/lib/python3.8/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gen/lib/python3.8/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gen/lib/python3.8/glob.py\u001b[0m in \u001b[0;36m_glob1\u001b[0;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_glob1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gen/lib/python3.8/glob.py\u001b[0m in \u001b[0;36m_iterdir\u001b[0;34m(dirname, dironly)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdironly\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = './data/HATP26/ut190313'\n",
    "data = data_dir.split('/')[-1]\n",
    "fpaths = np.array(sorted(glob.glob(f'{data_dir}/ift*c1.fits')))\n",
    "filenames = []\n",
    "objects = []\n",
    "slits = []\n",
    "airmasses = []\n",
    "file_info = {}\n",
    "for fpath in tqdm(fpaths):\n",
    "    header = utils.fits_header(fpath)\n",
    "    #header = fits.getheader(fpath)\n",
    "    #print(header['OBJECT'])\n",
    "    if header is not None:\n",
    "        file_info[header['FILENAME'].split('c')[0]] = {\n",
    "            'UT Date':         header['UT-DATE'],\n",
    "            'UT Time (start)': header['UT-TIME'],\n",
    "            'UT Time (end)':   header['UT-END'],\n",
    "            'Exposure (s)':    header['EXPTIME'],\n",
    "            'Object':          header['OBJECT'],\n",
    "            'Exposure type':   header['EXPTYPE'],\n",
    "            'RA':              header['RA'],\n",
    "            'Dec':             header['DEC'],\n",
    "            'Mask':            header['SLITMASK'],\n",
    "            'Filter':          header['FILTER'],\n",
    "            'Disperser':       header['DISPERSR'],\n",
    "            'Airmass':         header['AIRMASS'],\n",
    "            'Seeing':          header['G-SEEING'],\n",
    "            'Binning':         header['Binning'],\n",
    "            'Speed':           header['Speed'],\n",
    "            'Subrastr':           header['SUBRASTR'],\n",
    "            #'File':            header['FILENAME'],\n",
    "        }\n",
    "    \n",
    "df_file_info = pd.DataFrame.from_dict(file_info, orient='index')\n",
    "df_file_info.index.name = 'root'\n",
    "#sci_mask = df_file_info['Object'].str.contains('science')\n",
    "#df_file_info[sci_mask]#.info()\n",
    "#date = data_dir.split('/')[-1]\n",
    "df_file_info.to_csv(f'/home/mango/Projects/HATP26b/night_log_{date}.csv', index=False)\n",
    "#df_file_info.to_csv(f'./projects/HATP26b/night_log_{date}.txt', index=False)\n",
    "#df_file_info.query('Object.str.contains(\"sci\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f'projects/HATP26b/journal/night_log_{date}.csv'\n",
    "pd.read_csv(fpath)\n",
    "df_sci = df_file_info.query('Object.str.contains(\"sci\")')\n",
    "df_cal = df_file_info.query('Object.str.contains(\"He\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sci.nunique() #[cols].unique()\n",
    "df_cal#.nunique() #[cols].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sci.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM = df_sci['Airmass'].to_numpy()\n",
    "idxs = range(len(AM))\n",
    "idx_min = np.argmin(AM)\n",
    "\n",
    "def plot_ann(ax, x, y):\n",
    "    ax.plot(x, y, 'ro')\n",
    "    ax.annotate(f'{y:.3f}', xy=(x, y+0.02))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(idxs, AM)\n",
    "plot_ann(ax, idxs[0], AM[0])\n",
    "plot_ann(ax, idxs[idx_min], np.min(AM))\n",
    "plot_ann(ax, idxs[-1], AM[-1])\n",
    "\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel('Airmass')\n",
    "ax.set_title('HAT-P-26 science frames')\n",
    "\n",
    "utils.savefig('projects/HATP26b/journal/figures/data_inspection/airmass.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/HATP23'\n",
    "data_dict = {\n",
    "    'transit_1':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut160621',\n",
    "            'ift':'1116',\n",
    "            'sky_ap':20,\n",
    "        },\n",
    "#\n",
    "    'transit_2':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut170609',\n",
    "            'ift':'0183',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "    'transit_3':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut180603',\n",
    "            'ift':'0076',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "    'transit_4':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut180620',\n",
    "            'ift':'4444',\n",
    "            #'ift':'4050',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "    'transit_5':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut180821',\n",
    "            'ift':'0200',\n",
    "            #'ift':'0000',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/HATP26'\n",
    "data_dict = {\n",
    "    'transit_1':\n",
    "    {\n",
    "        'path':f'{data_dir}/ut190313',\n",
    "        'ift':'1310',\n",
    "        'sky_ap':25,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mango/miniconda3/envs/gen/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\", line 224, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/home/mango/miniconda3/envs/gen/lib/python3.8/site-packages/mpl_toolkits/axes_grid1/colorbar.py\", line 715, in update_normal\n",
      "    self.draw_all()\n",
      "AttributeError: 'Colorbar' object has no attribute 'draw_all'\n"
     ]
    }
   ],
   "source": [
    "for transit, transit_info in data_dict.items():\n",
    "    dirpath = transit_info['path']\n",
    "    fname = f\"ift{transit_info['ift']}\"\n",
    "    sky_ap = transit_info['sky_ap']\n",
    "    fig, im = utils.plot_chips(\n",
    "        dirpath, fname, vmin=0, vmax=2_000, sky_ap=25, spec_ap=12,\n",
    "    )\n",
    "    #fig.set_size_inches(8, 11)\n",
    "    #fig.colorbar(im, ax=axes.flatten(), aspect=30, label='counts')\n",
    "    #fig.subplots_adjust(wspace=0.1, hspace=0.01)\n",
    "    #plt.savefig(\"/Users/mango/Desktop/test.png\", bbox_inches=\"tight\")\n",
    "    plt.savefig(\n",
    "       f'projects/HATP26b/journal/figures/{transit}_raw_frame.png',\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=250\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(8, 11))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    im = ax.imshow(np.random.rand(2048, 1024))\n",
    "    if i <= 3:\n",
    "        ax.set_title('title')\n",
    "    else:\n",
    "        ax.set_xlabel('title')\n",
    "    \n",
    "#cbar_ax = fig.add_axes([0.91, 0, 0.05, 0.7])\n",
    "#fig.colorbar(im, cax=cbar_ax)\n",
    "#fig.colorbar(im, ax=axes.ravel().tolist(), aspect=30, label='counts')\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chips Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.switch_backend(\"Agg\")\n",
    "dirpath = \"./data/HATP26\"\n",
    "fnames = df_sci.index.values\n",
    "for fname in tqdm(fnames):\n",
    "    fig, axes = utils.plot_chips(dirpath, fname, vmin=0, vmax=1_000, sky_ap=25)\n",
    "    fpath = f\"{dirpath}/pngs/sci_mask_{fname}.png\"\n",
    "    fig.savefig(fpath, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chips Movie all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend(\"Agg\")\n",
    "frames_all_nights = []\n",
    "for night in sorted(glob.glob(\"./data/WASP39/ut*\")):\n",
    "    frame_date = sorted(glob.glob(f\"{night}/pngs/*.png\"))\n",
    "    frames_all_nights.append(frame_date)\n",
    "\n",
    "# Get longest night for padding\n",
    "max_night_length = len(max(frames_all_nights, key=len))\n",
    "\n",
    "# Pad shorter nights with last frame for each night\n",
    "for night in frames_all_nights:\n",
    "    night += [night[-1]]*(max_night_length - len(night))\n",
    "\n",
    "# Combine\n",
    "#for frames_all in zip(*frames_all_nights):\n",
    "#    for frame in frames_all:\n",
    "#        print(frame)\n",
    "    #print(\"\\nMoving on to next frame in all datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend(\"Agg\")\n",
    "for i, frame in tqdm(enumerate(zip(*frames_all_nights)), total=max_night_length):\n",
    "    # Create plt plot:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(40, 18))\n",
    "\n",
    "    for ax, img in zip(axes.flat, frame):\n",
    "        plt_image = np.array(Image.open(img))\n",
    "        ax.imshow(plt_image, aspect=\"auto\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=.0, hspace=.0)\n",
    "    plt.savefig(f\"../atmospheres_meeting/figs/chips/frames/frame_{i:03}.png\", \n",
    "                bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_all_nights = []\n",
    "for night in sorted(glob.glob(\"./data/HATP23/ut*\")):\n",
    "    frame_date = sorted(glob.glob(f\"{night}/pngs/*.png\"))\n",
    "    frames_all_nights.append(frame_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_all_nights = []\n",
    "for night in sorted(glob.glob(\"./data/HATP23/ut*\")):\n",
    "    frame_date = sorted(glob.glob(f\"{night}/pngs/*.png\"))\n",
    "    frames_all_nights.append(frame_date)\n",
    "\n",
    "# Get longest night for padding\n",
    "max_night_length = len(max(frames_all_nights, key=len))\n",
    "\n",
    "# Pad shorter nights with last frame for each night\n",
    "for night in frames_all_nights:\n",
    "    night += [night[-1]]*(max_night_length - len(night))\n",
    "\n",
    "# Combine\n",
    "#for frames_all in zip(*frames_all_nights):\n",
    "#    print(frames_all)\n",
    "    #for frame in frames_all:\n",
    "    #    print(frame)\n",
    "    \n",
    "    #print(\"\\nMoving on to next frame in all datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"./data/HATP26/ut190313/ift1310c2.fits\"\n",
    "fig, axes, data = utils.plot_aperture(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Spectra over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = []\n",
    "for fpath in fpaths_sci:\n",
    "    chip_data = utils.fits_data(fpath)\n",
    "    x_l, x_r = 190, 206\n",
    "    #x_l, x_r = 688, 691\n",
    "    y_d, y_u = 0, chip_data.shape[0]\n",
    "    spectra_n = chip_data[y_d:y_u, x_l:x_r]\n",
    "    #spectra_n = np.max(spectra_n, axis=1)\n",
    "    spectra.append(spectra_n)\n",
    "    \n",
    "spectra = np.concatenate(np.array(spectra), axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/WASP39/ut190315\"\n",
    "chip_num = 5\n",
    "x_l, x_r = 190, 206\n",
    "object_name = \"w39bs science\"\n",
    "\n",
    "#data_dir = \"../data/WASP43/ut180603\"\n",
    "#chip_num = 8\n",
    "#x_l, x_r = 688, 691\n",
    "#object_name = \"science\"\n",
    "\n",
    "fig, ax, spectra = utils.plot_spec2d(data_dir, chip_num, x_l, x_r, object_name)\n",
    "\n",
    "tokens = data_dir.split(\"/\")\n",
    "target, date = tokens[2], tokens[3]\n",
    "fname = f\"spectra_2D_{target}_{date}\"\n",
    "fig.savefig(f\"/Users/mango/Desktop/{fname}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(spectra, vmin=0, vmax=30_000)\n",
    "fig.colorbar(im, ax=ax)\n",
    "ax.set_aspect(\"equal\")\n",
    "#fig.savefig(f\"/Users/mango/Desktop/{fname}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicklook Light Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fluxes'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"./data/HATP23/ut180821/HATP23_WLC_OTG.pkl\"\n",
    "target = fpath.split('/')[2]\n",
    "data = utils.pkl_load(fpath)\n",
    "name_target = [s for s in data[\"fluxes\"].keys() if target in s][0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "# Plot divided LCs\n",
    "time = data[\"time\"]\n",
    "flux_target = data[\"fluxes\"][name_target]\n",
    "flux_comps = []\n",
    "for obj, flux in data[\"fluxes\"].items():\n",
    "    if obj != name_target :\n",
    "        flux_comps.append(flux)\n",
    "        flux = flux_target / flux\n",
    "        #ax.plot(time, flux/np.median(flux), '.', label=obj)\n",
    "        ax.plot(flux/np.median(flux), 'o', label=obj)\n",
    "        \n",
    "# Plot sum LC\n",
    "flux_sum_comps = np.sum(flux_comps, axis=0)\n",
    "flux = flux_target / flux_sum_comps\n",
    "flux_norm = flux / np.median(flux)\n",
    "#ax.plot(time, flux / np.median(flux), 'lightgrey', lw=5, label=\"all\")\n",
    "ax.plot(flux_norm, '-o', color='lightgrey', lw=5, label=\"all\")\n",
    "ax.legend(ncol=int((len(flux_comps)+1)/2), frameon=True)\n",
    "delta = 1.0 - np.min(flux_norm)\n",
    "RpRs = np.sqrt(delta)\n",
    "label = rf\"$R_\\mathrm{{p}}/R_\\mathrm{{s}} \\approx {RpRs:.3f}$\"\n",
    "ax.annotate(label, xy=(0.9, 0.1), xycoords=\"axes fraction\", ha=\"center\")\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "ax.set_ylabel(\"Normalized Flux\")\n",
    "ax.set_ylim(0.978, 1.04)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMACS Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Transit 2':\n",
    "    f'{data_dir}/ut170609_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "    'Transit 3':\n",
    "    f'{data_dir}/ut180603_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_LARGE)\n",
    "\n",
    "objs = [\"HATP23b\", \"comp4\", 'comp5']\n",
    "colors = [\"C5\", \"C0\", \"C1\"]\n",
    "for ax, (transit_name, transit_path) in zip(axes.flat, data_dict.items()):\n",
    "    data = utils.pkl_load(transit_path)\n",
    "    time = Time(data[\"t\"], format=\"jd\")# - 2450000\n",
    "    wavs = data[\"optimal spectra\"][\"wavelengths\"]\n",
    "    wav_low_idx = np.where(wavs == 5000)[0][0]\n",
    "    wav_high_idx = np.where(wavs == 9000)[0][0]\n",
    "    wavs_int = wavs[wav_low_idx:wav_high_idx+1]\n",
    "    for obj, c in zip(objs, colors):\n",
    "        f = data[\"optimal spectra\"][obj][:,wav_low_idx:wav_high_idx+1].sum(axis=1)\n",
    "        ax.plot_date(time.plot_date, f/np.max(f), '.', label=obj, color=c)\n",
    "\n",
    "        ax.legend(ncol=3, loc=4)\n",
    "        ax.set_xlabel(\"Time (UTC)\")\n",
    "        ax.set_ylabel(\"$F / F_\\mathrm{max}$\")\n",
    "        ax.set_title(transit_name)\n",
    "\n",
    "    #ax.plot_date(time.plot_date, data[\"oLC\"]/np.max(data[\"oLC\"]), c='r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(data[\"oLC\"][:, 1], '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASAS-SN Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme(\"paper\")\n",
    "fpaths = [\n",
    "    'projects/HATP23b/asas-sn_hatp23.csv',\n",
    "    'projects/HATP23b/asas-sn_comp5.csv',\n",
    "    'projects/HATP23b/asas-sn_comp4.csv',\n",
    "    'projects/HATP23b/asas-sn_comp7.csv'\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "for fpath in fpaths:\n",
    "    df = pd.read_csv(fpath, parse_dates=[\"UT Date\"], date_parser=utils.myparser)\n",
    "\n",
    "    #display(df.head())\n",
    "    name = fpath.split('/')[-1]\n",
    "    df.set_index([\"UT Date\"], inplace=True)\n",
    "    grouped = df.groupby('Filter')\n",
    "    for (k, g) in grouped:\n",
    "        if k=='V':\n",
    "            ax.plot(g['flux(mJy)'], marker='.', lw=0, label=name)\n",
    "    \n",
    "mid_transit_times = {\n",
    "        'Transit 1': '2016-06-22 08:18:00',\n",
    "        'Transit 2': '2017-06-10 07:05:00',\n",
    "        'Transit 3': '2018-06-04 07:24:00',\n",
    "        'Transit 4': '2018-06-21 06:56',\n",
    "        'Transit 5': '2018-08-22 03:30:00',\n",
    "    }\n",
    "p_kwargs = {'ls': '--', 'c': 'grey', 'lw':1.0}\n",
    "for transit_name, t0 in mid_transit_times.items():\n",
    "    t_mid = parser.parse(t0)\n",
    "    ax.axvline(t_mid, **p_kwargs)\n",
    "    ax.text(t_mid, 20.0, transit_name, ha='right', rotation=90.0)\n",
    "\n",
    "ax.legend(loc=2, frameon=True, fontsize=12, bbox_to_anchor=(1, 1))\n",
    "#ax.set_title(fpath)\n",
    "ax.set_ylim(0, 60)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Flux (mJy)')\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m=2):\n",
    "    outlier_mask = abs(data - np.mean(data)) > m * np.std(data)\n",
    "    return data[~outlier_mask], outlier_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"projects/HATP23b/asas-sn_hatp23.csv\"\n",
    "df = pd.read_csv(fpath, parse_dates=[\"UT Date\"], date_parser=utils.myparser)\n",
    "df_V = df.groupby(\"Filter\").get_group(\"V\")\n",
    "t = (df_V[\"HJD\"] - 2.457e6).values\n",
    "f = df_V[\"flux(mJy)\"].values\n",
    "plt.figure()\n",
    "plt.plot(t[142:], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_filtered, outlier_mask = reject_outliers(f)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_LARGE)\n",
    "ax_top, ax_bottom = axes\n",
    "\n",
    "#ax.plot(t, f, '.')\n",
    "#ax.plot(t[outlier_mask], f[outlier_mask], 'ro', alpha=0.5)\n",
    "\n",
    "idxs_dict = {\n",
    "    \"asas-sn_hatp23.csv\":{\n",
    "        \"idx_start\":54,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 203), slice(204, 377), slice(412, 516)]\n",
    "    },\n",
    "    \"asas-sn_comp4.csv\":{\n",
    "        \"idx_start\":7,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 203), slice(204, 377), slice(419, 531)]\n",
    "    },\n",
    "    \"asas-sn_comp5.csv\":{\n",
    "        \"idx_start\":7,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 203), slice(204, 371), slice(418, 530)]\n",
    "    },\n",
    "    \"asas-sn_comp7.csv\":{\n",
    "        \"idx_start\":142,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 202), slice(204, 377), slice(419, 531)]\n",
    "    },\n",
    "}\n",
    "\n",
    "target_file = fpath.split('/')[-1]\n",
    "idx_start = idxs_dict[target_file][\"idx_start\"]\n",
    "time_global, flux_global = t[~outlier_mask][idx_start:], f[~outlier_mask][idx_start:]\n",
    "\n",
    "idxs_seasons = idxs_dict[target_file][\"idxs_seasons\"]\n",
    "\n",
    "ax_top.plot(time_global, flux_global, 'ko', alpha=0.25, mew=0)\n",
    "# Compute the GLS periodogram with default options.\n",
    "clp = pyPeriod.Gls((time_global, flux_global))\n",
    "freq_max, freq_max_err = clp.hpstat[\"fbest\"], clp.hpstat[\"f_err\"]\n",
    "P_max, P_max_err = 1.0/freq_max, clp.hpstat[\"Psin_err\"]\n",
    "label = f\"$P_\\mathrm{{max}} = {P_max:.3f} \\pm {P_max_err:.3e}$\"\n",
    "ax_bottom.semilogx(1.0/clp.freq, clp.power, label=label)\n",
    "print(f\"> Global\")\n",
    "print(f\"{fpath}\")\n",
    "clp.info()\n",
    "print()\n",
    "\n",
    "# Calculate sine wave associated with 'best-fit' frequency\n",
    "bestSine_global = clp.sinmod(time_global)\n",
    "ax_top.plot(time_global, bestSine_global, label=\"Global\")\n",
    "ax_top.legend(fontsize=12)\n",
    "\n",
    "for i, idxs_season in enumerate(idxs_seasons, start=1):\n",
    "    time, flux = time_global[idxs_season], flux_global[idxs_season]\n",
    "    #ax.plot(time, flux, '.')\n",
    "\n",
    "    # Compute the GLS periodogram with default options.\n",
    "    clp = pyPeriod.Gls((time, flux))\n",
    "    \n",
    "    # and plot power vs. period.\n",
    "    freq_max, freq_max_err = clp.hpstat[\"fbest\"], clp.hpstat[\"f_err\"]\n",
    "    P_max, P_max_err = 1.0/freq_max, clp.hpstat[\"Psin_err\"]\n",
    "    label = f\"$P_\\mathrm{{max}} = {P_max:.3f} \\pm {P_max_err:.3e}$\"\n",
    "    ax_bottom.semilogx(1.0/clp.freq, clp.power, label=label)\n",
    "    ax_bottom.set_xlabel(\"Period (days)\")\n",
    "    ax_bottom.set_ylabel(\"Power\")\n",
    "    \n",
    "    # Calculate sine wave associated with 'best-fit' frequency\n",
    "    bestSine = clp.sinmod(time)\n",
    "    ax_top.plot(time, bestSine, label=f\"Season {i}\")\n",
    "    idxs_mid = len(time) // 2\n",
    "    phot_var = np.var(flux)\n",
    "    ax_top.annotate(\n",
    "        f\"$\\sigma^2 = {phot_var:.3f}$\",\n",
    "        (time[idxs_mid], 41.5),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "    # Print helpful information to screen\n",
    "    print(f\"> Season {i}\")\n",
    "    print(f\"{fpath}\")\n",
    "    clp.info()\n",
    "    print()\n",
    "    \n",
    "ax_top.set_xlabel(\"HJD - 2.457e6\")\n",
    "ax_top.set_ylabel(\"Flux (mJy)\")\n",
    "ax_top.set_title(fpath)\n",
    "ax_top.legend(ncol=4, fontsize=12)\n",
    "ax_bottom.legend(ncol=2, fontsize=12)\n",
    "fig.tight_layout()\n",
    "\n",
    "#utils.savepng(f\"/Users/mango/Desktop/{target_file.split('.')[0]}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme(\"paper\")\n",
    "dirpath = 'projects/HATP23b/data/stell_act'\n",
    "\n",
    "# Load processed data\n",
    "df_stell_data = pd.read_csv(\n",
    "    f'{dirpath}/HATP23_lc_norm_v3.csv',\n",
    "    names=['t_HJD', 't_UT', 'f'],\n",
    "    parse_dates=[1],\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "#df_stell_data.set_index([\"t_ut\"], inplace=True)\n",
    "\n",
    "# Load model data\n",
    "df_stell_model = pd.read_csv(\n",
    "    f'{dirpath}/HATP23_GP_model_Prot7_v3.csv',\n",
    "    names=['t_HJD', 'f', 'f_err'],\n",
    ")\n",
    "\n",
    "print(\"data\")\n",
    "display(df_stell_data.head())\n",
    "print(\"model\")\n",
    "display(df_stell_model.head())\n",
    "\n",
    "# Load model\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "#ax.plot(df_stell_data['f'], '.')\n",
    "ax.plot(df_stell_data['t_HJD'], df_stell_data['f'], 'r.', alpha=0.5, mew=0)\n",
    "ax.plot(df_stell_model['t_HJD'], df_stell_model['f'], color=\"grey\")\n",
    "f_d = df_stell_model['f'] - df_stell_model['f_err']\n",
    "f_u = df_stell_model['f'] + df_stell_model['f_err']\n",
    "ax.fill_between(df_stell_model['t_HJD'], f_d, f_u, alpha=0.3, lw=0, color=\"grey\")\n",
    "\n",
    "p_kwargs = {'ls': '--', 'c': 'darkgrey', 'lw':1.0}\n",
    "trans = transforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
    "\n",
    "for transit_name, t0 in mid_transit_times.items():\n",
    "    t_mid = Time(t0).jd - 2.4e6\n",
    "    ax.axvline(t_mid, **p_kwargs)\n",
    "    ax.annotate(\n",
    "        transit_name,\n",
    "        xy=(t_mid, 0.1),\n",
    "        xycoords=trans,\n",
    "        ha='right',\n",
    "        rotation=90.0,\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "#ax.set_title(fpath)\n",
    "#ax.set_xlim(57400, 58500)\n",
    "ax.set_ylim(0.88, 0.98)\n",
    "ax.set_xlabel('Date (HJD - 2400000)')\n",
    "ax.set_ylabel('Flux (mJy)')\n",
    "fig.tight_layout()\n",
    "\n",
    "#utils.savefig(\"projects/HATP23b/paper/figures/phot_mon_full.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_stell_model['f'])\n",
    "ax.axhline(np.median(df_stell_model['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.max(df_stell_model['f']) - np.median(df_stell_model['f'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time(mid_transit_times[\"Transit 1\"]).jd - 2400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.947726 - 0.93211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(13571.18577 - 12584.79890) / 12584.79890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.weighted_mean_uneven_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(12585 + 12716 + 13571 + 13204 + 12832) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12585 - 12981.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0.05\n",
    "100*f / (1 - f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data #np.ones((8192, 1))\n",
    "f=open(\"pyt2.pickle\",\"wb\")\n",
    "pickle.dump(d, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.pkl_load(\"data/data_reductions/HATP23/ut180603_a15_25_noflat/LCs_hp23_species.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cLC\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"spectra\"][\"HATP23b\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traces over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"./data/data_reductions/HATP26/ut190313_a15_25_noflat_LBR\"\n",
    "fig, axes, XX, YY = utils.plot_traces(dirpath)\n",
    "#utils.savepng('projects/HATP23/traces_ut180821')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(XX[\"comp7_3\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some typin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './data/data_reductions/HATP23/ut180603_a15_25_noflat/sub_images/ift0136_HATP23b_c5.fits'\n",
    "data = utils.fits_data(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_sub = \"../data/data_reductions/WASP39/ut190315_a8_18_noflat_LBR/sub_images\"\n",
    "fpath_subimg = f\"{dir_sub}/ift3058_WASP39_c5.fits\"\n",
    "fpath_subtrace = f\"{dir_sub}/trace_ift3058_WASP39_c5_ap_109.fits\"\n",
    "\n",
    "#dir_sub = \"../data/data_reductions/WASP43/ut180603_a9_24_noflat_LBR/sub_images\"\n",
    "#fpath_subimg = f\"{dir_sub}/ift0107_WASP43b_c8.fits\"\n",
    "#fpath_subtrace = f\"{dir_sub}/trace_ift0107_WASP43b_c8_ap_25.fits\"\n",
    "\n",
    "subimg = utils.fits_data(fpath_subimg)\n",
    "subtrace = utils.fits_data(fpath_subtrace)\n",
    "print(f\"subarray dimension: {subimg.shape}\")\n",
    "fig, axes, data = utils.plot_subaperture(fpath_subimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Extracted Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mango/miniconda3/envs/gen/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/mango/miniconda3/envs/gen/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1664: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "dirpath = \"./data/data_reductions/HATP26/ut190313_a15_25_noflat_LBR\"\n",
    "#dirpath = './data/data_reductions/HATP23_py2/ut180620_a15_25_noflat'\n",
    "fpaths = np.array(glob.glob(f\"{dirpath}/*spec.fits\"))\n",
    "#mask = np.array([\"comp5_5\" not in fpath for fpath in fpaths])\n",
    "#mask &= [\"comp7_3\" not in fpath for fpath in fpaths]\n",
    "#mask &= [\"comp7_8\" not in fpath for fpath in fpaths]\n",
    "\n",
    "#mask = np.array([\"c05_4\" not in fpath for fpath in fpaths])\n",
    "#mask &= [\"c05_7\" not in fpath for fpath in fpaths]\n",
    "\n",
    "#mask = np.array([\"com03_6\" not in fpath for fpath in fpaths])\n",
    "#fpaths = fpaths[mask]\n",
    "objs = {}\n",
    "for i, obj_path in enumerate(fpaths):\n",
    "    p, p_name, wavs, p_data = utils.plot_spec_file_objects(\n",
    "        ax, obj_path, i=1,\n",
    "    )\n",
    "    objs[p_name] = p_data\n",
    "\n",
    "ax.set_title(dirpath)\n",
    "ax.legend(loc=2, fontsize=12)\n",
    "ax.set_xlim(0, 2_000)\n",
    "#ax.set_ylim(-10, 90_000)\n",
    "ax.set_xlabel(\"pixel (dispersion direction)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "fig.tight_layout()\n",
    "#date = Path(dirpath).parts[-1].split('_')[0]\n",
    "utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'data/data_reductions/HATP23/ut180821_a15_25_noflat/HATP23b_5_spec.fits'\n",
    "data = utils.fits_data(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[10, 1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelength Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the lamp spectra through the target and comparison star slits are usually completely shifted off of the reference lamp spectra, so `guess_lines.py` can't be used. Instead of using this, the lines can be manually identified from [NOAO](http://iraf.noao.edu/specatlas/henear/henear.html). After getting the first target done, the rest can be bootstrapped relatively quickly since their arc spectra should be similar.\n",
    "\n",
    "To make things a little easier, the following routine will automatically record the pixel and wavelength coordinate of each line selected from the bottom panel. To select the pixel value under the mouse, press 'X' on the keyboard. To record the corresponding wavelength value, click on the annotated value in the top reference panel. Rinse and repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reference (NOAO), do this one first\n",
    "# dirpath = \"./useful_scripts\"\n",
    "# fpath_arc_ref = f\"{dirpath}/noao_flux.fits\"\n",
    "# fpath_lines_ref = f\"{dirpath}/noao_line_list.txt\"\n",
    "\n",
    "# Reference (target) arc spectra, use as ref after calibrating inital with NOAO\n",
    "dirpath_ref = \"./data/data_reductions/HATP26/ut190313_a15_25_noflat_LBR/arcs\"\n",
    "fpath_arc_ref = f\"{dirpath_ref}/HATP26_2_arc.fits\"\n",
    "name = fpath_arc_ref.split('/')[-1].split('_')[0]\n",
    "#fpath_lines_ref = f\"{dirpath_ref}/{name}_guesses.txt\"\n",
    "fpath_lines_ref = f\"{dirpath_ref}/{name}_lines_chips.csv\"\n",
    "\n",
    "# Arc spectra to compare\n",
    "dirpath = \"./data/data_reductions/HATP26/ut190313_a15_25_noflat_LBR/arcs\"\n",
    "fpath_arc = f\"{dirpath}/c05_4_arc.fits\"\n",
    "name = fpath_arc.split('/')[-1].split('_')[0]\n",
    "#fpath_lines = f\"{dirpath}/{name}_guesses.csv\"\n",
    "fpath_lines = f\"{dirpath}/{name}_lines_chips.csv\"\n",
    "\n",
    "# Plot\n",
    "wavs, pixels = utils.compare_arc_lines(\n",
    "    fpath_arc_ref=fpath_arc_ref, \n",
    "    fpath_lines_ref=fpath_lines_ref,\n",
    "    fpath_arc=fpath_arc,\n",
    "    fpath_lines=fpath_lines,\n",
    "    sharex=False, sharey=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guesses = pd.read_csv(fpath_lines, escapechar='#')\n",
    "# update if lines chosen\n",
    "#if len(wavs) != 0 and len(pixels) != 0:\n",
    "chips = [int(fpath_arc.split('/')[-1].split('_')[1])] * len(wavs)\n",
    "df_chosen = pd.DataFrame({\"Wav\":wavs, \"Pix\":pixels, \"Chip\":chips})\n",
    "\n",
    "df_guesses = pd.concat([df_guesses, df_chosen])\n",
    "\n",
    "fname = fpath_lines.split('/')[-1]\n",
    "df_guesses = df_guesses.sort_values(by=[\"Chip\", \"Wav\"])\n",
    "display(df_guesses)\n",
    "print(f\"Will save to: {dirpath}/{fname}\")\n",
    "\n",
    "save = input(\"Continue? (y/n): \")\n",
    "if save.lower() == 'y': \n",
    "    df_guesses.to_csv(f\"{dirpath}/{fname}\", index=False, escapechar='#')\n",
    "    print(f\"Saved to: {dirpath}/{fname}\")\n",
    "else: \n",
    "    print(\"not saved\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt(fpath, delimiter=',').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View wavelength solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=FIG_LARGE)\n",
    "\n",
    "dir_lines = \"./data/data_reductions/HATP26/ut190313_a15_25_noflat_LBR/arcs\"\n",
    "#fpaths = glob.glob(f\"{dir_lines}/*guesses*.txt\")\n",
    "fpaths = glob.glob(f\"{dir_lines}/*lines_chips.csv\")\n",
    "x_name = \"Pix\"\n",
    "y_name = \"Wav\"\n",
    "for fpath in fpaths:\n",
    "    df = pd.read_csv(fpath, escapechar=\"#\")\n",
    "    comp_name = fpath.split('/')[-1].split('_')[0].split(\"comp\")[-1]\n",
    "    utils.plot_pix_wav(ax, df, x_name, y_name, comp_name)\n",
    "\n",
    "ax.legend(frameon=True)\n",
    "ax.set_xlabel(x_name)\n",
    "ax.set_ylabel(y_name)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4791.25 4792.5  4793.75 ... 8831.25 8832.5  8833.75]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_reductions\"\n",
    "binsize = \"hp26_bins\"\n",
    "# data_dict = {\n",
    "#     'Transit 1':\n",
    "#     f'{data_dir}/ut160621_a15_20_noflat/LCs_hp23_{binsize}_160621.pkl',\n",
    "    \n",
    "#     'Transit 2':\n",
    "#     f'{data_dir}/ut170609_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "#     'Transit 3':\n",
    "#     f'{data_dir}/ut180603_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "#     'Transit 4':\n",
    "#     f'{data_dir}/ut180620_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "#     'Transit 5':\n",
    "#     f'{data_dir}/ut180821_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "# }\n",
    "\n",
    "data_dict = {\n",
    "    \"Transit 1\":\n",
    "    f\"{data_dir}/ut190313_a15_25_noflat_LBR/LCs_{binsize}.pkl\"\n",
    "}\n",
    "\n",
    "#set_theme('paper')\n",
    "#paper_path = 'projects/HATP23b/paper/figures'\n",
    "wbins = pd.read_table(\n",
    "    f\"{data_dir}/hp26_bins.dat\",\n",
    "    names=['wav_d', 'wav_u'],\n",
    "    skiprows=1,\n",
    "    sep='\\s+',\n",
    "    comment='#',\n",
    ")\n",
    "for transit, fpath in data_dict.items():\n",
    "    data = utils.pkl_load(fpath)\n",
    "    spec = data['optimal spectra']\n",
    "    wavs = spec[\"wavelengths\"]\n",
    "    print(wavs[[data['idx_usable_wl']]])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "    c = 'darkgrey'\n",
    "    for name, data in sorted(spec.items()):\n",
    "        if name in 'HATP23b':\n",
    "            median_kwargs = {'c':'C5'} \n",
    "        else:\n",
    "            median_kwargs = None #{'c':c}\n",
    "            c = 'grey'\n",
    "        if (name != 'wavelengths'):\n",
    "            p, wav, flux = utils._plot_spec_file(\n",
    "                ax, data=data, wavs=wavs, label=name, median_kwargs=median_kwargs,\n",
    "            )\n",
    "    ax.legend(loc=1, fontsize=12)\n",
    "    \n",
    "    # bins\n",
    "    for i, (w_d, w_u) in enumerate(zip(wbins['wav_d'], wbins['wav_u'])):\n",
    "        c = 'k' if i % 2 == 0 else 'darkgrey'\n",
    "        ax.axvspan(w_d, w_u, alpha=0.25, color=c, lw=0)\n",
    "    \n",
    "    # species lines\n",
    "    species = {\n",
    "        'Na I-D':5892.9, \n",
    "        'K I_avg':7682.0, \n",
    "        'Na I-8200_avg':8189.0\n",
    "    }\n",
    "    [ax.axvline(wav, ls='--', lw=1, color='grey') for name, wav in species.items()]\n",
    "    title = transit\n",
    "    ax.set_xlabel('Wavelength (Å)')\n",
    "    ax.set_ylabel('Normalized flux')\n",
    "    #ax.set_title(title)\n",
    "    ax.set_xlim(wavs[0], wavs[-1])\n",
    "    ax.set_ylim(-0.01, 1.15)\n",
    "\n",
    "    title = title.lower().replace(' ', '_') + '_extr_spec'\n",
    "    fig.set_size_inches(FIG_WIDE)\n",
    "    #utils.savefig(f'{paper_path}/extracted_spectra/{title}.pdf')\n",
    "    #utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.pkl_load(fpath)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Transit 2':\n",
    "    f'{data_dir}/ut170609_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "    'Transit 3':\n",
    "    f'{data_dir}/ut180603_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_LARGE)\n",
    "\n",
    "objs = [\"HATP23b\", \"comp4\", 'comp5']\n",
    "colors = [\"C5\", \"C0\", \"C1\"]\n",
    "for ax, (transit_name, transit_path) in zip(axes.flat, data_dict.items()):\n",
    "    data = utils.pkl_load(transit_path)\n",
    "    time = Time(data[\"t\"], format=\"jd\")# - 2450000\n",
    "    wavs = data[\"optimal spectra\"][\"wavelengths\"]\n",
    "    wav_low_idx = np.where(wavs == 5000)[0][0]\n",
    "    wav_high_idx = np.where(wavs == 9000)[0][0]\n",
    "    wavs_int = wavs[wav_low_idx:wav_high_idx+1]\n",
    "    for obj, c in zip(objs, colors):\n",
    "        f = data[\"optimal spectra\"][obj][:,wav_low_idx:wav_high_idx+1].sum(axis=1)\n",
    "        ax.plot_date(time.plot_date, f/np.max(f), '.', label=obj, color=c)\n",
    "\n",
    "        ax.legend(ncol=3, loc=4)\n",
    "        ax.set_xlabel(\"Wavelength (Å)\")\n",
    "        ax.set_ylabel(\"$F / F_\\mathrm{max}$\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c01', 'c03', 'c05']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbins = pd.read_table('hp26_bins.dat', names=['wav_d', 'wav_u'], skiprows=1, sep='\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4791.25 4792.5  4793.75 ... 8831.25 8832.5  8833.75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-a7c3ec140109>:5: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  print(wavs[[data['idx_usable_wl']]])\n",
      "/home/mango/miniconda3/envs/gen/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/mango/miniconda3/envs/gen/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1664: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "fpath = 'data/data_reductions/HATP26/ut190313_a15_25_noflat_LBR/LCs_w43_25nm.pkl'\n",
    "data = utils.pkl_load(fpath)\n",
    "spec = data['optimal spectra']\n",
    "wavs = spec[\"wavelengths\"]\n",
    "print(wavs[[data['idx_usable_wl']]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "p, wav, flux = utils._plot_spec_file(ax, data=spec['HATP26'], wavs=wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8109.00 8309.00\n",
      "8309.00 8509.00\n",
      "8509.00 8709.00\n",
      "8709.00 8909.00\n",
      "8909.00 9109.00\n"
     ]
    }
   ],
   "source": [
    "dw = 200\n",
    "for w in np.arange(8109, 9069+40, dw):\n",
    "    print(f'{w:.2f}', f'{w+dw:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_d</th>\n",
       "      <th>wav_u</th>\n",
       "      <th>diff</th>\n",
       "      <th>center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4800.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>4900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000.00</td>\n",
       "      <td>5200.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>5100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5200.00</td>\n",
       "      <td>5400.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>5300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5400.00</td>\n",
       "      <td>5600.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>5500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5600.00</td>\n",
       "      <td>5800.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>5700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5800.00</td>\n",
       "      <td>5985.80</td>\n",
       "      <td>185.80</td>\n",
       "      <td>5892.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5985.80</td>\n",
       "      <td>6185.80</td>\n",
       "      <td>200.00</td>\n",
       "      <td>6085.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6185.80</td>\n",
       "      <td>6385.80</td>\n",
       "      <td>200.00</td>\n",
       "      <td>6285.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6385.80</td>\n",
       "      <td>6655.00</td>\n",
       "      <td>269.20</td>\n",
       "      <td>6520.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6655.00</td>\n",
       "      <td>6855.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>6755.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6855.00</td>\n",
       "      <td>7055.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>6955.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7055.00</td>\n",
       "      <td>7255.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>7155.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7255.00</td>\n",
       "      <td>7455.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>7355.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7455.00</td>\n",
       "      <td>7655.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>7555.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7655.00</td>\n",
       "      <td>7709.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>7682.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7709.00</td>\n",
       "      <td>7909.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>7809.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7909.00</td>\n",
       "      <td>8109.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>8009.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8109.00</td>\n",
       "      <td>8309.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>8209.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8309.00</td>\n",
       "      <td>8509.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>8409.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8509.00</td>\n",
       "      <td>8709.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>8609.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8709.00</td>\n",
       "      <td>8909.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>8809.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8909.00</td>\n",
       "      <td>9109.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>9009.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     wav_d   wav_u   diff  center\n",
       "0  4800.00 5000.00 200.00 4900.00\n",
       "1  5000.00 5200.00 200.00 5100.00\n",
       "2  5200.00 5400.00 200.00 5300.00\n",
       "3  5400.00 5600.00 200.00 5500.00\n",
       "4  5600.00 5800.00 200.00 5700.00\n",
       "5  5800.00 5985.80 185.80 5892.90\n",
       "6  5985.80 6185.80 200.00 6085.80\n",
       "7  6185.80 6385.80 200.00 6285.80\n",
       "8  6385.80 6655.00 269.20 6520.40\n",
       "9  6655.00 6855.00 200.00 6755.00\n",
       "10 6855.00 7055.00 200.00 6955.00\n",
       "11 7055.00 7255.00 200.00 7155.00\n",
       "12 7255.00 7455.00 200.00 7355.00\n",
       "13 7455.00 7655.00 200.00 7555.00\n",
       "14 7655.00 7709.00  54.00 7682.00\n",
       "15 7709.00 7909.00 200.00 7809.00\n",
       "16 7909.00 8109.00 200.00 8009.00\n",
       "17 8109.00 8309.00 200.00 8209.00\n",
       "18 8309.00 8509.00 200.00 8409.00\n",
       "19 8509.00 8709.00 200.00 8609.00\n",
       "20 8709.00 8909.00 200.00 8809.00\n",
       "21 8909.00 9109.00 200.00 9009.00"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "wbins = pd.read_table('hp26_bins.dat', names=['wav_d', 'wav_u'], skiprows=1, sep='\\s+', comment='#')\n",
    "\n",
    "offs = 0\n",
    "wbins['wav_d'] -= offs\n",
    "wbins['wav_u'] -= offs\n",
    "\n",
    "wbins['diff'] = wbins['wav_u'] - wbins['wav_d']\n",
    "wbins['center'] = (wbins['wav_u'] + wbins['wav_d']) / 2\n",
    "wbins.rename(\n",
    "    columns={\n",
    "        \"wav_d\": \"Wav start\",\n",
    "        \"wav_u\": \"Wav end\",\n",
    "        \"diff\": \"Wav diff\",\n",
    "        \"center\": \"Wav cen\",\n",
    "    },\n",
    "#).to_csv('projects/HATP23b/data/wavbins/species.csv', index=False)\n",
    ")#.to_clipboard(index=False)\n",
    "wbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_d\twav_u\n",
    "5775.799999999999\t5830.0\n",
    "5820.799999999999\t5875.0\n",
    "5865.799999999999\t5920.0\n",
    "5910.799999999999\t5965.0\n",
    "5955.799999999999\t6010.0\n",
    "7645.799999999999\t7665.0\n",
    "7655.799999999999\t7675.0\n",
    "7665.799999999999\t7685.0\n",
    "7675.799999999999\t7695.0\n",
    "7685.799999999999\t7705.0\n",
    "8080.799999999999\t8130.0\n",
    "8120.799999999999\t8170.0\n",
    "8160.799999999999\t8210.0\n",
    "8200.8\t8250.0\n",
    "8240.8\t8290.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# spectrum\n",
    "#x.plot(wav, flux)\n",
    "\n",
    "# wav bins\n",
    "\"\"\"\n",
    "wbins = {}\n",
    "wbins['wav_d'] = []\n",
    "wbins['wav_u'] = []\n",
    "dw = 200\n",
    "for w in range(5300, 9000, dw):\n",
    "    wbins['wav_d'].append(w)\n",
    "    wbins['wav_u'].append(w+dw)\n",
    "\"\"\"\n",
    "print(len(wbins['wav_d']))\n",
    "for i, (w_d, w_u) in enumerate(zip(wbins['wav_d'], wbins['wav_u'])):\n",
    "    c = 'b' if i % 2 == 0 else 'r'\n",
    "    ax.axvspan(w_d, w_u, alpha=0.25, color=c)\n",
    "\n",
    "# species lines\n",
    "species = {\n",
    "    'Na I-D':5892.9, \n",
    "    'Hα':6564.6, \n",
    "    'K I_avg':7682.0, \n",
    "    'Na I-8200_avg':8189.0\n",
    "}\n",
    "[ax.axvline(wav, ls='--', color='w') for name, wav in species.items()]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5785-5300)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(6440-6010)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(7657 - 6690)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "for name, data in sorted(spec.items()):\n",
    "    if name != 'wavelengths':\n",
    "        p, _ = utils._plot_spec_file(ax, data=data, wavs=wavs, label=name)\n",
    "        \n",
    "ax.set_xlim(wavs[0], wavs[-1])\n",
    "ax.set_ylim(-0.01, 1.15)\n",
    "ax.legend(fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c01', 'c03', 'c05']\n",
      "['c01', 'c03', 'c05']\n"
     ]
    }
   ],
   "source": [
    "dirpath = \"/home/mango/Projects/HATP26b/data_detrending/hp26_190313_c/\"\n",
    "# data_dict = {\n",
    "#     \"Transit 2\":\n",
    "#     { \n",
    "#         \"fpath\":f\"{dirpath}/ut170609_a15_25_noflat/LCs_hp23_bins.pkl\",\n",
    "#         \"idxs_oot\":\"0:28, 128:164\",\n",
    "#     },\n",
    "#     \"Transit 3\":\n",
    "#     { \n",
    "#         \"fpath\":f\"{dirpath}/ut180603_a15_25_noflat/LCs_hp23_bins.pkl\",\n",
    "#         \"idxs_oot\":\"0:39, 119:180\",\n",
    "#     },\n",
    "#     \"Transit 4\":\n",
    "#     { \n",
    "#         \"fpath\":f\"{dirpath}/ut180620_a15_25_noflat/LCs_hp23_bins.pkl\",\n",
    "#         \"idxs_oot\":\"0:19, 128:171\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "data_dict = {\n",
    "    \"Transit 1\":\n",
    "    {\n",
    "        \"fpath\":f\"{dirpath}/ut190313_a15_25_noflat_LBR/LCs_w43_25nm.pkl\",\n",
    "        \"idxs_oot\": \"[]\",\n",
    "    }\n",
    "}\n",
    "\n",
    "for transit_name, transit_data in data_dict.items():\n",
    "    fpath = transit_data[\"fpath\"]\n",
    "    data = utils.pkl_load(fpath)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=FIG_WIDE)\n",
    "    ax_left, ax_middle, ax_right = axes\n",
    "\n",
    "    # Raw fluxes\n",
    "    p, _ = utils.plot_fluxes(ax_left, data, use_time=False)\n",
    "    p.set_title(\"Raw fluxes\")\n",
    "    p.set_ylim(0, 3e8)\n",
    "\n",
    "    # OOT raw fluxes\n",
    "    idx_oot = utils._bad_idxs(transit_data[\"idxs_oot\"])\n",
    "    p, p_data = utils.plot_fluxes(ax_middle, data, oot=True, idx_oot=idx_oot)\n",
    "    p.set_title(\"OOT raw fluxes\")\n",
    "    p.set_ylim(0, 3e8)\n",
    "\n",
    "    # Divided OOT raw fluxes\n",
    "    time = p_data[\"time\"]\n",
    "    targ_flux = p_data[\"targ_flux\"]\n",
    "    comp_fluxes = p_data[\"comp_fluxes\"]\n",
    "    cNames = p_data[\"cNames\"]\n",
    "    p = utils.plot_div_fluxes(\n",
    "        ax_right, time, targ_flux, comp_fluxes, cNames,\n",
    "    )\n",
    "    p.set_title(\"Divided OOT raw fluxes\")\n",
    "    p.set_ylim(0.5, 2.0)\n",
    "    #np.savetxt(f\"/Users/mango/Desktop/{title}.txt\", fluxes)\n",
    "\n",
    "    title = transit_name\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    #utils.savepng(f\"/Users/mango/Desktop/oot_{title}.png\")\n",
    "\n",
    "    f_data = {\n",
    "        \"time\":p_data[\"time\"],\n",
    "        \"targ\":p_data[\"targ_flux\"],\n",
    "        \"comp5\":p_data[\"comp_fluxes\"][:, 0],\n",
    "        \"comp4\":p_data[\"comp_fluxes\"][:, 1],\n",
    "    }\n",
    "    #pd.DataFrame(f_data).to_csv(f\"/Users/mango/Desktop/fluxes_{title}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(f_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLC Divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['spectra', 'optimal spectra', 'Z', 'g', 'rot', 'fo', 't', 'ha', 'telev', 'theta', 'derg', 'drot', 'etimes', 'deltas', 'wbins', 'cNames', 'oLC', 'cLC', 'idx_usable_wl', 'oLCw', 'cLCw', 'traces', 'apertures', 'sky', 'fwhm'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = utils.pkl_load(data_dict[\"Transit 1\"][\"fpath\"])\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c01', 'c03', 'c05']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"cNames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mango/ACCESS_notebook/Projects/HATP26b/data_reductions/ut190313_a15_25_noflat_LBR/LCs_hp26_bins_r.pkl\n",
      "271\n",
      "['c01', 'c03', 'c05']\n",
      "c01 1-sigma bad_idxs: [15]\n",
      "c03 1-sigma bad_idxs: [12, 17]\n",
      "c05 1-sigma bad_idxs: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set_theme(\"paper\")\n",
    "#sns.set_context('paper')\n",
    "data_dir = \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_reductions\"\n",
    "LCs_pickle = \"LCs_hp26_bins_r.pkl\"\n",
    "data_dict = {\n",
    "    \"Transit 1\":\n",
    "    {\n",
    "        \"path\":f\"{data_dir}/ut190313_a15_25_noflat_LBR/{LCs_pickle}\",\n",
    "        \"bad_idxs\":\"[4,5,11,12]\",\n",
    "        \"t0\":2455304.65218,\n",
    "    }\n",
    "}\n",
    "# data_dict = {\n",
    "#     'Transit 1':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut160621_a15_20_noflat/{LCs_pickle}_160621.pkl',\n",
    "#             'bad_idxs':'[239, 240, 241, 256, 276, 278, 283, 284, 288:299]',\n",
    "#             't0':2457561.84167,\n",
    "#         },\n",
    "    \n",
    "#     'Transit 2':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut170609_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             'bad_idxs':'[10]',\n",
    "#             't0':2457914.79167,\n",
    "#         },\n",
    "    \n",
    "#     'Transit 3':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut180603_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             'bad_idxs':'[0:17]',\n",
    "#             't0':2458273.80556,\n",
    "#         },\n",
    "    \n",
    "#     'Transit 4':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut180620_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             'bad_idxs':'[93, 94, 149, 157:171]',\n",
    "#             't0':2458290.78472,\n",
    "#         },\n",
    "#     'Transit 5':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut180821_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             #'bad_idxs':'[4:6, 51, 53, 54, 56:59, 64, 66, 68, 69, 72, 77:80, 87:94, 96:98, 101, 108:119, 120, 129:131, 133, 174:181]',\n",
    "#             'bad_idxs':'[4:6, 51, 53, 54, 56:59, 64, 66, 68, 69, 72, 77:80, 87:94, 96:98, 101, 129:131, 133, 174:181]',\n",
    "#             #'bad_idxs':'[108:120]',\n",
    "#             't0':2458352.64028,\n",
    "#         },\n",
    "    \n",
    "# }\n",
    "\n",
    "comps = ['c01', 'c03', 'c05']\n",
    "ncomps = len(comps)\n",
    "fig, axes = plt.subplots(\n",
    "    1, ncomps, \n",
    "    sharex=True, sharey=True,\n",
    "    #figsize=(7, 14),\n",
    ")\n",
    "if axes.ndim == 1: axes = axes.reshape(1, axes.size) \n",
    "colors = sns.color_palette()\n",
    "for i, (transit_name, transit_info) in enumerate(data_dict.items()):\n",
    "    fpath = transit_info['path']\n",
    "    t0 = transit_info['t0']\n",
    "    data = utils.pkl_load(fpath)\n",
    "    print(fpath)\n",
    "    print(len(data['t']))\n",
    "    print(data['cNames'])\n",
    "    #ncomps = len(data['cNames'])\n",
    "    #fig, axes = plt.subplots(\n",
    "    #    1, ncomps, \n",
    "    #    sharex=True, sharey=True,\n",
    "    #    figsize=(12,3),\n",
    "    #)\n",
    "    \n",
    "    for ax, comp in zip(axes[i, :], comps):\n",
    "        p = utils.plot_divided_wlcs(\n",
    "            ax,\n",
    "            data,\n",
    "            t0=t0,\n",
    "            ferr=0.001,\n",
    "            comps_to_use=[comp],\n",
    "            bad_idxs_user = transit_info['bad_idxs'],\n",
    "            div_kwargs={'fmt':'.', 'lw':0.5, 'mew':0.0, 'ms':3, 'c':colors[i]},\n",
    "            bad_div_kwargs={'fmt':'.', 'lw':0.5, 'mec':'k', 'ms':6, 'c':'w'},\n",
    "        )\n",
    "        #ax.set_title(comp)\n",
    "        ax.annotate(\n",
    "            rf\"{transit_name}/{comp}\",\n",
    "            xy=(0.05, 0.85),\n",
    "            xycoords='axes fraction',\n",
    "            fontsize=12, color=colors[i],\n",
    "            weight='bold',\n",
    "        )\n",
    "        #ax.set_xlim(-3, 3)\n",
    "        #ax.xaxis.set_ticks([-3, -2, -1, 0, 1, 2, 3])\n",
    "        ax.set_ylim(0.988, 1.02)\n",
    "        ax.yaxis.set_ticks([0.96, 0.98, 1.00, 1.02, 1.04])\n",
    "        #fig.set_size_inches(12, 3)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    title = transit_name.lower().replace(' ', '_') + '_extr_wlcs'\n",
    "# Custom legend\n",
    "#handles, labels = [], []\n",
    "#for transit_name in list(data_dict.keys()):\n",
    "#    dummy = plt.errorbar([], [], yerr=0.1, fmt='o', ms=5, elinewidth=2, label=transit_name)\n",
    "#    handles.append(dummy)\n",
    "#    labels.append(transit_name)\n",
    "#fig.legend(handles, labels, ncol=5, bbox_to_anchor=(0.54, 1.1), loc='upper center')#, ncol=len(data_dict)+1) \n",
    "#axes[0, 0].set_title('comp4')\n",
    "#axes[0, 1].set_title('comp5')\n",
    "\n",
    "fig.text(0.54, -0.02, 'Time from estimated mid-transit (hours)', ha='center')\n",
    "fig.text(-0.01, 0.5, 'Normalizd flux', va='center', rotation='vertical')\n",
    "#axes[0].set_ylabel('Normalized flux')\n",
    "fig.tight_layout()\n",
    "#fig.set_size_inches(12, 3)\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/wlc\")\n",
    "\n",
    "    #plt.savefig('/Users/mango/Desktop/wlc_py2_py3.png', dpi=250, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.653529;0.775x0.226471) a1\n",
      "AxesSubplot(0.125,0.381765;0.775x0.226471) a2\n",
      "AxesSubplot(0.125,0.11;0.775x0.226471) a3\n"
     ]
    }
   ],
   "source": [
    "comps = [\"a1\", \"a2\", \"a3\"]\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "if axes.ndim == 1: axes = axes.reshape(1, axes.size) \n",
    "plt.close()\n",
    "\n",
    "for ax, comp in zip(axes[0, :], comps):\n",
    "    print(ax, comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:>], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(set([6, 51, 52, 55, 59, 64, 65, 66, 67, 68, 69, 72, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 108, 111, 112, 113, 120, 129, 130, 131, 132, 133, 178, 179, 180]).union(set([55, 56, 59, 68, 88, 89, 90, 91, 97, 120, 178]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIG_WIDE, sharex=True, sharey=True)\n",
    "\n",
    "comps_to_use =  [\"comp4\", \"comp5\"] #data[\"cNames\"]\n",
    "p, i_used, t, f_div_sum, i_not_used, i_all = utils.plot_sum_divided_wlcs(\n",
    "    ax,\n",
    "    data,\n",
    "    comps_to_use=comps_to_use,\n",
    "    bad_idxs_user = \"[53:59, 64, 65, 68, 78:80, 88:91, 97, 109, 110:120, 173:181]\",\n",
    "    div_sum_kwargs={\"fmt\":'.', \"mew\":0, \"alpha\":0.5, \"lw\":0.5},\n",
    ")\n",
    "p.legend(ncol=3, loc=\"upper center\", frameon=True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview divided LC\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "ax.errorbar(i_used, f_div_sum[i_used], yerr=0.001, fmt='.', lw=0.5)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferr = 0.001 * np.ones_like(i_used)\n",
    "instrument = [\"MAGELLAN\"] * len(i_used)\n",
    "df_juliet = pd.DataFrame(\n",
    "    zip(t[i_used] - 2457000, f_div_sum[i_used].flatten(), ferr, instrument),\n",
    ")\n",
    "df_juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path(\"juliet/hatp23_test/\")\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "df_juliet.to_csv(\n",
    "    f\"{p}/lc.dat\",\n",
    "    float_format=\"%.10f\",\n",
    "    sep=' ',\n",
    "    header=False,\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "with open(p / \"used_comps_and_bad_idxs.txt\", \"w\") as f:\n",
    "    f.writelines([f\"{comps_to_use}\\n\", f\"{i_not_used}\"])\n",
    "    \n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.pkl_load(\n",
    "    \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_reductions/ut190313_a15_25_noflat_LBR/LCs_hp26_bins_r.pkl\"\n",
    ")\n",
    "\n",
    "# Get target flux\n",
    "flux_target = np.c_[data[\"oLCw\"]]\n",
    "\n",
    "# Select comps\n",
    "cNames = data[\"cNames\"]\n",
    "comps_to_use = [\"c01\", \"c03\", \"c05\"] #cNames\n",
    "comps_to_use_idxs = [cNames.index(cName) for cName in comps_to_use]\n",
    "flux_comps_used = np.c_[data[\"cLCw\"][:, comps_to_use_idxs, :]]\n",
    "flux_comps_used_sum = np.c_[np.sum(flux_comps_used, axis=1)]\n",
    "\n",
    "# Divide target flux by sum of chosen comp sum\n",
    "flux_div_sum = flux_target / flux_comps_used_sum\n",
    "flux_div_sum /= np.median(flux_div_sum, axis=0)\n",
    "\n",
    "# Identify bad time idxs\n",
    "time = data['t']\n",
    "bad_idxs = '[4,5,11,12]' #'[4:6, 51, 53, 54, 56:59, 64, 66, 68, 69, 72, 77:80, 87:94, 96:98, 101, 108:119, 120, 129:131, 133, 174:181]'\n",
    "bad_idxs = utils._bad_idxs(bad_idxs)\n",
    "if bad_idxs is not None:\n",
    "    idxs_used = np.delete(range(len(time)), bad_idxs)\n",
    "else:\n",
    "    idxs_used = range(len(time))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 11), sharex=True, sharey=True)\n",
    "ax_left, ax_right = axes\n",
    "\n",
    "fluxes = flux_div_sum[idxs_used, :]\n",
    "N_bins = fluxes.shape[1]\n",
    "\n",
    "# Plot binned light curves\n",
    "offs = 0.008\n",
    "p_left = utils.plot_binned(\n",
    "        ax_left,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=np.array(data[\"wbins\"]), \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0}\n",
    "    )\n",
    "p_left.set_title(\"Raw divided flux\")\n",
    "\n",
    "# TODO: Try detrending with `exoplanet`\n",
    "# Plot residuals\n",
    "p_right = utils.plot_binned(\n",
    "        ax_right,\n",
    "        idxs_used,\n",
    "        np.ones_like(fluxes),\n",
    "        utc=False,\n",
    "        bins=np.array(data[\"wbins\"]), \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        annotate=True,\n",
    "        annotate_kwargs={\"fontsize\":10, \"ha\":\"center\"},\n",
    "    )\n",
    "p_right.set_title(\"Residuals\")\n",
    "\n",
    "ax_left.set_ylabel(\"Normalized flux + offset\")\n",
    "fig.text(0.5, 0, 'Time (JD)', ha='left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig(\"/Users/mango/Desktop/binned_lc.png\", dpi=250, bbox_inches=\"tight\")\n",
    "\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/raw_blcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['idx_usable_wl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['optimal spectra']['wavelengths']#[data['idx_usable_wl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['idx_usable_wl'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "data = np.c_[time[idxs_used], fluxes]\n",
    "p = pathlib.Path(\"xo/WASP43/ut180603/binned_free_rho_star\")\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "np.save(f\"{p}/lc_w.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(p / \"lc_w.npy\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detrending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comp idxs\n",
    "cNames = data[\"cNames\"]\n",
    "comps_to_use = [\"comp4\"]\n",
    "idxs_comps_to_use = [cNames.index(cName) for cName in comps_to_use]\n",
    "\n",
    "# Get time idxs\n",
    "bad_idxs = utils._bad_idxs(\"[239:241, 256, 276, 296]\")\n",
    "t = data['t']\n",
    "idxs = range(len(t))\n",
    "idxs_to_use = np.delete(idxs, bad_idxs)\n",
    "\n",
    "# Get target and comp fluxes (in magnitude-space)\n",
    "target_flux = data[\"oLC\"][idxs_to_use]\n",
    "comp_fluxes = data[\"cLC\"][np.ix_(idxs_to_use, idxs_comps_to_use)]\n",
    "\n",
    "target_flux_mag = -2.51*np.log10(target_flux)\n",
    "comp_fluxes_mag = -2.51*np.log10(comp_fluxes)\n",
    "\n",
    "# Median-substracted target (tms) and comparison (cms) lightcurves (in magnitude-space)\n",
    "# tms will also have the time in ints first column\n",
    "tms = target_flux_mag - np.median(target_flux_mag, axis=0)\n",
    "tms = np.c_[t[idxs_to_use], tms]\n",
    "cms = comp_fluxes_mag - np.median(comp_fluxes_mag, axis=0)\n",
    "\n",
    "# Mean-subtract and rms normalize\n",
    "#X = eparams #(tms - np.mean(tms, axis=0)) / np.std(tms, axis=0)\n",
    "Xc = (cms - np.mean(cms, axis=0)) / np.std(cms, axis=0)\n",
    "\n",
    "PCA = False\n",
    "if PCA:\n",
    "    eigenvectors, eigenvalues, Xc = utils.classic_PCA(Xc) \n",
    "\n",
    "#plt.plot(X[:, 1], '.')\n",
    "#plt.plot(Xc[:, 1], '.')\n",
    "#plt.plot(np.array(idxs)[idxs_to_use], target_flux, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_params = {\n",
    "    'ld_law': 'logarithmic',\n",
    "    'q1': 0.5,\n",
    "    'q2': 0.5,\n",
    "    't0': 2457561.8458,\n",
    "    'P': 1.2128867,\n",
    "    'p': 0.1113,\n",
    "    'a': 4.26,\n",
    "    'inc': 85.10,\n",
    "}\n",
    "\n",
    "t = np.linspace(np.min(t), np.max(t), 100)\n",
    "lc_model = utils.get_transit_model(t, lc_params)\n",
    "plt.plot(t, lc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External params\n",
    "\n",
    "# Get median of FWHM, background flux, accross all wavelengths, and trace position of zero point.\n",
    "# First, find chips-names of target:\n",
    "target = b\"HATP23\"\n",
    "names = []\n",
    "for name in data['fwhm'].keys():\n",
    "    if target in name:\n",
    "        names.append(name)\n",
    "if len(names) == 1:\n",
    "    Xfwhm = data['fwhm'][names[0]]\n",
    "    Xsky = data['sky'][names[0]]\n",
    "else:\n",
    "    Xfwhm = np.hstack((data['fwhm'][names[0]],data['fwhm'][names[1]]))\n",
    "    Xsky = np.hstack((data['sky'][names[0]],data['sky'][names[1]]))\n",
    "\n",
    "fwhm = np.zeros(Xfwhm.shape[0])\n",
    "sky = np.zeros(Xfwhm.shape[0])\n",
    "trace = np.zeros(Xfwhm.shape[0])\n",
    "target = \"HATP23\"\n",
    "for i in range(len(fwhm)):\n",
    "    idx = np.where(Xfwhm[i,:]!=0)[0]\n",
    "    fwhm[i] = np.median(Xfwhm[i,idx])\n",
    "    idx = np.where(Xsky[i,:]!=0)[0]\n",
    "    sky[i] = np.median(Xsky[i,idx])\n",
    "    trace[i] = np.polyval(data['traces'][target][i],Xfwhm.shape[1]/2)\n",
    "    \n",
    "eparams = np.c_[data['t'] - 2457000, data['Z'], data[\"deltas\"][f\"{target}_final\"], fwhm, sky, trace]\n",
    "eparams = eparams[i_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Time', 'Airmass', 'Delta_Wav', 'FWHM', 'Sky_Flux', 'Trace_Center']\n",
    "df_eparams = pd.DataFrame(eparams, columns=columns)\n",
    "\n",
    "df_eparams[\"Instrument\"] = [\"MAGELLAN\"] * df_eparams.shape[0]\n",
    "df_eparams.to_csv(\n",
    "    \"juliet/hatp23_test/GP_lc_regressors.dat\",\n",
    "    sep=' ',\n",
    "    index=False,\n",
    "    header=False,\n",
    "    float_format=\"%.10f\",\n",
    ")\n",
    "df_eparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_theme('paper')\n",
    "# data = {\n",
    "#     #'Transit 1':'160621',\n",
    "#     #'Transit 2':'170609',\n",
    "#     #'Transit 3':'180603',\n",
    "#     #'Transit 4':'180620',\n",
    "#     'Transit 5':'180821',\n",
    "# }\n",
    "data = {\"Transit 1\":\"190313\"}\n",
    "PCA = 'PCA_2'\n",
    "\n",
    "for i, (transit, date) in enumerate(data.items()):\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 1,\n",
    "        sharex=True,\n",
    "        gridspec_kw={'height_ratios':[5, 1]}\n",
    "    )\n",
    "    dirpath = f\"/home/mango/ACCESS_notebook/Projects/HATP26b/data_detrending/hp26_{date}_r/white-light\"\n",
    "    ax_top, ax_bottom = axes\n",
    "    # get t0, P\n",
    "    fpath_t0 = f'{dirpath}/results.dat'\n",
    "    df_results = pd.read_table(\n",
    "        fpath_t0, sep='\\s+', index_col=0, escapechar='#',\n",
    "    )\n",
    "    t0, P = df_results.loc[['t0', 'P']]['Value']\n",
    "\n",
    "    fpath = f\"{dirpath}/{PCA}/detrended_lc.dat\"\n",
    "    \n",
    "    # Detrended data\n",
    "    t, detflux, detflux_err, model = np.genfromtxt(fpath, unpack=True)\n",
    "    phase = utils.get_phases(t, P, t0)\n",
    "    ax_top.plot(phase*24, detflux, 'o', label=transit,c=f\"C{i}\", mew=0) \n",
    "    c_dark = 0.5*np.array(mpl.colors.to_rgba(f'C{i}')[:3])\n",
    "    \n",
    "    # Full model\n",
    "    t_full, f_full = np.genfromtxt(f'{dirpath}/full_model_{PCA}.dat').T\n",
    "    phase_full = utils.get_phases(t_full, P, t0)\n",
    "    p = ax_top.plot(phase_full*24, f_full, color=c_dark, lw=2, zorder=10)\n",
    "    \n",
    "    # Residuals\n",
    "    c = 2 * c_dark\n",
    "    resids = detflux - model\n",
    "    ax_bottom.plot(phase*24, resids*1e6, '.', mew=0, color=c)\n",
    "    trans = transforms.blended_transform_factory(\n",
    "            ax_bottom.transData, ax_bottom.transAxes\n",
    "        )\n",
    "    ax_bottom.axhline(0, lw=2, c=c_dark)\n",
    "\n",
    "    rms = np.std(resids*1e6)\n",
    "    ax_bottom.annotate(\n",
    "        f\"{int(rms)}\",\n",
    "        xy=(1.02*phase[-1]*24, 0.55),\n",
    "        xycoords=trans,\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "    #ax_top.legend(loc=4, frameon=True)\n",
    "    #ax_top.set_title(title)\n",
    "    #fig.text(0.5, 0, 'Phase (hours)', ha='left')\n",
    "    ax_bottom.set_xlabel('Phase (hours)')\n",
    "    #ax_top.set_xlim(-1., 1.)\n",
    "    #ax_top.set_ylim(0.990, 1.002)\n",
    "    #ax_bottom.set_ylim(-2000, 2000)\n",
    "    ax_top.set_ylabel(\"Normalized flux\")\n",
    "    ax_bottom.set_ylabel('ppm')\n",
    "    #ax.xaxis.set_major_locator(HOURS)\n",
    "    #ax.set_xlim(2.457561e6 + 0.76, 2.457561e6 + 0.92)\n",
    "    #ax.set_ylim(0.982, 1.00143)\n",
    "\n",
    "    fig.set_size_inches(FIG_WIDE)\n",
    "    fig.tight_layout()\n",
    "    title = transit.lower().replace(' ', '_') + '_detr_wlcs'\n",
    "    #utils.savefig(f'projects/HATP23b/paper/figures/detrended_wlcs/{title}.pdf')\n",
    "\n",
    "    #plt.savefig(\"/Users/mango/Desktop/wlc_gpts_ut160621.png\", dpi=250, bbox_inches=\"tight\")\n",
    "    #utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/det_lc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(phase, detflux, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, f = np.genfromtxt(f'{dirpath}/full_model_ut180821.dat').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(fpaths[0], sep='\\s+', index_col=0).loc['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = './data/data_detrending/HATP23'\n",
    "fpaths = sorted(glob.glob(f'{dirpath}/hp*/white-light/results.dat'))\n",
    "\n",
    "ps = []\n",
    "for fpath in fpaths[1:]:\n",
    "    print(fpath)\n",
    "    p = pd.read_table(fpath, sep='\\s+', index_col=0).loc['p'].to_numpy()\n",
    "    ps.append(p)\n",
    "ps = np.array(ps)\n",
    "\n",
    "p_means, p_us, p_ds = ps.T\n",
    "\n",
    "p_uncs=np.max([p_us, p_ds], axis=0)\n",
    "np.average(p_means, weights=1/p_uncs**2)\n",
    "#np.mean(p_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_means, p_us, p_ds = ps.T\n",
    "\n",
    "p_uncs=np.max([p_us, p_ds], axis=0)\n",
    "np.average(p_means, weights=1/p_uncs**2)\n",
    "#np.mean(p_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{p_means[0]:.9f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/data_detrending/HATP23_c'\n",
    "binsize = 'custom'\n",
    "data_dict = {\n",
    "    'Transit 1':\n",
    "    f'{data_dir}/hp23b_160621_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 2':\n",
    "    f'{data_dir}/hp23b_170609_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 3':\n",
    "    f'{data_dir}/hp23b_180603_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 4':\n",
    "    f'{data_dir}/hp23b_180620_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 5':\n",
    "    f'{data_dir}/hp23b_180821_{binsize}/white-light/results.dat',\n",
    "}\n",
    "\n",
    "# truths from Sada and Ramon (2016) + GAIA DR2\n",
    "with open(f'{data_dir}/truth.json', 'rb') as f:\n",
    "    parameters = json.load(f)\n",
    "\n",
    "parameters['d'] = {\n",
    "    'symbol': '$\\delta$',\n",
    "    'truth': [0.1113**2 * 1e6, 0.001**2 * 1e6, 0.0009**2 * 1e6],\n",
    "    'definition': 'transit depth (ppm)'\n",
    "}\n",
    "\n",
    "# holds results from each transit\n",
    "df_results = {}\n",
    "for transit, fpath in data_dict.items():\n",
    "    df_results[transit] = pd.read_table(fpath, sep='\\s+',index_col='Variable')\n",
    "    df_results[transit].loc['t0']['Value'] -= 2450000\n",
    "    p_val, p_u, p_d = df_results[transit].loc['p'].values.T\n",
    "    df_results[transit].loc['d'] = p_val**2 * 1e6, p_u**2 * 1e6, p_d**2 * 1e6\n",
    "    \n",
    "def write_latex(param, df):\n",
    "    v, vu, vd = df.loc[param]\n",
    "    return f'{v:.5f}^{{+{vu:.5f}}}_{{-{vd:.5f}}}'\n",
    "\n",
    "# Create summary table of all transits\n",
    "results_dict = {}\n",
    "results_dict['parameter'] = [p[\"symbol\"] for p in parameters.values()]\n",
    "#results_dict['definition'] = [p[\"definition\"] for p in parameters.values()]\n",
    "for transit, results in df_results.items():\n",
    "    results_dict[transit] = []\n",
    "    for param, param_info in parameters.items():\n",
    "        results_dict[transit].append(write_latex(param, results))\n",
    "        \n",
    "results_table = pd.DataFrame(results_dict)\n",
    "results_table#.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"Transit 1\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.weighted_mean_uneven_errors(*get_params_and_uncs(\"p\"))[0]**2*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.weighted_mean_uneven_errors(*get_params_and_uncs(\"d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_params_and_uncs(\"p\")[0]**2*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_params_and_uncs(\"d\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transits = [f\"Transit {i}\" for i in range(1, 6)]\n",
    "\n",
    "def get_params_and_uncs(param):\n",
    "    ps, p_us, p_ds = [], [], []\n",
    "    for transit in transits:\n",
    "        df_transit = df_results[transit]\n",
    "        p, p_u, p_d = df_transit.loc[param][[\"Value\", \"SigmaUp\", \"SigmaDown\"]]\n",
    "        ps.append(p)\n",
    "        p_us.append(p_u)\n",
    "        p_ds.append(p_d)\n",
    "    return np.array(ps), np.array(p_us), np.array(p_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.constants as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_theme('paper')\n",
    "# Load\n",
    "data_dir = \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_detrending\"\n",
    "#data_dir = \"data/data_detrending/WASP43\"\n",
    "#data_dir = 'data/data_detrending/HATP23_c'\n",
    "binsize = 'custom'\n",
    "fpath_truths = f'{data_dir}/truth.json'\n",
    "with open(fpath_truths) as f:\n",
    "    params_dict = json.load(f)\n",
    "\n",
    "def write_latex(row):\n",
    "    v, vu, vd = row\n",
    "    return f'{v:.4f}^{{+{vu:.4f}}}_{{-{vd:.4f}}}'\n",
    "\n",
    "data_dict = {\n",
    "    \"Transit 1\":\n",
    "    f\"{data_dir}/hp26_190313_c/white-light/BMA_posteriors.pkl\",\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "data_dict = {\n",
    "    'Transit 1':\n",
    "    f'{data_dir}/w43_150224/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    'Transit 2':\n",
    "    f'{data_dir}/w43_150309/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    'Transit 3':\n",
    "    f'{data_dir}/w43_170410/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    'Transit 4':\n",
    "    f'{data_dir}/w43_180603/white-light/BMA_posteriors.pkl',\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "data_dict = {\n",
    "    'Transit 1':\n",
    "    f'{data_dir}/hp23b_160621_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    'Transit 2':\n",
    "    f'{data_dir}/hp23b_170609_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    'Transit 3':\n",
    "    f'{data_dir}/hp23b_180603_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    'Transit 4':\n",
    "    f'{data_dir}/hp23b_180620_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    'Transit 5':\n",
    "    f'{data_dir}/hp23b_180821_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    \n",
    "    #'$aR_\\mathrm{s} + (\\mathrm{b}, \\mathrm{p})$':\n",
    "    #f'{data_dir}/out_ab/HATP23b/hp23b_180603_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    #\n",
    "    #'$aR_\\mathrm{s} + (r_1, r_2)$':\n",
    "    #f'{data_dir}/out_ar/HATP23b/hp23b_180603_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    #\n",
    "    #'$\\\\rho_\\mathrm{s} + (\\mathrm{b}, \\mathrm{p})$':\n",
    "    #f'{data_dir}/out_rb/HATP23b/hp23b_180603_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    #\n",
    "    #'$\\\\rho_\\mathrm{s} + (r_1, r_2)$':\n",
    "    #f'{data_dir}/out_rr/HATP23b/hp23b_180603_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "    #\n",
    "    #'py2':\n",
    "    #f'{data_dir}/out_py2/HATP23b/hp23b_180603_{binsize}/white-light/BMA_posteriors.pkl',\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Plot\n",
    "fig = None # Initialize figure\n",
    "for t_i, (transit_name, fpath) in enumerate(data_dict.items()):\n",
    "    # Load\n",
    "    data = utils.pkl_load(fpath)\n",
    "    if 'rho' not in data.keys():\n",
    "        G = c.G.cgs.value\n",
    "        aR = data['aR']\n",
    "        P = data['P']\n",
    "        data['rho'] = 3.0*np.pi * aR**3 / (G*(P*86400.0)**2)\n",
    "    samples = pd.DataFrame(data)[params_dict.keys()]\n",
    "    if 'WASP43' not in data_dir:\n",
    "        samples['t0'] -= 2450000\n",
    "    \n",
    "    mins = np.min(np.array([samples.min(), samples.min()]), axis=0)\n",
    "    maxs = np.min(np.array([samples.max(), samples.max()]), axis=0)\n",
    "    ranges = list(zip(mins, maxs))\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = utils.plot_corner(\n",
    "        samples,\n",
    "        fpath_truths,\n",
    "        c=f'C{t_i}',\n",
    "        fig=fig,\n",
    "        ranges=ranges,\n",
    "    )\n",
    "    \n",
    "    # Custom titles\n",
    "    ps = [0.16, 0.5, 0.84]\n",
    "    ps_strs = [f'{p*100:.0f}%' for p in ps]\n",
    "    df_stats = samples.describe(percentiles=ps).loc[ps_strs]\n",
    "    df_latex = pd.DataFrame(columns=df_stats.columns)\n",
    "    df_latex.loc['p'] = df_stats.loc['50%']\n",
    "    df_latex.loc['p_u'] = df_stats.loc['84%'] - df_stats.loc['50%']\n",
    "    df_latex.loc['p_d'] = df_stats.loc['50%'] - df_stats.loc['16%']\n",
    "    \n",
    "    titles = df_latex.apply(write_latex, axis=0).to_list()\n",
    "    \n",
    "    ndim = samples.shape[1]\n",
    "    axes = np.array(fig.axes).reshape((ndim, ndim))\n",
    "    for i, (param_key, param_data) in enumerate(params_dict.items()):\n",
    "        ax = axes[i, i] # select 1d hist\n",
    "        ax.annotate(\n",
    "            f'${titles[i]}$',\n",
    "            xy=(0.0, 1.1 + t_i/4.0),\n",
    "            xycoords='axes fraction',\n",
    "            ha=\"left\",\n",
    "            color=f'C{t_i}',\n",
    "            fontsize=14,\n",
    "        )\n",
    "    \n",
    "# Label custom titles\n",
    "for i, (param_key, param_data) in enumerate(params_dict.items()):\n",
    "    ax = axes[i, i] # select 1d hist\n",
    "    ax.annotate(\n",
    "        f'{param_data[\"symbol\"]}',\n",
    "        xy=(0.5, 1.1 + (t_i+1)/4.0),\n",
    "        xycoords='axes fraction',\n",
    "        ha='center',\n",
    "        #color='w',\n",
    "    )  \n",
    "    p_mean, p_u, p_d = param_data[\"truth\"] # Unpack mean +/-\n",
    "    ax.axvspan(p_mean - p_u, p_mean + p_u, alpha=0.75, color='grey',\n",
    "               lw=0, zorder=0)\n",
    "    ax.axvline(p_mean, color='w')\n",
    "\n",
    "# True values\n",
    "with open(fpath_truths) as f:\n",
    "    params_dict = json.load(f)\n",
    "truths = [v['truth'][0] for v in params_dict.values()]\n",
    "ndim = len(truths)\n",
    "for yi in range(ndim):\n",
    "    for xi in range(yi):\n",
    "        ax = axes[yi, xi]\n",
    "        ax.plot(truths[xi], truths[yi], \"P\", ms=10, mec=\"grey\", mfc=\"w\")\n",
    "\n",
    "# Custom legend\n",
    "handles, labels = [], []\n",
    "for transit_name in list(data_dict.keys()):\n",
    "    dummy, = plt.plot([], [], 'D', ms=12, mfc='none', mew=2, label=transit_name)\n",
    "    handles.append(dummy)\n",
    "    labels.append(transit_name)\n",
    "fig.legend(handles, labels, loc=1, fontsize=18, ncol=len(data_dict)+1)  \n",
    "\n",
    "fig.set_size_inches(14, 14)\n",
    "# Save\n",
    "#utils.savefig(f\"projects/HATP23b/paper/figures/detrended_wlcs_corners/corner_wlcs.pdf\")\n",
    "#title = data_dir.split('/')[-1]\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/wlc_corner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantiles(dist,alpha = 0.68, method = 'median'):\n",
    "    \"\"\" \n",
    "    get_quantiles function\n",
    "    DESCRIPTION\n",
    "        This function returns, in the default case, the parameter median and the error% \n",
    "        credibility around it. This assumes you give a non-ordered \n",
    "        distribution of parameters.\n",
    "    OUTPUTS\n",
    "        Median of the parameter,upper credibility bound, lower credibility bound\n",
    "    \"\"\"\n",
    "    ordered_dist = dist[np.argsort(dist)]\n",
    "    param = 0.0 \n",
    "    # Define the number of samples from posterior\n",
    "    nsamples = len(dist)\n",
    "    nsamples_at_each_side = int(nsamples*(alpha/2.)+1)\n",
    "    if(method == 'median'):\n",
    "        med_idx = 0 \n",
    "        if(nsamples%2 == 0.0): # Number of points is even\n",
    "            med_idx_up = int(nsamples/2.)+1\n",
    "            med_idx_down = med_idx_up-1\n",
    "            param = (ordered_dist[med_idx_up]+ordered_dist[med_idx_down])/2.\n",
    "            return param,ordered_dist[med_idx_up+nsamples_at_each_side],\\\n",
    "                   ordered_dist[med_idx_down-nsamples_at_each_side]\n",
    "        else:\n",
    "            med_idx = int(nsamples/2.)\n",
    "            param = ordered_dist[med_idx]\n",
    "            return param,ordered_dist[med_idx+nsamples_at_each_side],\\\n",
    "                   ordered_dist[med_idx-nsamples_at_each_side]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1.2128867\n",
    "sigma = 0.0000002\n",
    "x1 = 1.21288287\n",
    "x2 = mu + 2*sigma\n",
    "\n",
    "z1 = ( x1 - mu ) / sigma\n",
    "z2 = ( x2 - mu ) / sigma\n",
    "\n",
    "x = np.arange(z1, z2, 0.001) # range of x in spec\n",
    "x_all = np.arange(-10, 10, 0.001) # entire range of x, both in and out of spec\n",
    "# mean = 0, stddev = 1, since Z-transform was calculated\n",
    "y = sp.stats.norm.pdf(x, 0, 1)\n",
    "y2 = sp.stats.norm.pdf(x_all, 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.axvline(z1)\n",
    "ax.axvline(z2)\n",
    "ax.plot(x_all,y2)\n",
    "ax.fill_between(x, y, 0, alpha=0.3, color='b')\n",
    "#ax.fill_between(x_all, y2, 0, alpha=0.1)\n",
    "#ax.set_xlim([-4,4])\n",
    "ax.set_xlabel('# of Standard Deviations Outside the Mean')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('Normal Gaussian Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.212880 - 3*0.000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [0.16, 0.5, 0.84]\n",
    "ps_strs = [f'{p*100:.0f}%' for p in ps]\n",
    "df_stats = samples_new.describe(percentiles=ps).loc[ps_strs]\n",
    "df_latex = pd.DataFrame(columns=df_stats.columns)\n",
    "df_latex.loc['p'] = df_stats.loc['50%']\n",
    "df_latex.loc['p_u'] = df_stats.loc['84%'] - df_stats.loc['50%']\n",
    "df_latex.loc['p_d'] = df_stats.loc['50%'] - df_stats.loc['16%']\n",
    "df_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_quantiles(samples_new['inc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = sorted(glob.glob('data/data_detrending/HATP23_*'))\n",
    "\n",
    "for data_dir in data_dirs:\n",
    "    print(data_dir)\n",
    "    fpaths = glob.glob(f'{data_dir}/hp*/white-light/PCA_*/posteriors_trend_george.pkl')\n",
    "\n",
    "    for fpath in sorted(fpaths):\n",
    "        lnZ = utils.pkl_load(fpath)['lnZ']\n",
    "        print(lnZ)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max common PCA = 2\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Read in data\n",
    "##############\n",
    "data = {\"Transit 1\":\"190313\"}\n",
    "# data = {\n",
    "#     'Transit 1':'160621',\n",
    "#     'Transit 2':'170609',\n",
    "#     'Transit 3':'180603',\n",
    "#     'Transit 4':'180620',\n",
    "#     'Transit 5':'180821',\n",
    "# }\n",
    "#binsize = \"custom\"\n",
    "for title, date in data.items():\n",
    "    #GPT_dir = f\"data/data_detrending/HATP23_c/hp23b_{date}_{binsize}\"\n",
    "    GPT_dir = \"./data/data_detrending/HATP26_25nm/hp26_190313_25nm\"\n",
    "    def wbin_num(fpath):\n",
    "        # Extracts <num> from fpath = .../wbin<num>/...\n",
    "        tokens = fpath.split('/')\n",
    "        for token in tokens:\n",
    "            if \"wbin\" in token: # Do the extraction\n",
    "                bin_str = token.split(\"wbin\")[-1]\n",
    "                bin_num = int(bin_str)\n",
    "                return(bin_num)\n",
    "    wbin_paths = sorted(glob.glob(f'{GPT_dir}/wavelength/wbin*'), key=wbin_num)\n",
    "    PCA_list = []\n",
    "    for wbin_path in wbin_paths:\n",
    "        PCA_paths = glob.glob(f'{wbin_path}/PCA*')\n",
    "        PCAs = [path.split('/')[-1] for path in PCA_paths]\n",
    "        PCA_list.append(PCAs)\n",
    "\n",
    "    common_PCAs = set(PCA_list[0])\n",
    "    for s in PCA_list[1:]:\n",
    "        common_PCAs.intersection_update(s)\n",
    "\n",
    "    PCA_max = max(common_PCAs, key=lambda s: int(s.split('_')[-1]))\n",
    "    PCA_num = int(PCA_max.split('_')[-1])\n",
    "    print(f'max common PCA = {PCA_num}')\n",
    "\n",
    "    # getting t0 from WLC data\n",
    "    def get_result(fpath, key=\"t0\", unc=True):\n",
    "        data = np.genfromtxt(fpath, encoding=None, dtype=None)\n",
    "        for line in data:\n",
    "            if key in line: \n",
    "                if unc: return line\n",
    "                else: return line[1]\n",
    "\n",
    "        print(f\"'{key}' not found. Check results.dat file.\")        \n",
    "    fpath = f\"{GPT_dir}/white-light/results.dat\"\n",
    "    t0 = float(get_result(fpath, key=\"t0\", unc=False))\n",
    "    P = float(get_result(fpath, key=\"P\", unc=False))\n",
    "\n",
    "    # Get wavelength bins\n",
    "    fpath = f\"{GPT_dir}/transpec.csv\"\n",
    "    wbins = np.loadtxt(fpath, skiprows=1, usecols=[0, 1], delimiter=',')\n",
    "\n",
    "    # Glob doesn't automatically sort, but instead follows your local filesystem's \n",
    "    # rules, which can be very system dependent. \n",
    "    # To avoid potential cross-platform issues, I just sort based on an explicit\n",
    "    # rule that is passed to `sorted`. In this case, the rule is: \n",
    "    # sort based on the <num> part in wbin<num> of each file path.\n",
    "    dirpath = f\"{GPT_dir}/wavelength\"\n",
    "    detrended_files = f\"{dirpath}/wbin*/PCA_{PCA_num}/detrended_lc.dat\"\n",
    "    fpaths = sorted(glob.glob(detrended_files), key=wbin_num)\n",
    "\n",
    "    # Store final data in <# of wavelength bins> x <length of timeseries> arrays \n",
    "    detfluxes, models, resids = [], [], []\n",
    "    for fpath in fpaths:\n",
    "        time, detflux, detfluxerr, model = np.loadtxt(fpath, unpack=True)\n",
    "        detfluxes.append(detflux)\n",
    "        models.append(model)\n",
    "        resids.append(detflux - model + 1)\n",
    "    detfluxes = np.array(detfluxes).T\n",
    "    models = np.array(models).T\n",
    "    resids = np.array(resids).T\n",
    "    phase = utils.get_phases(time, P, t0)\n",
    "    time_rel = phase*24 #(time - t0)*24 # Convert to hours\n",
    "\n",
    "    ###################################\n",
    "    # Plot detrended flux and residuals\n",
    "    ###################################\n",
    "    # Plot configs\n",
    "    import matplotlib.patheffects as PathEffects\n",
    "    N = detfluxes.shape[1] # number of wavelength bins\n",
    "    colors = np.array(sns.color_palette(\"Spectral_r\", N))\n",
    "\n",
    "    offset = 0.014 # 0.01 # spacing betweem binned lcs\n",
    "    # Optional bins to highlight\n",
    "    species = {\n",
    "        'Na I-D':5892.9,\n",
    "        #'Hα':6564.6,\n",
    "        'K I':7682.0,\n",
    "        'Na I-8200':8189.0\n",
    "    }\n",
    "    scatter_plot_kwargs = {\n",
    "        \"marker\":\".\", \n",
    "        \"lw\":0, \n",
    "        \"mew\":0, # Make non-zero to show marker outlines\n",
    "        #\"mec\":'k', # Won't show if `mew`=0\n",
    "    }\n",
    "    annotate_kwargs = {\n",
    "        \"fontsize\":8, \n",
    "        \"horizontalalignment\":'right',\n",
    "        \"path_effects\":[PathEffects.withStroke(linewidth=1, foreground=\"k\")],\n",
    "    }\n",
    "    annotate_rms_kwargs = {\n",
    "        \"fontsize\":8, \n",
    "        \"horizontalalignment\":'left',\n",
    "        \"path_effects\":[PathEffects.withStroke(linewidth=1, foreground=\"k\")],\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 11), sharex=True, sharey=True)\n",
    "    ax_left, ax_right = axes.flatten()\n",
    "\n",
    "    # detrended flux\n",
    "    ax_left.set_title('Detrended flux')\n",
    "    p_det = utils.plot_binned(ax_left, time_rel, detfluxes, wbins, offset, colors, \n",
    "                              plot_kwargs=scatter_plot_kwargs, models=models)\n",
    "\n",
    "    # residual flux\n",
    "    ax_right.set_title('Residuals')\n",
    "    baselines = np.ones_like(resids)\n",
    "    p_res = utils.plot_binned(\n",
    "        ax_right,\n",
    "        time_rel,\n",
    "        resids,\n",
    "        wbins,\n",
    "        offset,\n",
    "        colors, \n",
    "        plot_kwargs=scatter_plot_kwargs,\n",
    "        models=baselines,\n",
    "        annotate=True,\n",
    "        annotate_kwargs=annotate_kwargs,\n",
    "        annotate_rms_kwargs=annotate_rms_kwargs,\n",
    "        species=species,\n",
    "    ) \n",
    "\n",
    "    ax_left.set_ylabel(\"Normalized flux + offset\")\n",
    "    fig.text(0.47, 0, 'Phase (hours)', ha='left')\n",
    "\n",
    "    ax_left.set_xlim(-1, 1)\n",
    "\n",
    "    fig.set_size_inches(8, 8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    #plt.savefig(\"/Users/mango/Desktop/wlc_access.png\", dpi=250, bbox_inches=\"tight\")\n",
    "\n",
    "    title = title.lower().replace(' ', '_') + '_detr_blcs'\n",
    "    #utils.savefig(f\"projects/HATP23b/paper/figures/detrended_blcs/{title}.pdf\")\n",
    "    utils.savepng(\"/home/mango/Projects/HATP26b/journal/blcs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmission spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transit 1\n",
      "offsets: [0.89061188]\n",
      "offsets (% mean wlc depth): [0.01685872]\n",
      "mean WLC depth: 5282.796590975366 11.006123230623828\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'G'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d8097a41a7b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0mRp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_wlc_depth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mRs\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0mMp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.35\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupiterMass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mMp\u001b[0m  \u001b[0;34m/\u001b[0m\u001b[0mRp\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rs (Rsun):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rsun\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rp (Rj):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rjupiter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'G'"
     ]
    }
   ],
   "source": [
    "set_theme(\"dark\")\n",
    "#data_dir = 'data/data_detrending/HATP23_c'\n",
    "#data_dir = \"data/data_detrending/WASP43\"\n",
    "data_dir = \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_detrending\"\n",
    "binsize = 'custom'\n",
    "if data_dir.split('/')[-1].split('_')[-1] == 's':\n",
    "    binsize = 'species'\n",
    "\"\"\"\n",
    "data_dict = {\n",
    "    #'Transit 1':{\n",
    "    #'path_tspec':f'{data_dir}/hp23b_160621_{binsize}/transpec.csv',\n",
    "    #'path_wlc':f'{data_dir}/hp23b_160621_{binsize}/white-light/results.dat',\n",
    "    #},\n",
    "    \n",
    "    'Transit 1':f'{data_dir}/hp23b_160621_{binsize}',\n",
    "    \n",
    "    'Transit 2':f'{data_dir}/hp23b_170609_{binsize}',\n",
    "    \n",
    "    'Transit 3':f'{data_dir}/hp23b_180603_{binsize}',\n",
    "    \n",
    "    'Transit 4':f'{data_dir}/hp23b_180620_{binsize}',\n",
    "    \n",
    "    'Transit 5':f'{data_dir}/hp23b_180821_{binsize}',\n",
    "    \n",
    "    #'$aR_\\mathrm{s} + (\\mathrm{b}, \\mathrm{p})$':f'{data_dir}/out_ab/HATP23b/hp23b_180603_{binsize}',\n",
    "    \n",
    "    #'$\\\\rho_\\mathrm{s} + (\\mathrm{b}, \\mathrm{p})$':f'{data_dir}/out_rb/HATP23b/hp23b_180603_{binsize}',\n",
    "    \n",
    "    #'py2':f'{data_dir}/out_py2/HATP23b/hp23b_180603_{binsize}',\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# data_dict = {\n",
    "#     #\"Transit 1\":f\"{data_dir}/w43_150224\",\n",
    "#     \"Transit 2\":f\"{data_dir}/w43_150309\",\n",
    "#     \"Transit 3\":f\"{data_dir}/w43_170410\",\n",
    "#     \"Transit 4\":f\"{data_dir}/w43_180603\",\n",
    "# }\n",
    "\n",
    "data_dict = {\n",
    "    \"Transit 1\":f\"{data_dir}/hp26_190313_c5\"\n",
    "}\n",
    "\n",
    "def write_latex(row):\n",
    "    v, vu, vd = row\n",
    "    return f'{v:.3f}^{{+{vu:.3f}}}_{{-{vd:.3f}}}'\n",
    "def write_latex_wav(row):\n",
    "    wav_d, wav_u = row\n",
    "    return f'{wav_d:.1f} - {wav_u:.1f}'\n",
    "\n",
    "# Use first entry for wavelength\n",
    "transit_0, dirpath_0 = next(iter(data_dict.items()))\n",
    "fpath = f'{dirpath_0}/transpec.csv'\n",
    "df_wavs = pd.read_csv(fpath)[['Wav_d', 'Wav_u']]\n",
    "wav = (df_wavs['Wav_u'] + df_wavs['Wav_d']) / 2.0\n",
    "\n",
    "depth_wlc_stats = []\n",
    "tspec_stats = []\n",
    "for transit, dirpath in data_dict.items():\n",
    "    print(transit)\n",
    "    # WLCs\n",
    "    fpath = f'{dirpath}/white-light/results.dat'\n",
    "    #p_stats = pd.read_table(fpath, sep='\\s+', escapechar='#').query('` Variable` == \"p\"')\n",
    "    p_stats = pd.read_table(fpath, sep='\\s+', escapechar='#').query('Variable == \"p\"')\n",
    "    p, p_u, p_d = p_stats[['Value', 'SigmaUp', 'SigmaDown']].values[0].T\n",
    "    wlc_depth = p**2 * 1e6\n",
    "    wlc_depth_u = p_u**2 * 1e6\n",
    "    wlc_depth_d = p_d**2 * 1e6\n",
    "    depth_wlc_stats.append([wlc_depth, wlc_depth_u, wlc_depth_d])\n",
    "    \n",
    "    # Tspec\n",
    "    fpath = f'{dirpath}/transpec.csv'\n",
    "    df_tspec = pd.read_csv(fpath)[\n",
    "        ['Depth (ppm)', 'Depthup (ppm)', 'DepthDown (ppm)']\n",
    "    ]\n",
    "        \n",
    "    if transit == \"Transit 1\" and binsize==\"custom\":\n",
    "        tspec, tspec_u, tspec_d = df_tspec.values.T\n",
    "    else:\n",
    "        tspec, tspec_u, tspec_d = df_tspec.values[1:-1, :].T\n",
    "        \n",
    "    tspec_stats.append([tspec, tspec_u, tspec_d])\n",
    "    \n",
    "# Compute offset\n",
    "depth_wlc_stats = np.array(depth_wlc_stats)\n",
    "depth_wlc, depth_wlc_u, depth_wlc_d = depth_wlc_stats.T\n",
    "mean_wlc_depth, mean_wlc_depth_unc = utils.weighted_mean_uneven_errors(\n",
    "    depth_wlc, depth_wlc_u, depth_wlc_d\n",
    ")\n",
    "\n",
    "wlc_offsets = depth_wlc - mean_wlc_depth\n",
    "print(f\"offsets: {wlc_offsets}\")\n",
    "print(f\"offsets (% mean wlc depth): {wlc_offsets*100/mean_wlc_depth}\")\n",
    "tspec_stats = np.array(tspec_stats) # transits x (depth, u, d) x wavelength\n",
    "tspec_stats[:, 0, :] -= wlc_offsets[np.newaxis].T\n",
    "\n",
    "tspec_depths = tspec_stats[:, 0, :]\n",
    "tspec_us = tspec_stats[:, 1, :]\n",
    "tspec_ds = tspec_stats[:, 2, :]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.axhline(mean_wlc_depth, color=\"darkgrey\", zorder=0, ls='--')\n",
    "\n",
    "# Species\n",
    "species = {\n",
    "    'Na I-D':5892.9, \n",
    "    #'Hα':6564.6, \n",
    "    'K I_avg':7682.0, \n",
    "    'Na I-8200_avg':8189.0\n",
    "}\n",
    "[ax.axvline(wav, ls='--', lw=0.5, color='grey', zorder=0) for name, wav in species.items()]\n",
    "\n",
    "tspec_tables = {} # Each entry will hold Table(Transit, Depth, Up , Down)\n",
    "# For combining into latex later\n",
    "#colors = ['C0', 'C2', 'C4']\n",
    "#for transit, tspec, tspec_d, tspec_u, c in zip(\n",
    "for transit, tspec, tspec_d, tspec_u, in zip(\n",
    "    data_dict.keys(),\n",
    "    tspec_depths,\n",
    "    tspec_ds,\n",
    "    tspec_us,\n",
    "    #colors,\n",
    "):\n",
    "    ax.errorbar(\n",
    "        wav,\n",
    "        tspec,\n",
    "        #xerr=[wav - df_wavs['Wav_d'], df_wavs['Wav_u'] - wav],\n",
    "        yerr=[tspec_d, tspec_u],\n",
    "        fmt='o',\n",
    "        alpha=1.0,\n",
    "        mew=0,\n",
    "        label=transit,\n",
    "        barsabove=False,\n",
    "        #color=c,\n",
    "    )\n",
    "    \n",
    "    data_i = {}\n",
    "    data_i['Depth (ppm)'] = tspec\n",
    "    data_i['Depthup (ppm)'] = tspec_u\n",
    "    data_i['DepthDown (ppm)'] = tspec_d\n",
    "    df = pd.DataFrame(data_i)\n",
    "    tspec_tables[transit] = df\n",
    "\n",
    "tspec_combined = []\n",
    "tspec_combined_unc = []\n",
    "tspec_combined_max = []\n",
    "tspec_combined_unc_max = []\n",
    "for i in range(len(tspec_stats[0, 0, :])):\n",
    "    tspec_comb, tspec_comb_unc = utils.weighted_mean_uneven_errors(\n",
    "        tspec_stats[:, 0, i],\n",
    "        tspec_stats[:, 1, i],\n",
    "        tspec_stats[:, 2, i],\n",
    "    )\n",
    "    tspec_combined.append(tspec_comb)\n",
    "    tspec_combined_unc.append(tspec_comb_unc)\n",
    "        \n",
    "    # single errorbar way\n",
    "    uncs_max = np.max([tspec_stats[:, 1, i], tspec_stats[:, 2, i]], axis=0)\n",
    "    weights = 1 / uncs_max**2\n",
    "    tspec_comb_max = np.average(tspec_stats[:, 0, i], weights=weights)\n",
    "    tspec_comb_max_unc = utils.weighted_err(uncs_max)\n",
    "    tspec_combined_max.append(tspec_comb_max)\n",
    "    tspec_combined_unc_max.append(tspec_comb_max_unc)\n",
    "\n",
    "# Combined\n",
    "# tspec_combined = np.array(tspec_combined)\n",
    "# tspec_combined_unc = np.array(tspec_combined_unc)\n",
    "# p = ax.errorbar(\n",
    "#     wav,\n",
    "#     tspec_combined,\n",
    "#     yerr=tspec_combined_unc,\n",
    "#     c='w',\n",
    "#     mec='k',\n",
    "#     fmt='o',\n",
    "#     zorder=10,\n",
    "#     label=\"combined\",\n",
    "#     ecolor='k',\n",
    "#     lw=4,\n",
    "# )\n",
    "#fpath = \"projects/HATP23b/data/tspec/tspec_combined.dat\"\n",
    "#fpath = \"/home/mango/Desktop/yea.dat\"\n",
    "#np.savetxt(fpath, np.c_[wav/1e4, tspec_combined*1e-6, tspec_combined_unc*1e-6])\n",
    "\n",
    "# Write to table\n",
    "tspec_table = pd.DataFrame()\n",
    "tspec_table['Wavelength (Å)'] = df_wavs.apply(write_latex_wav, axis=1)\n",
    "# Transmission spectra\n",
    "for transit, df_tspec in tspec_tables.items():\n",
    "    tspec_table[transit] = df_tspec.apply(write_latex, axis=1)\n",
    "data = np.array([tspec_combined, tspec_combined_unc]).T\n",
    "df_combined = pd.DataFrame(data, columns=[\"Combined\", \"Unc\"])\n",
    "def write_latex(row):\n",
    "    v, v_unc = row\n",
    "    return f'{v:.3f} \\pm {v_unc:.3f}'\n",
    "tspec_table['Combined'] = df_combined.apply(write_latex, axis=1)\n",
    "ax.legend(ncol=6, loc=1, fontsize=12, frameon=True)\n",
    "#ax.set_xlim(5106.55, 9362.45)\n",
    "#ax.set_ylim(9_000, 17_000)\n",
    "\n",
    "# Inset plots\n",
    "if binsize==\"species\":\n",
    "    margin=10\n",
    "    utils.plot_inset(\n",
    "        ax,\n",
    "        species_slc=slice(0,5),\n",
    "        box_lims=[0.3, 0.15, 0.2, 0.2],\n",
    "        lims=(5780.40-margin, 6005.40+margin),\n",
    "    )\n",
    "    utils.plot_inset(\n",
    "        ax,\n",
    "        species_slc=slice(5,10),\n",
    "        box_lims=[0.38, 0.65, 0.2, 0.2],\n",
    "        lims=(7657-margin, 7707+margin),\n",
    "    )\n",
    "    utils.plot_inset(\n",
    "        ax,\n",
    "        species_slc=slice(10,15),\n",
    "        box_lims=[0.78, 0.15, 0.2, 0.2],\n",
    "        lims=(8089-margin, 8289+margin),\n",
    "    )\n",
    "\n",
    "title = \"tspec\"\n",
    "if binsize == \"species\":\n",
    "    title = \"tspec_species\"\n",
    "    # Plot inset for species fig\n",
    "    # [x0, y0, width, height] relative to lower left corner\n",
    "    # Shortcut to zoom in on last instrument\n",
    "    #axins.set_xlim(p.get_xlim())\n",
    "    #axins.set_ylim(p.get_ylim())\n",
    "    #plot_model(axins, model, model_kwargs=model_kwargs, fill_kwargs=fill_kwargs)\n",
    "    \n",
    "#ax.set_title(\"ACCESS Magellan/IMACS Transit Spectra of HAT-P-23\")\n",
    "ax.set_xlabel('Wavelength (Å)')\n",
    "ax.set_ylabel(r'Transit Depth (ppm)')\n",
    "fig.set_size_inches(FIG_WIDE)\n",
    "fig.tight_layout()\n",
    "#utils.savefig(f'projects/HATP23b/paper/figures/tspec/{title}.pdf')\n",
    "#utils.savepng('/home/mango/Projects/HATP26b/journal/figures/tspec')\n",
    "\n",
    "print(\"mean WLC depth:\", mean_wlc_depth, mean_wlc_depth_unc)\n",
    "Rs = 0.96 * u.solRad\n",
    "Rp = np.sqrt(mean_wlc_depth*1e-6 * Rs**2)\n",
    "Mp = 1.35 * u.jupiterMass\n",
    "gp = c.G * Mp  /Rp**2\n",
    "print(\"Rs (Rsun):\", Rs.to(\"Rsun\"))\n",
    "print(\"Rp (Rj):\", Rp.to(\"Rjupiter\"))\n",
    "print(\"gp (m/s^2):\", gp.to(\"m/s^2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transit 1\n",
    "offsets: [-0.28737234]\n",
    "offsets (% mean wlc depth): [-0.00514713]\n",
    "mean WLC depth: 5583.157185935618 12.071465288531083\n",
    "Rs (Rsun): 0.96 solRad\n",
    "Rp (Rj): 0.69803261828029 jupiterRad\n",
    "gp (m/s^2): 68.67487561900433 m / s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f'{dirpath}/white-light/results.dat'\n",
    "p_stats = pd.read_table(fpath, sep='\\s+', escapechar='#').query('` Variable` == \"p\"')\n",
    "p_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f'{dirpath}/transpec.csv'\n",
    "df_tspec = pd.read_csv(fpath)\n",
    "df_tspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transit, table in tspec_tables.items():\n",
    "    mi = min(table[['Depthup (ppm)', 'DepthDown (ppm)']].min(axis=0)),\n",
    "    ma = max(table[['Depthup (ppm)', 'DepthDown (ppm)']].max(axis=0)),\n",
    "    print(transit, mi, ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspec_table.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max = np.array([tspec_combined_max, tspec_combined_unc_max]).T\n",
    "df_combined_max = pd.DataFrame(data_max, columns=[\"Combined Max\", \"Unc Max\"])\n",
    "def write_latex(row):\n",
    "    v, v_unc = row\n",
    "    return f'{v:.5f} \\pm {v_unc:.5f}'\n",
    "#df_combined.apply(write_latex, axis=1)\n",
    "df_combined_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    '#Wlow':df_wavs['Wav_d'],\n",
    "    'Wup':df_wavs['Wav_u'],\n",
    "    'Depth':df_combined['Combined'],\n",
    "    'ErrUp':df_combined['Unc'],\n",
    "    'ErrLow':df_combined['Unc'],\n",
    "    'Instrument':'Magellan/IMACS',\n",
    "    'Offset?':'NO',\n",
    "}\n",
    "df_retrieval = pd.DataFrame(data)\n",
    "df_retrieval.to_csv(\n",
    "    'projects/HATP23b/data/retrieval/tspec_hp23_c.csv',\n",
    "    index=False,\n",
    ")\n",
    "df_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"xo/HATP23/ut180603/wlc\"\n",
    "lc = np.load(f\"{dirpath}/lc.npy\")\n",
    "map_soln = utils.pkl_load(f\"{dirpath}/map_soln.pkl\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "ax.plot(map_soln[\"light_curve\"] + 1.0020465216919012, label=\"MAP\")\n",
    "ax.plot(lc[:, 1], '.', label=dirpath)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"xo/HATP23/ut180603/wlc_bak/lc.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"xo/HATP23/ut180603/wlc_bak\"\n",
    "fig, axes = utils.plot_exoplanet_WLC(dirpath, figsize=FIG_LARGE)\n",
    "#fig.suptitle(dirpath)\n",
    "#plt.savefig(\"/Users/mango/Desktop/HATP23_ut180603.png\", dpi=250, bbox_inches=\"tight\")\n",
    "#plt.savefig(\"/Users/mango/Desktop/w43_ut180603_xo_wlc.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"xo/HATP23/ut1806\"\n",
    "fig, axes, df_samples = utils.plot_corner(\n",
    "    dirpath=dirpath,\n",
    "    title=\"\"\" \"truth\" values from Sada & Ramón-Fox (2016) \"\"\",\n",
    "    #title=\"\"\" \"truth\" values from Weaver et al. (2020) \"\"\",\n",
    ")\n",
    "\n",
    "#xlims = np.array([[ax.get_xlim() for ax in ax_row] for ax_row in axes])\n",
    "#ylims = np.array([[ax.get_ylim() for ax in ax_row] for ax_row in axes])\n",
    "\n",
    "\"\"\"\n",
    "for ax_row, xlim_row, ylim_row in zip(axes, xlims, ylims):\n",
    "    for ax, xlim, ylim in zip(ax_row, xlim_row, ylim_row):\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "\"\"\"\n",
    "        \n",
    "#plt.savefig(f\"{dirpath}/corner.png\", dpi=250, bbox_inches=\"tight\")\n",
    "#plt.savefig(f\"/Users/mango/Desktop/corner_hp23_ut180603.png\", dpi=250, bbox_inches=\"tight\")\n",
    "plt.savefig(f\"/Users/mango/Desktop/hp23_ut180603_xo_wlc_corner.png\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"xo/WASP43/ut180603/wl_bak/trace.pkl\"\n",
    "trace = utils.pkl_load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_traces = [trace[\"trace\"][i]['r'] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = sorted(glob.glob(\"xo/WASP43/ut180603/binned_free_rho_star/wbin_*/detrended.csv\"))\n",
    "columns = {\"flux\", \"lc_model\"}\n",
    "DT_list = [dt.fread(fpath, columns=columns) for fpath in fpaths]\n",
    "phase = dt.fread(fpaths[0], columns={\"phase\"}).to_numpy()\n",
    "fluxes = dt.cbind(*[DT[\"flux\"] for DT in DT_list]).to_numpy()\n",
    "models = dt.cbind(*[DT[\"lc_model\"] for DT in DT_list]).to_numpy()\n",
    "resids = fluxes - models + 1.\n",
    "#df_list = [DT.to_pandas() for DT in DT_list]\n",
    "#fluxes = dt.cbind(*DT_list).to_numpy()\n",
    "#models = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_tepspec = \"data/data_reductions/WASP43/ut180603_a9_24_noflat_LBR/LCs_w43_kreidberg.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(11, 11), sharex=True, sharey=True)\n",
    "ax_left, ax_right = axes\n",
    "N_bins = fluxes.shape[1]\n",
    "wbins = utils.pkl_load(fpath_tepspec)[\"wbins\"]\n",
    "wbins = np.array(wbins)\n",
    "idxs_used = phase\n",
    "\n",
    "# Plot binned light curves\n",
    "p_left = utils.plot_binned(\n",
    "        ax_left,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=wbins, \n",
    "        offset=0.01,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0},\n",
    "        models=models,\n",
    "    )\n",
    "p_left.set_title(\"detrended flux - exoplanet\")\n",
    "\n",
    "# TODO: Try detrending with `exoplanet`\n",
    "# Plot residuals\n",
    "p_right = utils.plot_binned(\n",
    "        ax_right,\n",
    "        idxs_used,\n",
    "        resids,\n",
    "        utc=False,\n",
    "        bins=wbins, \n",
    "        offset=0.01,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0},\n",
    "        annotate=True,\n",
    "        annotate_kwargs={\"fontsize\":10, \"ha\":\"center\"},\n",
    "    )\n",
    "p_right.set_title(\"Residuals\")\n",
    "\n",
    "ax_left.set_ylabel(\"Normalized flux + offset\")\n",
    "fig.text(0.5, 0, 'Time (JD)', ha='left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/mango/Desktop/binned_xo.png\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmission spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = sorted(glob.glob(\"xo/WASP43/ut180603/binned_free_rho_star/wbin_*/summary.csv\"))\n",
    "columns = slice(0, 3) #{\"C0\", \"mean\", \"sd\"}\n",
    "DT_list = [dt.fread(fpath, columns=columns)[dt.f[\"C0\"] == \"r\", :][:, [\"mean\",\"sd\"]] for fpath in fpaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspec = dt.rbind(*DT_list).to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "ax.errorbar(range(len(df[\"Rp/Rs\"])), df[\"Rp/Rs\"], yerr=df[\"Rp/RsErrUp\"], fmt='o',\n",
    "            label=\"GPTS (square_exp)\", color='b', alpha=0.5)\n",
    "ax.errorbar(range(len(tspec[:, 0])), tspec[:, 0], yerr=tspec[:, 1], fmt='o',\n",
    "            label=\"exoplanet-quick (matern)\", color='C1', alpha=0.5)\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_ylabel(r\"$R_p/R_s$\")\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"/Users/mango/Desktop/tspec.png\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\"flux\", \"lc_model\"}\n",
    "DT_list = [dt.fread(fpath, columns=columns) for fpath in fpaths]\n",
    "phase = dt.fread(fpaths[0], columns={\"phase\"}).to_numpy()\n",
    "fluxes = dt.cbind(*[DT[\"flux\"] for DT in DT_list]).to_numpy()\n",
    "models = dt.cbind(*[DT[\"lc_model\"] for DT in DT_list]).to_numpy()\n",
    "resids = fluxes - models + 1.\n",
    "#df_list = [DT.to_pandas() for DT in DT_list]\n",
    "#fluxes = dt.cbind(*DT_list).to_numpy()\n",
    "#models = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(1e-6*12_945 * 1.152**2) * 9.731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common directory\n",
    "dirpath = \"projects/HATP23b/data\"\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"generic_local_001_056_0001_000.dat\":\"normal scattering, clear\",\n",
    "    \"generic_local_001_056_0001_001.dat\":\"normal scattering, cloudy\",\n",
    "    \"generic_local_001_056_1100_000.dat\":\"enhanced scattering, clear\",\n",
    "    \"generic_local_001_056_1100_001.dat\":\"enhanced scattering, cloudy\",\n",
    "    \"hatp23b_solar_noTiOVO.dat\":\"cold (no TiO/VO)\",\n",
    "    \"generic_detr.dat\":\"detr\",\n",
    "}\n",
    "\n",
    "# Plot models\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "for model, l in models.items():\n",
    "    fpath = f\"{dirpath}/forward_model/{model}\"\n",
    "    wav_model, flux_model = np.loadtxt(fpath, unpack=True)\n",
    "    ax.plot(wav_model*1e4, flux_model*1e6, label=l)\n",
    "\n",
    "# Load data\n",
    "data = \"tspec/tspec_combined.dat\"\n",
    "fpath = f\"{dirpath}/{data}\"\n",
    "wav_data, flux_data, flux_data_err = np.loadtxt(fpath, unpack=True)\n",
    "\n",
    "# Plot data\n",
    "ax.plot(wav_data, flux_data, 'o')\n",
    "ax.errorbar(\n",
    "    wav_data*1e4,\n",
    "    flux_data*1e6,\n",
    "    yerr=flux_data_err*1e6,\n",
    "    c='w',\n",
    "    mec='k',\n",
    "    fmt='o',\n",
    "    zorder=10,\n",
    "    label=\"this study\",\n",
    "    ecolor='k',\n",
    "    lw=2,\n",
    ")\n",
    "\n",
    "ax.legend(fontsize=12, ncol=3)\n",
    "ax.set_xlim(5106.55, 9362.45)\n",
    "ax.set_ylim(9_000, 17_000)\n",
    "ax.set_xlabel(\"Wavelength (Å)\")\n",
    "ax.set_ylabel(\"Transit depth (ppm)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exoretrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme('paper')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "########\n",
    "# Models\n",
    "########\n",
    "dirpath = \"data/retrievals/HATP23_wider\"\n",
    "model_key_name = \"Na+K+TiO (haze)\"\n",
    "models = {\n",
    "    \"K (clear)\":f\"{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_NoHaze_fitR0_K\",\n",
    "    f\"{model_key_name}\":f\"{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_Haze_fitR0_Na_K_TiO\",\n",
    "}\n",
    "\n",
    "instruments = {\n",
    "    'Magellan_IMACS': {\n",
    "        'c': 'w', 'mec':'k', 'fmt': 'o', \n",
    "        'ecolor':'k', \n",
    "        #'lw':4,\n",
    "        'label': 'Magellan/IMACS',\n",
    "        'zorder':10,\n",
    "    },\n",
    "}\n",
    "colors = [\"grey\", \"C5\"]\n",
    "for i, (model_name, model_path) in enumerate(models.items()):\n",
    "    # Plot model\n",
    "    model = ascii.read(f'{model_path}/retr_model.txt')\n",
    "    model_kwargs = {'label':model_name, \"alpha\":1}\n",
    "    fill_kwargs = {'alpha':0.125, \"color\":colors[i]}\n",
    "    _, p = utils.plot_model(\n",
    "        ax, model, model_kwargs=model_kwargs, fill_kwargs=fill_kwargs,\n",
    "    )\n",
    "    \n",
    "    # Plot sampled points\n",
    "    for instrument in instruments.keys():\n",
    "        instr_sampled = ascii.read(f'{model_path}/retr_model_sampled_{instrument}.txt')\n",
    "        sampled_kwargs = {'marker':'s', 'color':p[0].get_color(), 'lw':0, \"alpha\":1}\n",
    "        utils.plot_instrument(\n",
    "            ax, instr_sampled=instr_sampled, sampled_kwargs=sampled_kwargs,\n",
    "        )\n",
    "\n",
    "#############\n",
    "# Instruments\n",
    "#############\n",
    "# Dict of instr_kwargs\n",
    "instruments = {\n",
    "    'Magellan_IMACS': {\n",
    "        'c': 'w', 'mec':'k', 'fmt': 'o', \n",
    "        'ecolor':'k', \n",
    "        #'lw':4,\n",
    "        'label': 'Magellan/IMACS',\n",
    "        'zorder':10,\n",
    "    },\n",
    "}\n",
    "model_path = models['K (clear)'] # Instrument sampling identical for all models\n",
    "for instrument, instr_kwargs in instruments.items():\n",
    "    instr = ascii.read(f'{model_path}/retr_{instrument}.txt')\n",
    "    instrument_name = instrument.replace('_', '/')\n",
    "    utils.plot_instrument(\n",
    "        ax, instr, sampled=False, instr_kwargs=instr_kwargs,\n",
    "    )\n",
    "    \n",
    "####################\n",
    "# Annotate Delta lnZ\n",
    "####################\n",
    "fpath = f'{models[model_key_name]}/retrieval.pkl'\n",
    "fpath_flat = f'{models[\"K (clear)\"]}/retrieval.pkl'\n",
    "DlnZ, DlnZ_unc, lnZ, lnZ_unc = utils.get_Delta_lnZ(fpath, fpath_flat)\n",
    "s = f\"$\\Delta \\ln(Z) = {DlnZ:.2f} \\pm {DlnZ_unc:.2f}$\"\n",
    "ax.annotate(s, (0.02, 0.05), xycoords='axes fraction')\n",
    "\n",
    "\"\"\"\n",
    "# Plot inset\n",
    "axins = ax.inset_axes([0.5, 0.5, 0.5, 0.5])\n",
    "# Shortcut to zoom in on last instrument\n",
    "p = plot_instrument(axins, instr, instr_sampled, instr_kwargs=configs, sampled_kwargs=sampled_kwargs)\n",
    "axins.set_xlim(p.get_xlim())\n",
    "axins.set_ylim(p.get_ylim())\n",
    "plot_model(axins, model, model_kwargs=model_kwargs, fill_kwargs=fill_kwargs)\n",
    "ax.indicate_inset_zoom(axins, alpha=1.0, edgecolor='w')\n",
    "\"\"\"\n",
    "\n",
    "ax.set_xlim(0.5, 0.95)\n",
    "#ax.set_ylim(25000, 27000)\n",
    "ax.set_ylim(11_000, 16_000)\n",
    "\n",
    "ax.set_xlabel(r'Wavelength $(\\mu\\mathrm{m})$')\n",
    "ax.set_ylabel('Transit depth (ppm)')\n",
    "ax.legend(loc=1, ncol=3)\n",
    "\n",
    "#########\n",
    "# Species\n",
    "#########\n",
    "species = {\n",
    "    'Na I-D':5892.9, \n",
    "    #'Hα':6564.6, \n",
    "    'K I_avg':7682.0, \n",
    "    'Na I-8200_avg':8189.0\n",
    "}\n",
    "[ax.axvline(wav/10000, lw=0.5, ls='--', color='grey', zorder=0) for name, wav in species.items()]\n",
    "\n",
    "#ax.annotate(f\"Python 2\", (0.05, 0.9), xycoords='axes fraction')\n",
    "\n",
    "#plt.savefig('/Users/mango/Desktop/exoretrievals_py2.png', dpi=250, bbox_inches='tight')\n",
    "\n",
    "fig.set_size_inches(FIG_WIDE)\n",
    "#fig.tight_layout()\n",
    "#utils.savefig('projects/HATP23b/paper/figures/retrievals/retrieval.pdf')\n",
    "plt.savefig(f'/Users/mango/Desktop/tspec_haze_mid.pdf', bbox_inches='tight')\n",
    "#plt.savefig(f'../retrieval/kreidberg/{species}/tspec/retr_{basename}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "p = ax.fill_between([1,2,3,4,5], [5,5,5,5,5], [1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.get_facecolor()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath.split('E1_')[-1].split('FitP0')[0] + dirpath.split('/')[-1].split('R0_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "def test(x, y, **kwargs): \n",
    "    return x + y\n",
    "    \n",
    "plt.plot([1,2,3], **{})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirpath = 'data/retrievals/HATP23'\n",
    "species = [\"Na\", \"K\", \"TiO\", \"Na_K\", \"Na_TiO\", \"K_TiO\", \"Na_K_TiO\"]\n",
    "\n",
    "data_dict = {\n",
    "    sp:{\n",
    "        'clear':f'{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_NoHaze_fitR0_{sp}',\n",
    "        'haze':f'{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_Haze_fitR0_{sp}',\n",
    "        'spot':f'{dirpath}/HATP23_E1_Het_FitP0_NoClouds_NoHaze_fitR0_{sp}',\n",
    "        'spot+haze':f'{dirpath}/HATP23_E1_Het_FitP0_NoClouds_Haze_fitR0_{sp}',\n",
    "    }\n",
    "    for sp in species\n",
    "}\n",
    "\n",
    "#dirpath_flat = f'{dirpath}/HATP23_E1_NoHet_FlatLine'\n",
    "dirpath_flat = f'{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_NoHaze_fitR0_K'\n",
    "fpath_flat = f'{dirpath_flat}/retrieval.pkl'\n",
    "data = {}\n",
    "for species, model_info in data_dict.items():\n",
    "    data[species] = {}\n",
    "    for model, dirpath in model_info.items():\n",
    "        fpath = f'{dirpath}/retrieval.pkl'\n",
    "        Delta_lnZ, Delta_lnZ_unc, lnZ, lnZ_unc = utils.get_Delta_lnZ(\n",
    "            fpath, fpath_flat\n",
    "        )\n",
    "        data[species][model] = utils.write_latex2(\n",
    "            Delta_lnZ, Delta_lnZ_unc)\n",
    "#         data[species][model] = (lnZ, lnZ_unc)\n",
    "\n",
    "df_retr = pd.DataFrame(data)\n",
    "df_retr#.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retr.min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme(\"paper\")\n",
    "fpath = 'data/retrievals/HATP23/HATP23_E1_Het_FitP0_NoClouds_NoHaze_fitR0_Na_K_TiO/retrieval.pkl'\n",
    "post = utils.pkl_load(fpath)\n",
    "\n",
    "df = pd.DataFrame(post['samples']) \n",
    "\n",
    "params = {\n",
    "    'logP0':r'$\\log P_0$',\n",
    "    'T':r'$T_\\mathrm{p}$',\n",
    "#     'logH2O':r'$\\log \\mathrm{H}_2\\mathrm{O}$',\n",
    "    'logNa':r'$\\log \\mathrm{Na}$',\n",
    "    'logK':r'$\\log \\mathrm{K}$',\n",
    "    'logTiO':r'$\\log \\mathrm{TiO}$',\n",
    "    'f':r'$f$',\n",
    "}\n",
    "\n",
    "if \"_Haze\" in fpath:\n",
    "    params['loga'] = r'$\\log a$'\n",
    "    params['gamma'] = r'$\\gamma_\\mathrm{haze}$'\n",
    "\n",
    "if \"_Het\" in fpath:\n",
    "    params['Tocc'] = r'$T_\\mathrm{star}$'\n",
    "    params['Thet'] = r'$T_\\mathrm{het}$'\n",
    "    params['Fhet'] = r'$f_\\mathrm{het}$'\n",
    "\n",
    "df_params = df[params.keys()]\n",
    "\n",
    "corner_kwargs = {\n",
    "    'show_titles':True,\n",
    "}\n",
    "hist_kwargs = {'histtype':'stepfilled', 'lw':2, 'density':True,}\n",
    "fig, axes = utils.plot_corner(\n",
    "    df_params,\n",
    "    params=params,\n",
    "    c=f'C5',\n",
    "    corner_kwargs=corner_kwargs,\n",
    "    hist_kwargs=hist_kwargs,\n",
    ")\n",
    "\n",
    "fig.set_size_inches(18, 18)\n",
    "\n",
    "utils.savefig('projects/HATP23b/paper/figures/retrievals/retrieval_corner.pdf')\n",
    "#plt.savefig(f'../retrieval/kreidberg/{species}/corner/corner_{basename}.pdf', bbox_inches='tight')\n",
    "#plt.savefig(f'/Users/mango/Desktop/corner_{source}_all.pdf', bbox_inches='tight')\n",
    "#plt.savefig(f\"/Users/mango/Desktop/corner_test.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHIMERA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmisson Spectrum File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, h = fits.getdata(fpath, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puts transmission into format that can be read by CHIMERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../WASP43/retrieval/kreidberg/GP_kr_noffsH.dat\"\n",
    "df_exoretrievals = pd.read_csv(fpath, sep='\\s+')\n",
    "df_exoretrievals.rename({\"#Wlow\":\"Wlow\"}, axis=1, inplace=True)\n",
    "\n",
    "# create CHIMERA datatable\n",
    "df_CHIMERA = pd.DataFrame()\n",
    "\n",
    "# add mid-wavelength column\n",
    "wav_low_AA, wav_up_AA = df_exoretrievals[[\"Wlow\", \"Wup\"]].T.values\n",
    "df_CHIMERA[\"wl [um]\"] = (wav_low_AA + wav_up_AA)/2 * 1e-4\n",
    "df_CHIMERA[\"wl [um]\"] = df_CHIMERA[\"wl [um]\"].apply(lambda x: f\"{x:.18e}\")\n",
    "\n",
    "# add (Rp/Rstar)^2\n",
    "depth = df_exoretrievals[\"Depth\"]\n",
    "df_CHIMERA[\"(Rp/Rstar)^2\"] = depth*1e-6\n",
    "df_CHIMERA[\"(Rp/Rstar)^2\"] = df_CHIMERA[\"(Rp/Rstar)^2\"].apply(lambda x: f\"{x:.18e}\")\n",
    "\n",
    "\n",
    "# add (Rp/Rstar)^2 err\n",
    "errup_ppm, errlow_ppm = df_exoretrievals[[\"ErrUp\", \"ErrLow\"]].T.values\n",
    "err_ppm = (errlow_ppm + errlow_ppm)/2\n",
    "df_CHIMERA[\"(Rp/Rstar)^2 err\"] = err_ppm * 1e-6\n",
    "df_CHIMERA[\"(Rp/Rstar)^2 err\"] = df_CHIMERA[\"(Rp/Rstar)^2 err\"].apply(lambda x: f\"{x:.18e}\")\n",
    "\n",
    "# write to txt file\n",
    "fpath = \"/Users/mango/Desktop/w43b_trans.txt\"\n",
    "\n",
    "with open(fpath, 'w') as file:\n",
    "    header = \"#Weaver et al. 2019\\n#wl [um]\\t\\t\\t(Rp/Rstar)^2\\t\\t(Rp/Rstar)^2 err\\n\"\n",
    "    file.write(header)\n",
    "    df_CHIMERA.to_csv(file, sep=\" \", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpath = \"../data/WASP43/test/spectral_samples_trans_pmn_wfc3_cc.pic\"\n",
    "fpath = \"../data/WASP43/test/pmn_transmission_wfc3_cc.pic\"\n",
    "data = utils.pkl_load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:, 0])"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "884px",
    "width": "296px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "623px",
    "left": "176px",
    "top": "133px",
    "width": "165px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
