{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.patheffects as PathEffects\n",
    "#import juliet\n",
    "import seaborn as sns\n",
    "import mplcyberpunk\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import corner\n",
    "import pathlib\n",
    "import itertools\n",
    "import batman\n",
    "import json\n",
    "import re\n",
    "\n",
    "from astropy.io import fits, ascii\n",
    "from astropy import constants as c\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "from matplotlib.collections import LineCollection\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from PyAstronomy.pyTiming import pyPeriod\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Display and backend\n",
    "#####################\n",
    "FIG_LARGE = (11, 8) # Default plot figure size for large figures\n",
    "FIG_WIDE = (11, 5)    \n",
    "%config InlineBackend.figure_format = \"retina\" # Crisp retina display on macs\n",
    "# Qt5 backend for interactive plotting\n",
    "%matplotlib qt5 \n",
    "\n",
    "################\n",
    "# Theme settings\n",
    "################\n",
    "def set_theme(notebook_mode=\"dark\"):\n",
    "    plt.style.use(\"default\") # Reset to default before layering on any changes\n",
    "    sns.set(palette=\"Paired\", color_codes=True, context=\"talk\")\n",
    "\n",
    "    if notebook_mode.lower() == \"paper\":\n",
    "        sns.set_style('ticks')\n",
    "        params = {\n",
    "            # xticks\n",
    "            \"xtick.top\":False,\n",
    "            \"xtick.direction\":\"out\",\n",
    "            \"xtick.major.size\":5,\n",
    "            \"xtick.minor.visible\":False,\n",
    "\n",
    "            # yticks\n",
    "            \"ytick.right\":False,\n",
    "            \"ytick.direction\":\"out\",\n",
    "            \"ytick.major.size\":5,\n",
    "            \"ytick.minor.visible\":False,\n",
    "\n",
    "            # pallete\n",
    "            \"axes.prop_cycle\":mpl.cycler(color=[\n",
    "                \"#fdbf6f\", # Yellow\n",
    "                \"#ff7f00\", # Orange\n",
    "                \"#a6cee3\", # Cyan\n",
    "                \"#1f78b4\", # Blue\n",
    "                \"#956cb4\", # Purple\n",
    "                \"#029e73\", # Green\n",
    "                \"#c44e52\", # Red\n",
    "            ]),\n",
    "        }\n",
    "        #sns.set_style(\"ticks\", tick_params)\n",
    "        #params = {\n",
    "        #    \"axes.formatter.limits\":(-3, 7),\n",
    "        #    #\"axes.spine.right\":False,\n",
    "        #    \"xtick.major.size\":2,\n",
    "        #}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "    elif notebook_mode.lower() == \"dark\":\n",
    "        sns.set(palette=\"colorblind\", color_codes=True, context=\"talk\")\n",
    "        plt.style.use(\"cyberpunk\")\n",
    "        # Re-order color cycle\n",
    "        params = {\n",
    "            \"axes.prop_cycle\":mpl.cycler(color=[\n",
    "                \"#F5D300\", # Yellow\n",
    "                'r',       # Red\n",
    "                \"#08F7FE\", # Cyan\n",
    "                \"b\", # Blue\n",
    "                \"g\", # Green\n",
    "            ]),\n",
    "        }\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "    else:\n",
    "        plt.style.use(\"default\")\n",
    "    \n",
    "HOURS = mdates.HourLocator() # For UTC plots with ticks every hour\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "set_theme(\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.palettes.color_palette('muted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#f5d300', '#d55e00', '#08f7fe', '#0173b2', '#029e73']\n"
     ]
    }
   ],
   "source": [
    "print(sns.palettes.color_palette().as_hex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Teq(Ts=None, albedo=None, aRs=None, Rs=None, a=None):\n",
    "    if (aRs is None):\n",
    "        return Ts * (1 - albedo)**0.25 * (0.5*Rs/a)**0.5\n",
    "    else:\n",
    "        return Ts * (1 - albedo)**0.25 * (0.5/aRs)**0.5\n",
    "\n",
    "def get_H(\n",
    "    Tp=None,\n",
    "    Mp=None,\n",
    "    Rp=None,\n",
    "    Ts=None,\n",
    "    Rs=None,\n",
    "    mu=None,\n",
    "    albedo=None,\n",
    "    aRs=None,\n",
    "    a=None,\n",
    "    RpRs=None,\n",
    "):\n",
    "    if isinstance(Mp, u.Quantity):\n",
    "        G_Mp = c.G * Mp\n",
    "    else:\n",
    "        # Default to Jupiter mass\n",
    "        G_Mp = c.GM_jup * Mp\n",
    "    if (RpRs is None) and (Rp is not None):\n",
    "        g = G_Mp / Rp**2\n",
    "    else:\n",
    "        g = G_Mp / (RpRs**2 * Rs**2)\n",
    "    if Tp is None:\n",
    "        Tp = get_Teq(Ts=Ts, albedo=0, aRs=aRs, Rs=Rs, a=a)\n",
    "    return c.k_B * Tp / (mu * g), Tp\n",
    "\n",
    "def get_depth(Tp=None,\n",
    "              Mp=None,\n",
    "              Rp=None,\n",
    "              Ts=None,\n",
    "              Rs=None,\n",
    "              mu=None,\n",
    "              H=None,\n",
    "              aRs=None,\n",
    "              a=None,\n",
    "              RpRs=None,\n",
    "):\n",
    "    if H is None:\n",
    "        H, Tp = get_H(Tp=Tp, Mp=Mp, Rp=Rp, Ts=Ts, Rs=Rs, mu=mu, aRs=aRs, a=a, RpRs=RpRs)\n",
    "    if RpRs is None:\n",
    "        Delta_D =  2 * H * Rp / Rs**2, H, Tp\n",
    "    else:\n",
    "        Delta_D =  2 * H * RpRs/Rs, H, Tp\n",
    "    return Delta_D\n",
    "\n",
    "D, H, Tp = get_depth(\n",
    "    #Rp=1.036*u.R_jup,\n",
    "    mu=2*u.Da,\n",
    "    Mp=1.97*u.M_jup,\n",
    "    Ts=5734*u.K,\n",
    "    Rs=1.1858169*u.R_sun,\n",
    "    RpRs = 0.1113,\n",
    "    aRs=4.26,\n",
    "    #a=0.01528*u.AU,\n",
    "    #Tp=1440*u.K,\n",
    ")\n",
    "\n",
    "print(f'Tp = {Tp.cgs:.3f}')\n",
    "print(f'H = {H.to(\"km\"):.3f},')\n",
    "n = 5\n",
    "print(f'Delta D = {n * D.cgs * 1e6:.3f} ppm at {n} scale heights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = glob.glob(\"./data/HATP23/ut160720/ift*c1.fits\")\n",
    "#fpaths = glob(\"./data/HATP23/ut160621/ift*c1.fits\")\n",
    "\n",
    "object_names = []\n",
    "for fpath in fpaths:\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        header = fits.open(f, de)[0].header\n",
    "        name = header[\"OBJECT\"]\n",
    "        object_names.append(name)\n",
    "        \n",
    "len(object_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config:\n",
    "images_dir = '../atmospheres_meeting/figs'\n",
    "result_grid_filename = '/Users/mango/Desktop/grid.png'\n",
    "result_figsize_resolution = 40 # 1 = 100px\n",
    "\n",
    "images_list = glob.glob(f\"{images_dir}/*raw_lc.png\")\n",
    "\n",
    "# Create plt plot:\n",
    "fig, axes = plt.subplots(5, 2, figsize=(8, 40))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img in zip(axes, images_list):\n",
    "    plt_image = plt.imread(img)\n",
    "    plt_image = np.array(Image.open(img))\n",
    "    ax.imshow(plt_image, aspect=\"auto\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=.0, hspace=.0)\n",
    "#plt.savefig(\"/Users/mango/Desktop/grid.png\", dpi=250, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Projects/HATP26b/data/ut190313\"\n",
    "date = data_dir.split('/')[-1]\n",
    "fpaths = np.array(sorted(glob.glob(f'{data_dir}/ift*c1.fits')))\n",
    "filenames = []\n",
    "objects = []\n",
    "slits = []\n",
    "airmasses = []\n",
    "file_info = {}\n",
    "for fpath in tqdm(fpaths):\n",
    "    header = utils.fits_header(fpath)\n",
    "    #header = fits.getheader(fpath)\n",
    "    #print(header['OBJECT'])\n",
    "    if header is not None:\n",
    "        file_info[header['FILENAME'].split('c')[0]] = {\n",
    "            'UT Date':         header['UT-DATE'],\n",
    "            'UT Time (start)': header['UT-TIME'],\n",
    "            'UT Time (end)':   header['UT-END'],\n",
    "            'Exposure (s)':    header['EXPTIME'],\n",
    "            'Object':          header['OBJECT'],\n",
    "            'Exposure type':   header['EXPTYPE'],\n",
    "            'RA':              header['RA'],\n",
    "            'Dec':             header['DEC'],\n",
    "            'Mask':            header['SLITMASK'],\n",
    "            'Filter':          header['FILTER'],\n",
    "            'Disperser':       header['DISPERSR'],\n",
    "            'Airmass':         header['AIRMASS'],\n",
    "            'Seeing':          header['G-SEEING'],\n",
    "            'Binning':         header['Binning'],\n",
    "            'Speed':           header['Speed'],\n",
    "            'Subrastr':           header['SUBRASTR'],\n",
    "            #'File':            header['FILENAME'],\n",
    "        }\n",
    "    \n",
    "df_file_info = pd.DataFrame.from_dict(file_info, orient=\"index\")\n",
    "df_file_info.index.name = \"root\"\n",
    "#sci_mask = df_file_info['Object'].str.contains('science')\n",
    "#df_file_info[sci_mask]#.info()\n",
    "#date = data_dir.split('/')[-1]\n",
    "df_file_info.to_csv(\n",
    "    f\"{data_dir}/../logs/night_log_{date}.csv\",\n",
    "    #index_label = \"root\",\n",
    ")\n",
    "#df_file_info.to_csv(f'./projects/HATP26b/night_log_{date}.txt', index=False)\n",
    "#df_file_info.query('Object.str.contains(\"sci\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f\"{data_dir}/../logs/night_log_{date}.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sci = df_file_info[df_file_info[\"Object\"].str.contains(\"sci\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sci.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM = df_sci['Airmass'].to_numpy()\n",
    "idxs = range(len(AM))\n",
    "idx_min = np.argmin(AM)\n",
    "\n",
    "def plot_ann(ax, x, y):\n",
    "    ax.plot(x, y, 'ro')\n",
    "    ax.annotate(f'{y:.3f}', xy=(x, y+0.02))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.plot(np.array(phase)*24, AM[idxs_used])\n",
    "#plot_ann(ax, idxs[0], AM[0])\n",
    "#plot_ann(ax, idxs[idx_min], np.min(AM))\n",
    "#plot_ann(ax, idxs[-1], AM[-1])\n",
    "\n",
    "ax.set_xlabel('Phase')\n",
    "ax.set_ylabel('Airmass')\n",
    "ax.set_title('HAT-P-26 science frames')\n",
    "\n",
    "#utils.savefig('projects/HATP26b/journal/figures/data_inspection/airmass.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/HATP23'\n",
    "data_dict = {\n",
    "    'transit_1':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut160621',\n",
    "            'ift':'1116',\n",
    "            'sky_ap':20,\n",
    "        },\n",
    "#\n",
    "    'transit_2':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut170609',\n",
    "            'ift':'0183',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "    'transit_3':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut180603',\n",
    "            'ift':'0076',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "    'transit_4':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut180620',\n",
    "            'ift':'4444',\n",
    "            #'ift':'4050',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "    'transit_5':\n",
    "        {\n",
    "            'path':f'{data_dir}/ut180821',\n",
    "            'ift':'0200',\n",
    "            #'ift':'0000',\n",
    "            'sky_ap':25,\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/HATP26'\n",
    "data_dict = {\n",
    "    'transit_1':\n",
    "    {\n",
    "        'path':f'{data_dir}/ut190313',\n",
    "        'ift':'1310',\n",
    "        'sky_ap':25,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transit, transit_info in data_dict.items():\n",
    "    dirpath = transit_info['path']\n",
    "    fname = f\"ift{transit_info['ift']}\"\n",
    "    sky_ap = transit_info['sky_ap']\n",
    "    fig, im = utils.plot_chips(\n",
    "        dirpath, fname, vmin=0, vmax=2_000, sky_ap=25, spec_ap=12,\n",
    "    )\n",
    "    #fig.set_size_inches(8, 11)\n",
    "    #fig.colorbar(im, ax=axes.flatten(), aspect=30, label='counts')\n",
    "    #fig.subplots_adjust(wspace=0.1, hspace=0.01)\n",
    "    #plt.savefig(\"/Users/mango/Desktop/test.png\", bbox_inches=\"tight\")\n",
    "    plt.savefig(\n",
    "       f'projects/HATP26b/journal/figures/{transit}_raw_frame.png',\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=250\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(8, 11))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    im = ax.imshow(np.random.rand(2048, 1024))\n",
    "    if i <= 3:\n",
    "        ax.set_title('title')\n",
    "    else:\n",
    "        ax.set_xlabel('title')\n",
    "    \n",
    "#cbar_ax = fig.add_axes([0.91, 0, 0.05, 0.7])\n",
    "#fig.colorbar(im, cax=cbar_ax)\n",
    "#fig.colorbar(im, ax=axes.ravel().tolist(), aspect=30, label='counts')\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chips Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_info[df_file_info[\"Object\"].str.contains(\"sci\")].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath + fnames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.switch_backend(\"Agg\")\n",
    "dirpath = \"/home/mango/cfa/mercedes/ACCESS/data/HATP26/ut190313\"\n",
    "fnames = df_file_info[df_file_info[\"Object\"].str.contains(\"sci\")].index.values\n",
    "for fname in tqdm(fnames):\n",
    "    fig, axes = utils.plot_chips(dirpath, fname, vmin=0, vmax=1_000, sky_ap=25)\n",
    "    fpath = f\"{dirpath}/../pngs/sci_mask_{fname}.png\"\n",
    "    fig.savefig(fpath, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chips Movie all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend(\"Agg\")\n",
    "frames_all_nights = []\n",
    "for night in sorted(glob.glob(\"./data/WASP39/ut*\")):\n",
    "    frame_date = sorted(glob.glob(f\"{night}/pngs/*.png\"))\n",
    "    frames_all_nights.append(frame_date)\n",
    "\n",
    "# Get longest night for padding\n",
    "max_night_length = len(max(frames_all_nights, key=len))\n",
    "\n",
    "# Pad shorter nights with last frame for each night\n",
    "for night in frames_all_nights:\n",
    "    night += [night[-1]]*(max_night_length - len(night))\n",
    "\n",
    "# Combine\n",
    "#for frames_all in zip(*frames_all_nights):\n",
    "#    for frame in frames_all:\n",
    "#        print(frame)\n",
    "    #print(\"\\nMoving on to next frame in all datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend(\"Agg\")\n",
    "for i, frame in tqdm(enumerate(zip(*frames_all_nights)), total=max_night_length):\n",
    "    # Create plt plot:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(40, 18))\n",
    "\n",
    "    for ax, img in zip(axes.flat, frame):\n",
    "        plt_image = np.array(Image.open(img))\n",
    "        ax.imshow(plt_image, aspect=\"auto\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=.0, hspace=.0)\n",
    "    plt.savefig(f\"../atmospheres_meeting/figs/chips/frames/frame_{i:03}.png\", \n",
    "                bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_all_nights = []\n",
    "for night in sorted(glob.glob(\"./data/HATP23/ut*\")):\n",
    "    frame_date = sorted(glob.glob(f\"{night}/pngs/*.png\"))\n",
    "    frames_all_nights.append(frame_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_all_nights = []\n",
    "for night in sorted(glob.glob(\"./data/HATP23/ut*\")):\n",
    "    frame_date = sorted(glob.glob(f\"{night}/pngs/*.png\"))\n",
    "    frames_all_nights.append(frame_date)\n",
    "\n",
    "# Get longest night for padding\n",
    "max_night_length = len(max(frames_all_nights, key=len))\n",
    "\n",
    "# Pad shorter nights with last frame for each night\n",
    "for night in frames_all_nights:\n",
    "    night += [night[-1]]*(max_night_length - len(night))\n",
    "\n",
    "# Combine\n",
    "#for frames_all in zip(*frames_all_nights):\n",
    "#    print(frames_all)\n",
    "    #for frame in frames_all:\n",
    "    #    print(frame)\n",
    "    \n",
    "    #print(\"\\nMoving on to next frame in all datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"./data/HATP26/ut190313/ift1310c2.fits\"\n",
    "fig, axes, data = utils.plot_aperture(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Spectra over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = []\n",
    "for fpath in fpaths_sci:\n",
    "    chip_data = utils.fits_data(fpath)\n",
    "    x_l, x_r = 190, 206\n",
    "    #x_l, x_r = 688, 691\n",
    "    y_d, y_u = 0, chip_data.shape[0]\n",
    "    spectra_n = chip_data[y_d:y_u, x_l:x_r]\n",
    "    #spectra_n = np.max(spectra_n, axis=1)\n",
    "    spectra.append(spectra_n)\n",
    "    \n",
    "spectra = np.concatenate(np.array(spectra), axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/WASP39/ut190315\"\n",
    "chip_num = 5\n",
    "x_l, x_r = 190, 206\n",
    "object_name = \"w39bs science\"\n",
    "\n",
    "#data_dir = \"../data/WASP43/ut180603\"\n",
    "#chip_num = 8\n",
    "#x_l, x_r = 688, 691\n",
    "#object_name = \"science\"\n",
    "\n",
    "fig, ax, spectra = utils.plot_spec2d(data_dir, chip_num, x_l, x_r, object_name)\n",
    "\n",
    "tokens = data_dir.split(\"/\")\n",
    "target, date = tokens[2], tokens[3]\n",
    "fname = f\"spectra_2D_{target}_{date}\"\n",
    "fig.savefig(f\"/Users/mango/Desktop/{fname}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(spectra, vmin=0, vmax=30_000)\n",
    "fig.colorbar(im, ax=ax)\n",
    "ax.set_aspect(\"equal\")\n",
    "#fig.savefig(f\"/Users/mango/Desktop/{fname}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicklook Light Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fluxes'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"./data/HATP23/ut180821/HATP23_WLC_OTG.pkl\"\n",
    "target = fpath.split('/')[2]\n",
    "data = utils.pkl_load(fpath)\n",
    "name_target = [s for s in data[\"fluxes\"].keys() if target in s][0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "# Plot divided LCs\n",
    "time = data[\"time\"]\n",
    "flux_target = data[\"fluxes\"][name_target]\n",
    "flux_comps = []\n",
    "for obj, flux in data[\"fluxes\"].items():\n",
    "    if obj != name_target :\n",
    "        flux_comps.append(flux)\n",
    "        flux = flux_target / flux\n",
    "        #ax.plot(time, flux/np.median(flux), '.', label=obj)\n",
    "        ax.plot(flux/np.median(flux), 'o', label=obj)\n",
    "        \n",
    "# Plot sum LC\n",
    "flux_sum_comps = np.sum(flux_comps, axis=0)\n",
    "flux = flux_target / flux_sum_comps\n",
    "flux_norm = flux / np.median(flux)\n",
    "#ax.plot(time, flux / np.median(flux), 'lightgrey', lw=5, label=\"all\")\n",
    "ax.plot(flux_norm, '-o', color='lightgrey', lw=5, label=\"all\")\n",
    "ax.legend(ncol=int((len(flux_comps)+1)/2), frameon=True)\n",
    "delta = 1.0 - np.min(flux_norm)\n",
    "RpRs = np.sqrt(delta)\n",
    "label = rf\"$R_\\mathrm{{p}}/R_\\mathrm{{s}} \\approx {RpRs:.3f}$\"\n",
    "ax.annotate(label, xy=(0.9, 0.1), xycoords=\"axes fraction\", ha=\"center\")\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "ax.set_ylabel(\"Normalized Flux\")\n",
    "ax.set_ylim(0.978, 1.04)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMACS Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Transit 2':\n",
    "    f'{data_dir}/ut170609_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "    'Transit 3':\n",
    "    f'{data_dir}/ut180603_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_LARGE)\n",
    "\n",
    "objs = [\"HATP23b\", \"comp4\", 'comp5']\n",
    "colors = [\"C5\", \"C0\", \"C1\"]\n",
    "for ax, (transit_name, transit_path) in zip(axes.flat, data_dict.items()):\n",
    "    data = utils.pkl_load(transit_path)\n",
    "    time = Time(data[\"t\"], format=\"jd\")# - 2450000\n",
    "    wavs = data[\"optimal spectra\"][\"wavelengths\"]\n",
    "    wav_low_idx = np.where(wavs == 5000)[0][0]\n",
    "    wav_high_idx = np.where(wavs == 9000)[0][0]\n",
    "    wavs_int = wavs[wav_low_idx:wav_high_idx+1]\n",
    "    for obj, c in zip(objs, colors):\n",
    "        f = data[\"optimal spectra\"][obj][:,wav_low_idx:wav_high_idx+1].sum(axis=1)\n",
    "        ax.plot_date(time.plot_date, f/np.max(f), '.', label=obj, color=c)\n",
    "\n",
    "        ax.legend(ncol=3, loc=4)\n",
    "        ax.set_xlabel(\"Time (UTC)\")\n",
    "        ax.set_ylabel(\"$F / F_\\mathrm{max}$\")\n",
    "        ax.set_title(transit_name)\n",
    "\n",
    "    #ax.plot_date(time.plot_date, data[\"oLC\"]/np.max(data[\"oLC\"]), c='r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(data[\"oLC\"][:, 1], '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASAS-SN Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme(\"paper\")\n",
    "fpaths = [\n",
    "    'projects/HATP23b/asas-sn_hatp23.csv',\n",
    "    'projects/HATP23b/asas-sn_comp5.csv',\n",
    "    'projects/HATP23b/asas-sn_comp4.csv',\n",
    "    'projects/HATP23b/asas-sn_comp7.csv'\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "for fpath in fpaths:\n",
    "    df = pd.read_csv(fpath, parse_dates=[\"UT Date\"], date_parser=utils.myparser)\n",
    "\n",
    "    #display(df.head())\n",
    "    name = fpath.split('/')[-1]\n",
    "    df.set_index([\"UT Date\"], inplace=True)\n",
    "    grouped = df.groupby('Filter')\n",
    "    for (k, g) in grouped:\n",
    "        if k=='V':\n",
    "            ax.plot(g['flux(mJy)'], marker='.', lw=0, label=name)\n",
    "    \n",
    "mid_transit_times = {\n",
    "        'Transit 1': '2016-06-22 08:18:00',\n",
    "        'Transit 2': '2017-06-10 07:05:00',\n",
    "        'Transit 3': '2018-06-04 07:24:00',\n",
    "        'Transit 4': '2018-06-21 06:56',\n",
    "        'Transit 5': '2018-08-22 03:30:00',\n",
    "    }\n",
    "p_kwargs = {'ls': '--', 'c': 'grey', 'lw':1.0}\n",
    "for transit_name, t0 in mid_transit_times.items():\n",
    "    t_mid = parser.parse(t0)\n",
    "    ax.axvline(t_mid, **p_kwargs)\n",
    "    ax.text(t_mid, 20.0, transit_name, ha='right', rotation=90.0)\n",
    "\n",
    "ax.legend(loc=2, frameon=True, fontsize=12, bbox_to_anchor=(1, 1))\n",
    "#ax.set_title(fpath)\n",
    "ax.set_ylim(0, 60)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Flux (mJy)')\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m=2):\n",
    "    outlier_mask = abs(data - np.mean(data)) > m * np.std(data)\n",
    "    return data[~outlier_mask], outlier_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"projects/HATP23b/asas-sn_hatp23.csv\"\n",
    "df = pd.read_csv(fpath, parse_dates=[\"UT Date\"], date_parser=utils.myparser)\n",
    "df_V = df.groupby(\"Filter\").get_group(\"V\")\n",
    "t = (df_V[\"HJD\"] - 2.457e6).values\n",
    "f = df_V[\"flux(mJy)\"].values\n",
    "plt.figure()\n",
    "plt.plot(t[142:], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filtered, outlier_mask = reject_outliers(f)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_LARGE)\n",
    "ax_top, ax_bottom = axes\n",
    "\n",
    "#ax.plot(t, f, '.')\n",
    "#ax.plot(t[outlier_mask], f[outlier_mask], 'ro', alpha=0.5)\n",
    "\n",
    "idxs_dict = {\n",
    "    \"asas-sn_hatp23.csv\":{\n",
    "        \"idx_start\":54,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 203), slice(204, 377), slice(412, 516)]\n",
    "    },\n",
    "    \"asas-sn_comp4.csv\":{\n",
    "        \"idx_start\":7,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 203), slice(204, 377), slice(419, 531)]\n",
    "    },\n",
    "    \"asas-sn_comp5.csv\":{\n",
    "        \"idx_start\":7,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 203), slice(204, 371), slice(418, 530)]\n",
    "    },\n",
    "    \"asas-sn_comp7.csv\":{\n",
    "        \"idx_start\":142,\n",
    "        \"idxs_seasons\":\n",
    "            [slice(0, 202), slice(204, 377), slice(419, 531)]\n",
    "    },\n",
    "}\n",
    "\n",
    "target_file = fpath.split('/')[-1]\n",
    "idx_start = idxs_dict[target_file][\"idx_start\"]\n",
    "time_global, flux_global = t[~outlier_mask][idx_start:], f[~outlier_mask][idx_start:]\n",
    "\n",
    "idxs_seasons = idxs_dict[target_file][\"idxs_seasons\"]\n",
    "\n",
    "ax_top.plot(time_global, flux_global, 'ko', alpha=0.25, mew=0)\n",
    "# Compute the GLS periodogram with default options.\n",
    "clp = pyPeriod.Gls((time_global, flux_global))\n",
    "freq_max, freq_max_err = clp.hpstat[\"fbest\"], clp.hpstat[\"f_err\"]\n",
    "P_max, P_max_err = 1.0/freq_max, clp.hpstat[\"Psin_err\"]\n",
    "label = f\"$P_\\mathrm{{max}} = {P_max:.3f} \\pm {P_max_err:.3e}$\"\n",
    "ax_bottom.semilogx(1.0/clp.freq, clp.power, label=label)\n",
    "print(f\"> Global\")\n",
    "print(f\"{fpath}\")\n",
    "clp.info()\n",
    "print()\n",
    "\n",
    "# Calculate sine wave associated with 'best-fit' frequency\n",
    "bestSine_global = clp.sinmod(time_global)\n",
    "ax_top.plot(time_global, bestSine_global, label=\"Global\")\n",
    "ax_top.legend(fontsize=12)\n",
    "\n",
    "for i, idxs_season in enumerate(idxs_seasons, start=1):\n",
    "    time, flux = time_global[idxs_season], flux_global[idxs_season]\n",
    "    #ax.plot(time, flux, '.')\n",
    "\n",
    "    # Compute the GLS periodogram with default options.\n",
    "    clp = pyPeriod.Gls((time, flux))\n",
    "    \n",
    "    # and plot power vs. period.\n",
    "    freq_max, freq_max_err = clp.hpstat[\"fbest\"], clp.hpstat[\"f_err\"]\n",
    "    P_max, P_max_err = 1.0/freq_max, clp.hpstat[\"Psin_err\"]\n",
    "    label = f\"$P_\\mathrm{{max}} = {P_max:.3f} \\pm {P_max_err:.3e}$\"\n",
    "    ax_bottom.semilogx(1.0/clp.freq, clp.power, label=label)\n",
    "    ax_bottom.set_xlabel(\"Period (days)\")\n",
    "    ax_bottom.set_ylabel(\"Power\")\n",
    "    \n",
    "    # Calculate sine wave associated with 'best-fit' frequency\n",
    "    bestSine = clp.sinmod(time)\n",
    "    ax_top.plot(time, bestSine, label=f\"Season {i}\")\n",
    "    idxs_mid = len(time) // 2\n",
    "    phot_var = np.var(flux)\n",
    "    ax_top.annotate(\n",
    "        f\"$\\sigma^2 = {phot_var:.3f}$\",\n",
    "        (time[idxs_mid], 41.5),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "    # Print helpful information to screen\n",
    "    print(f\"> Season {i}\")\n",
    "    print(f\"{fpath}\")\n",
    "    clp.info()\n",
    "    print()\n",
    "    \n",
    "ax_top.set_xlabel(\"HJD - 2.457e6\")\n",
    "ax_top.set_ylabel(\"Flux (mJy)\")\n",
    "ax_top.set_title(fpath)\n",
    "ax_top.legend(ncol=4, fontsize=12)\n",
    "ax_bottom.legend(ncol=2, fontsize=12)\n",
    "fig.tight_layout()\n",
    "\n",
    "#utils.savepng(f\"/Users/mango/Desktop/{target_file.split('.')[0]}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme(\"paper\")\n",
    "dirpath = 'projects/HATP23b/data/stell_act'\n",
    "\n",
    "# Load processed data\n",
    "df_stell_data = pd.read_csv(\n",
    "    f'{dirpath}/HATP23_lc_norm_v3.csv',\n",
    "    names=['t_HJD', 't_UT', 'f'],\n",
    "    parse_dates=[1],\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "#df_stell_data.set_index([\"t_ut\"], inplace=True)\n",
    "\n",
    "# Load model data\n",
    "df_stell_model = pd.read_csv(\n",
    "    f'{dirpath}/HATP23_GP_model_Prot7_v3.csv',\n",
    "    names=['t_HJD', 'f', 'f_err'],\n",
    ")\n",
    "\n",
    "print(\"data\")\n",
    "display(df_stell_data.head())\n",
    "print(\"model\")\n",
    "display(df_stell_model.head())\n",
    "\n",
    "# Load model\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "#ax.plot(df_stell_data['f'], '.')\n",
    "ax.plot(df_stell_data['t_HJD'], df_stell_data['f'], 'r.', alpha=0.5, mew=0)\n",
    "ax.plot(df_stell_model['t_HJD'], df_stell_model['f'], color=\"grey\")\n",
    "f_d = df_stell_model['f'] - df_stell_model['f_err']\n",
    "f_u = df_stell_model['f'] + df_stell_model['f_err']\n",
    "ax.fill_between(df_stell_model['t_HJD'], f_d, f_u, alpha=0.3, lw=0, color=\"grey\")\n",
    "\n",
    "p_kwargs = {'ls': '--', 'c': 'darkgrey', 'lw':1.0}\n",
    "trans = transforms.blended_transform_factory(ax.transData, ax.transAxes)\n",
    "\n",
    "for transit_name, t0 in mid_transit_times.items():\n",
    "    t_mid = Time(t0).jd - 2.4e6\n",
    "    ax.axvline(t_mid, **p_kwargs)\n",
    "    ax.annotate(\n",
    "        transit_name,\n",
    "        xy=(t_mid, 0.1),\n",
    "        xycoords=trans,\n",
    "        ha='right',\n",
    "        rotation=90.0,\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "#ax.set_title(fpath)\n",
    "#ax.set_xlim(57400, 58500)\n",
    "ax.set_ylim(0.88, 0.98)\n",
    "ax.set_xlabel('Date (HJD - 2400000)')\n",
    "ax.set_ylabel('Flux (mJy)')\n",
    "fig.tight_layout()\n",
    "\n",
    "#utils.savefig(\"projects/HATP23b/paper/figures/phot_mon_full.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_stell_model['f'])\n",
    "ax.axhline(np.median(df_stell_model['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.max(df_stell_model['f']) - np.median(df_stell_model['f'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time(mid_transit_times[\"Transit 1\"]).jd - 2400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.947726 - 0.93211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(13571.18577 - 12584.79890) / 12584.79890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.weighted_mean_uneven_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(12585 + 12716 + 13571 + 13204 + 12832) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12585 - 12981.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0.05\n",
    "100*f / (1 - f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data #np.ones((8192, 1))\n",
    "f=open(\"pyt2.pickle\",\"wb\")\n",
    "pickle.dump(d, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.pkl_load(\"data/data_reductions/HATP23/ut180603_a15_25_noflat/LCs_hp23_species.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cLC\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"spectra\"][\"HATP23b\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traces over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, XX, YY = utils.plot_traces(\n",
    "    \"data_reductions/HATP23b/ut160621\"\n",
    ")\n",
    "#utils.savepng('projects/HATP23/traces_ut180821')\n",
    "#utils.savepng(\"/home/mango/Desktop/traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.fits_data(\"ift1258_HATP26_c2.fits\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_WIDE, sharex=True)\n",
    "ax_top, ax_bottom = axes\n",
    "\n",
    "start = 20\n",
    "end = 25\n",
    "ax_top.imshow(data, aspect=\"auto\", cmap=\"magma\")\n",
    "ax_top.grid(False)\n",
    "ax_top.set_ylim(start-2, end+2)\n",
    "ax_top.set_title(\"Sub-image (regular point 2)\")\n",
    "\n",
    "for i, row in enumerate(data[start:end, :], start=start):\n",
    "    ax_bottom.plot(row, lw=1.5, label=f\"{i}\")\n",
    "ax_bottom.legend(fontsize=11, title_fontsize=11, title=\"row number\")\n",
    "ax_bottom.set_xlabel(\"Pixel\")\n",
    "ax_bottom.set_ylabel(\"Counts\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "utils.savepng(\"/home/mango/Desktop/sub_regular2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "data = utils.pkl_load(\n",
    "    \"Projects/HATP26b/data_reductions/ut190313_a15_25_noflat_LBR/LCs_bins_stevenson_combined.pkl\"\n",
    ")\n",
    "spec = data[\"optimal spectra\"]\n",
    "wavs = spec[\"wavelengths\"]\n",
    "obj = \"c01\"\n",
    "for (i, label) in zip([20, 197, 199], [\"outlier\", \"regular\", \"regular 2\"]):\n",
    "    ax.plot(\n",
    "        wavs,\n",
    "        spec[\"HATP26\"][i, :] / spec[obj][i, :],\n",
    "        label=label,\n",
    "    )\n",
    "    \n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Wavelength (Ã…)\")\n",
    "ax.set_ylabel(\"Integrated Counts\")\n",
    "ax.set_title(f\"Opt extracted spectra (HATP26 / {obj})\")\n",
    "\n",
    "#fig.set_size_inches(FIG_WIDE)\n",
    "fig.tight_layout()\n",
    "\n",
    "#utils.savepng(f\"/home/mango/Desktop/divided_opt_extr_spectra_{obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Extracted Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "dirpath = \"HATP26b/data_reductions/ut190313_a15_25_noflat\"\n",
    "#dirpath = './data/data_reductions/HATP23_py2/ut180620_a15_25_noflat'\n",
    "fpaths = np.array(glob.glob(f\"{dirpath}/*spec.fits\"))\n",
    "#mask = np.array([\"comp5_5\" not in fpath for fpath in fpaths])\n",
    "#mask &= [\"comp7_3\" not in fpath for fpath in fpaths]\n",
    "#mask &= [\"comp7_8\" not in fpath for fpath in fpaths]\n",
    "\n",
    "#mask = np.array([\"c05_4\" not in fpath for fpath in fpaths])\n",
    "#mask &= [\"c05_7\" not in fpath for fpath in fpaths]\n",
    "\n",
    "#mask = np.array([\"com03_6\" not in fpath for fpath in fpaths])\n",
    "#fpaths = fpaths[mask]\n",
    "objs = {}\n",
    "for i, obj_path in enumerate(fpaths):\n",
    "    p, p_name, wavs, p_data = utils.plot_spec_file_objects(\n",
    "        ax, obj_path, i=1,\n",
    "    )\n",
    "    objs[p_name] = p_data\n",
    "\n",
    "ax.set_title(dirpath)\n",
    "ax.legend(loc=2, fontsize=12)\n",
    "ax.set_xlim(0, 2_000)\n",
    "#ax.set_ylim(-10, 90_000)\n",
    "ax.set_xlabel(\"pixel (dispersion direction)\")\n",
    "ax.set_ylabel(\"counts\")\n",
    "fig.tight_layout()\n",
    "#date = Path(dirpath).parts[-1].split('_')[0]\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/spectra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelength Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the lamp spectra through the target and comparison star slits are usually completely shifted off of the reference lamp spectra, so `guess_lines.py` can't be used. Instead of using this, the lines can be manually identified from [NOAO](http://iraf.noao.edu/specatlas/henear/henear.html). After getting the first target done, the rest can be bootstrapped relatively quickly since their arc spectra should be similar.\n",
    "\n",
    "To make things a little easier, the following routine will automatically record the pixel and wavelength coordinate of each line selected from the bottom panel. To select the pixel value under the mouse, press 'X' on the keyboard. To record the corresponding wavelength value, click on the annotated value in the top reference panel. Rinse and repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reference (NOAO), do this one first\n",
    "# dirpath = \"./useful_scripts\"\n",
    "# fpath_arc_ref = f\"{dirpath}/noao_flux.fits\"\n",
    "# fpath_lines_ref = f\"{dirpath}/noao_line_list.txt\"\n",
    "\n",
    "# Reference (target) arc spectra, use as ref after calibrating inital with NOAO\n",
    "dirpath_ref = \"data_reductions/HATP26b/ut190313_a15_25_noflat/arcs\"\n",
    "fpath_arc_ref = f\"{dirpath_ref}/HATP26b_2_arc.fits\"\n",
    "name = fpath_arc_ref.split('/')[-1].split('_')[0]\n",
    "#fpath_lines_ref = f\"{dirpath_ref}/{name}_guesses.txt\"\n",
    "fpath_lines_ref = f\"{dirpath_ref}/{name}_lines_chips.csv\"\n",
    "\n",
    "# Arc spectra to compare\n",
    "dirpath = \"data_reductions/HATP26b/ut190313_a15_25_noflat/arcs\"\n",
    "fpath_arc = f\"{dirpath}/c05_4_arc.fits\"\n",
    "name = fpath_arc.split('/')[-1].split('_')[0]\n",
    "#fpath_lines = f\"{dirpath}/{name}_guesses.csv\"\n",
    "fpath_lines = f\"{dirpath}/{name}_lines_chips.csv\"\n",
    "\n",
    "# Plot\n",
    "wavs, pixels = utils.compare_arc_lines(\n",
    "    fpath_arc_ref=fpath_arc_ref, \n",
    "    fpath_lines_ref=fpath_lines_ref,\n",
    "    fpath_arc=fpath_arc,\n",
    "    fpath_lines=fpath_lines,\n",
    "    sharex=False, sharey=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guesses = pd.read_csv(fpath_lines, escapechar='#')\n",
    "# update if lines chosen\n",
    "#if len(wavs) != 0 and len(pixels) != 0:\n",
    "chips = [int(fpath_arc.split('/')[-1].split('_')[1])] * len(wavs)\n",
    "df_chosen = pd.DataFrame({\"Wav\":wavs, \"Pix\":pixels, \"Chip\":chips})\n",
    "\n",
    "df_guesses = pd.concat([df_guesses, df_chosen])\n",
    "\n",
    "fname = fpath_lines.split('/')[-1]\n",
    "df_guesses = df_guesses.sort_values(by=[\"Chip\", \"Wav\"])\n",
    "display(df_guesses)\n",
    "print(f\"Will save to: {dirpath}/{fname}\")\n",
    "\n",
    "save = input(\"Continue? (y/n): \")\n",
    "if save.lower() == 'y': \n",
    "    df_guesses.to_csv(f\"{dirpath}/{fname}\", index=False, escapechar='#')\n",
    "    print(f\"Saved to: {dirpath}/{fname}\")\n",
    "else: \n",
    "    print(\"not saved\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = np.loadtxt(\n",
    "    \"data_reductions/HATP26b/ut190313_a15_25_noflat/arcs/HATP26b_lines_chips.csv\",\n",
    "    delimiter=',',\n",
    "    unpack=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View wavelength solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=FIG_LARGE)\n",
    "\n",
    "dir_lines = \"HATP26b/data_reductions/ut190313_a15_25_noflat/arcs\"\n",
    "#fpaths = glob.glob(f\"{dir_lines}/*guesses*.txt\")\n",
    "fpaths = glob.glob(f\"{dir_lines}/*lines_chips.csv\")\n",
    "x_name = \"Pix\"\n",
    "y_name = \"Wav\"\n",
    "for fpath in fpaths:\n",
    "    df = pd.read_csv(fpath, escapechar=\"#\")\n",
    "    comp_name = fpath.split('/')[-1].split('_')[0].split(\"comp\")[-1]\n",
    "    utils.plot_pix_wav(ax, df, x_name, y_name, comp_name)\n",
    "\n",
    "ax.legend(frameon=True)\n",
    "ax.set_xlabel(x_name)\n",
    "ax.set_ylabel(y_name)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data_reductions/HATP26b\"\n",
    "binsize = \"bins_stevenson_combined\"\n",
    "date = \"190313\"\n",
    "N = 1\n",
    "data_dict = {\n",
    "    f\"Transit {N}\":\n",
    "    f\"{data_dir}/ut{date}/hp26_{date}_st.pkl\",\n",
    "    \n",
    "#     'Transit 2':\n",
    "#     f'{data_dir}/ut170609_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "#     'Transit 3':\n",
    "#     f'{data_dir}/ut180603_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "#     'Transit 4':\n",
    "#     f'{data_dir}/ut180620_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "#     'Transit 5':\n",
    "#     f'{data_dir}/ut180821_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "}\n",
    "\n",
    "#data_dict = {\n",
    "#    \"Transit 1\":\n",
    "#    f\"{data_dir}/ut190313_a15_25_noflat_LBR/LCs_{binsize}.pkl\"\n",
    "#}\n",
    "\n",
    "#set_theme('paper')\n",
    "#paper_path = 'projects/HATP23b/paper/figures'\n",
    "# wbins = pd.read_table(\n",
    "#     f\"{data_dir}/hp23_bins.dat\",\n",
    "#     names=['wav_d', 'wav_u'],\n",
    "#     skiprows=1,\n",
    "#     sep='\\s+',\n",
    "#     comment='#',\n",
    "# )\n",
    "for transit, fpath in data_dict.items():\n",
    "    data = utils.pkl_load(fpath)\n",
    "    spec = data['spectra']\n",
    "    wavs = spec[\"wavelengths\"]\n",
    "    print(wavs[[data['idx_usable_wl']]])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "    c = 'darkgrey'\n",
    "    for name, data in sorted(spec.items()):\n",
    "        if name in 'HATP23b':\n",
    "            median_kwargs = {'c':'C5'} \n",
    "        else:\n",
    "            median_kwargs = None #{'c':c}\n",
    "            c = 'grey'\n",
    "        if (name != 'wavelengths'):\n",
    "            p, wav, flux = utils._plot_spec_file(\n",
    "                ax, data=data, wavs=wavs, label=name, median_kwargs=median_kwargs,\n",
    "            )\n",
    "    ax.legend(loc=1, fontsize=12)\n",
    "    \n",
    "    # bins\n",
    "#     for i, (w_d, w_u) in enumerate(zip(wbins['wav_d'], wbins['wav_u'])):\n",
    "#         c = 'k' if i % 2 == 0 else 'darkgrey'\n",
    "#         ax.axvspan(w_d, w_u, alpha=0.25, color=c, lw=0)\n",
    "    \n",
    "    # species lines\n",
    "    species = {\n",
    "        'Na I-D':5892.9, \n",
    "        'K I_avg':7682.0, \n",
    "        'Na I-8200_avg':8189.0\n",
    "    }\n",
    "    [ax.axvline(wav, ls='--', lw=1, color='grey') for name, wav in species.items()]\n",
    "    title = transit\n",
    "    ax.set_xlabel('Wavelength (Ã…)')\n",
    "    ax.set_ylabel('Flux')\n",
    "    #ax.set_title(title)\n",
    "    ax.set_xlim(wavs[0], wavs[-1])\n",
    "    #ax.set_ylim(-0.01, 1.15)\n",
    "\n",
    "    title = title.lower().replace(' ', '_') + '_extr_spec'\n",
    "    fig.set_size_inches(FIG_WIDE)\n",
    "    fig.tight_layout()\n",
    "    #utils.savefig(f'{paper_path}/extracted_spectra/{title}.pdf')\n",
    "    #utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/spectra\")\n",
    "    #utils.savepng(\"/home/mango/Desktop/unnormed_spec\")\n",
    "\n",
    "objs = [\"HATP26b\", \"c01\", \"c03\", \"c05\"]\n",
    "for obj in objs:\n",
    "    spec_hp23 = np.nan_to_num(spec[obj], nan=-20_000)\n",
    "    spec_hp23.shape\n",
    "    x = spec[\"wavelengths\"]\n",
    "    ys = [row for row in spec_hp23]\n",
    "\n",
    "    plot_lines2(x, ys, f\"Transit {N} {obj}\")\n",
    "\n",
    "    utils.savepng(f\"/home/mango/Desktop/transit{N}_{obj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.pkl_load(fpath)[\"spectra\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines2(x, ys, title):\n",
    "    # We need to set the plot limits, they will not autoscale\n",
    "    fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "    ax.set_xlim(np.min(x), np.max(x))\n",
    "    ax.set_ylim(np.min(ys), np.max(ys))\n",
    "\n",
    "    # colors is sequence of rgba tuples\n",
    "    # linestyle is a string or dash tuple. Legal string values are\n",
    "    #          solid|dashed|dashdot|dotted.  The dash tuple is (offset, onoffseq)\n",
    "    #          where onoffseq is an even length tuple of on and off ink in points.\n",
    "    #          If linestyle is omitted, 'solid' is used\n",
    "    # See :class:`matplotlib.collections.LineCollection` for more information\n",
    "\n",
    "    # Make a sequence of x,y pairs\n",
    "    line_segments = LineCollection([np.column_stack([x, y]) for y in ys],\n",
    "                                   linestyles='solid')\n",
    "    line_segments.set_array(np.arange(len(ys)))\n",
    "    ax.add_collection(line_segments)\n",
    "    axcb = fig.colorbar(line_segments)\n",
    "    axcb.set_label('Index #')\n",
    "    plt.sci(line_segments)  # This allows interactive changing of the colormap.\n",
    "    plt.viridis()\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Wavelength\")\n",
    "    ax.set_ylabel(\"Counts\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_hp23 = np.nan_to_num(spec[\"HATP23b\"], nan=-20_000)\n",
    "spec_hp23.shape\n",
    "x = spec[\"wavelengths\"]\n",
    "ys = [row for row in spec_hp23]\n",
    "\n",
    "plot_lines2(x, ys, \"Transit 1\")\n",
    "\n",
    "utils.savepng(\"/home/mango/Desktop/transit1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Transit 2':\n",
    "    f'{data_dir}/ut170609_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "\n",
    "    'Transit 3':\n",
    "    f'{data_dir}/ut180603_a15_25_noflat/LCs_hp23_{binsize}.pkl',\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_LARGE)\n",
    "\n",
    "objs = [\"HATP23b\", \"comp4\", 'comp5']\n",
    "colors = [\"C5\", \"C0\", \"C1\"]\n",
    "for ax, (transit_name, transit_path) in zip(axes.flat, data_dict.items()):\n",
    "    data = utils.pkl_load(transit_path)\n",
    "    time = Time(data[\"t\"], format=\"jd\")# - 2450000\n",
    "    wavs = data[\"optimal spectra\"][\"wavelengths\"]\n",
    "    wav_low_idx = np.where(wavs == 5000)[0][0]\n",
    "    wav_high_idx = np.where(wavs == 9000)[0][0]\n",
    "    wavs_int = wavs[wav_low_idx:wav_high_idx+1]\n",
    "    for obj, c in zip(objs, colors):\n",
    "        f = data[\"optimal spectra\"][obj][:,wav_low_idx:wav_high_idx+1].sum(axis=1)\n",
    "        ax.plot_date(time.plot_date, f/np.max(f), '.', label=obj, color=c)\n",
    "\n",
    "        ax.legend(ncol=3, loc=4)\n",
    "        ax.set_xlabel(\"Wavelength (Ã…)\")\n",
    "        ax.set_ylabel(\"$F / F_\\mathrm{max}$\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dw = 300\n",
    "for w in np.arange(4850, 5450, dw):\n",
    "    print(f'{w:.2f}', f'{w+dw:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "fpath = \"./Projects/HATP26b/data_reductions/bins_wakeford.txt\"\n",
    "wbins = pd.read_table(fpath, sep='\\s+', comment='#')\n",
    "wbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspec = pd.DataFrame()\n",
    "tspec['wav_d'] = ((wbins[\"wav_cen\"] - wbins[\"delta_wav\"])/2.0) * 1e4\n",
    "tspec['wav_u'] = ((wbins[\"wav_cen\"] + wbins[\"delta_wav\"])/2.0) * 1e4\n",
    "tspec[\"diff\"] = tspec[\"wav_u\"] - tspec[\"wav_d\"]\n",
    "tspec[\"wav_cen\"] = wbins[\"wav_cen\"] * 1e4\n",
    "tspec[\"depth\"] =  wbins[\"rprs\"]**2 * 1e6\n",
    "tspec[\"depth_unc\"] = np.sqrt(4.0*wbins[\"rprs\"]**2 * wbins[\"rprs_unc\"]**2) * 1e6\n",
    "\n",
    "tspec.to_csv(\"./Projects/HATP26b/data_detrending/tspec_wakeford.txt\",\n",
    "            index=False)\n",
    "\n",
    "tspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspec = pd.DataFrame()\n",
    "tspec['wav_d'] = wbins[\"wav_d\"] * 1e4\n",
    "tspec[\"wav_u\"] = wbins[\"wav_u\"] * 1e4\n",
    "tspec[\"diff\"] = tspec[\"wav_u\"] - tspec[\"wav_d\"]\n",
    "tspec[\"wav_cen\"] = (tspec[\"wav_u\"] + tspec[\"wav_d\"]) / 2.0\n",
    "tspec[\"depth\"] =  wbins[\"depth_percent\"] * 1e4\n",
    "tspec[\"depth_unc\"] = wbins[\"depth_unc_percent\"] * 1e4\n",
    "\n",
    "tspec.to_csv(\"./Projects/HATP26b/data_detrending/tspec_stevenson.txt\",\n",
    "            index=False)\n",
    "\n",
    "tspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "for name, data in sorted(spec.items()):\n",
    "    if name != 'wavelengths':\n",
    "        p, _ = utils._plot_spec_file(ax, data=data, wavs=wavs, label=name)\n",
    "        \n",
    "ax.set_xlim(wavs[0], wavs[-1])\n",
    "ax.set_ylim(-0.01, 1.15)\n",
    "ax.legend(fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"Transit 1\":\n",
    "    {\n",
    "        \"fpath\":f\"./Projects/HATP26b/data_reductions/ut190313_a15_25_noflat_LBR/LCs_bins_stevenson_combined.pkl\",\n",
    "    }\n",
    "}\n",
    "\n",
    "for transit_name, transit_data in data_dict.items():\n",
    "    fpath = transit_data[\"fpath\"]\n",
    "    data = utils.pkl_load(fpath)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "    # Raw fluxes\n",
    "    p, _ = utils.plot_fluxes(\n",
    "        ax,data,\n",
    "        use_time=True,\n",
    "        normalize=True,\n",
    "        t0 = 2458556.7500,\n",
    "    )\n",
    "    title = transit_name\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    p.set_xlabel(\"$T - T_0$ (hours)\")\n",
    "    p.set_ylabel(\"Normalized flux\")\n",
    "\n",
    "    utils.savepng(f\"/home/mango/Desktop/raw_LCs.png\")\n",
    "\n",
    "    #pd.DataFrame(f_data).to_csv(f\"/Users/mango/Desktop/fluxes_{title}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cLC\"]# / data[\"etimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2, 3])[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(f_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLC Divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_theme(\"paper\")\n",
    "#sns.set_context('paper')\n",
    "data_dir = \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_reductions\"\n",
    "LCs_pickle = \"LCs_bins_stevenson_combined.pkl\"\n",
    "data_dict = {\n",
    "    \"Transit 1\":\n",
    "    {\n",
    "        \"path\":f\"{data_dir}/ut190313_a15_25_noflat_LBR/{LCs_pickle}\",\n",
    "        \"bad_idxs\":\"[4,5,11,12]\",\n",
    "        \"t0\":2455304.65218,\n",
    "    }\n",
    "}\n",
    "# data_dict = {\n",
    "#     'Transit 1':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut160621_a15_20_noflat/{LCs_pickle}_160621.pkl',\n",
    "#             'bad_idxs':'[239, 240, 241, 256, 276, 278, 283, 284, 288:299]',\n",
    "#             't0':2457561.84167,\n",
    "#         },\n",
    "    \n",
    "#     'Transit 2':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut170609_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             'bad_idxs':'[10]',\n",
    "#             't0':2457914.79167,\n",
    "#         },\n",
    "    \n",
    "#     'Transit 3':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut180603_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             'bad_idxs':'[0:17]',\n",
    "#             't0':2458273.80556,\n",
    "#         },\n",
    "    \n",
    "#     'Transit 4':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut180620_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             'bad_idxs':'[93, 94, 149, 157:171]',\n",
    "#             't0':2458290.78472,\n",
    "#         },\n",
    "#     'Transit 5':\n",
    "#         {\n",
    "#             'path':f'{data_dir}/ut180821_a15_25_noflat/{LCs_pickle}.pkl',\n",
    "#             #'bad_idxs':'[4:6, 51, 53, 54, 56:59, 64, 66, 68, 69, 72, 77:80, 87:94, 96:98, 101, 108:119, 120, 129:131, 133, 174:181]',\n",
    "#             'bad_idxs':'[4:6, 51, 53, 54, 56:59, 64, 66, 68, 69, 72, 77:80, 87:94, 96:98, 101, 129:131, 133, 174:181]',\n",
    "#             #'bad_idxs':'[108:120]',\n",
    "#             't0':2458352.64028,\n",
    "#         },\n",
    "    \n",
    "# }\n",
    "\n",
    "comps = ['c01', 'c03', 'c05']\n",
    "ncomps = len(comps)\n",
    "fig, axes = plt.subplots(\n",
    "    1, ncomps, \n",
    "    sharex=True, sharey=True,\n",
    "    #figsize=(7, 14),\n",
    ")\n",
    "if axes.ndim == 1: axes = axes.reshape(1, axes.size) \n",
    "colors = sns.color_palette()\n",
    "for i, (transit_name, transit_info) in enumerate(data_dict.items()):\n",
    "    fpath = transit_info['path']\n",
    "    t0 = transit_info['t0']\n",
    "    data = utils.pkl_load(fpath)\n",
    "    print(fpath)\n",
    "    print(len(data['t']))\n",
    "    print(data['cNames'])\n",
    "    #ncomps = len(data['cNames'])\n",
    "    #fig, axes = plt.subplots(\n",
    "    #    1, ncomps, \n",
    "    #    sharex=True, sharey=True,\n",
    "    #    figsize=(12,3),\n",
    "    #)\n",
    "    \n",
    "    for ax, comp in zip(axes[i, :], comps):\n",
    "        p = utils.plot_divided_wlcs(\n",
    "            ax,\n",
    "            data,\n",
    "            t0=t0,\n",
    "            ferr=0.001,\n",
    "            comps_to_use=[comp],\n",
    "            bad_idxs_user = transit_info['bad_idxs'],\n",
    "            div_kwargs={'fmt':'.', 'lw':0.5, 'mew':0.0, 'ms':3, 'c':colors[i]},\n",
    "            bad_div_kwargs={'fmt':'.', 'lw':0.5, 'mec':'k', 'ms':6, 'c':'w'},\n",
    "        )\n",
    "        #ax.set_title(comp)\n",
    "        ax.annotate(\n",
    "            rf\"{transit_name}/{comp}\",\n",
    "            xy=(0.05, 0.85),\n",
    "            xycoords='axes fraction',\n",
    "            fontsize=12, color=colors[i],\n",
    "            weight='bold',\n",
    "        )\n",
    "        #ax.set_xlim(-3, 3)\n",
    "        #ax.xaxis.set_ticks([-3, -2, -1, 0, 1, 2, 3])\n",
    "        ax.set_ylim(0.988, 1.02)\n",
    "        ax.yaxis.set_ticks([0.96, 0.98, 1.00, 1.02, 1.04])\n",
    "        #fig.set_size_inches(12, 3)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    title = transit_name.lower().replace(' ', '_') + '_extr_wlcs'\n",
    "# Custom legend\n",
    "#handles, labels = [], []\n",
    "#for transit_name in list(data_dict.keys()):\n",
    "#    dummy = plt.errorbar([], [], yerr=0.1, fmt='o', ms=5, elinewidth=2, label=transit_name)\n",
    "#    handles.append(dummy)\n",
    "#    labels.append(transit_name)\n",
    "#fig.legend(handles, labels, ncol=5, bbox_to_anchor=(0.54, 1.1), loc='upper center')#, ncol=len(data_dict)+1) \n",
    "#axes[0, 0].set_title('comp4')\n",
    "#axes[0, 1].set_title('comp5')\n",
    "\n",
    "fig.text(0.54, -0.02, 'Time from estimated mid-transit (hours)', ha='center')\n",
    "fig.text(-0.01, 0.5, 'Normalizd flux', va='center', rotation='vertical')\n",
    "#axes[0].set_ylabel('Normalized flux')\n",
    "fig.tight_layout()\n",
    "#fig.set_size_inches(12, 3)\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/wlc\")\n",
    "\n",
    "    #plt.savefig('/Users/mango/Desktop/wlc_py2_py3.png', dpi=250, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = [\"a1\", \"a2\", \"a3\"]\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "if axes.ndim == 1: axes = axes.reshape(1, axes.size) \n",
    "plt.close()\n",
    "\n",
    "for ax, comp in zip(axes[0, :], comps):\n",
    "    print(ax, comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(set([6, 51, 52, 55, 59, 64, 65, 66, 67, 68, 69, 72, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 108, 111, 112, 113, 120, 129, 130, 131, 132, 133, 178, 179, 180]).union(set([55, 56, 59, 68, 88, 89, 90, 91, 97, 120, 178]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIG_WIDE, sharex=True, sharey=True)\n",
    "\n",
    "comps_to_use =  [\"comp4\", \"comp5\"] #data[\"cNames\"]\n",
    "p, i_used, t, f_div_sum, i_not_used, i_all = utils.plot_sum_divided_wlcs(\n",
    "    ax,\n",
    "    data,\n",
    "    comps_to_use=comps_to_use,\n",
    "    bad_idxs_user = \"[53:59, 64, 65, 68, 78:80, 88:91, 97, 109, 110:120, 173:181]\",\n",
    "    div_sum_kwargs={\"fmt\":'.', \"mew\":0, \"alpha\":0.5, \"lw\":0.5},\n",
    ")\n",
    "p.legend(ncol=3, loc=\"upper center\", frameon=True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview divided LC\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "ax.errorbar(i_used, f_div_sum[i_used], yerr=0.001, fmt='.', lw=0.5)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferr = 0.001 * np.ones_like(i_used)\n",
    "instrument = [\"MAGELLAN\"] * len(i_used)\n",
    "df_juliet = pd.DataFrame(\n",
    "    zip(t[i_used] - 2457000, f_div_sum[i_used].flatten(), ferr, instrument),\n",
    ")\n",
    "df_juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path(\"juliet/hatp23_test/\")\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "df_juliet.to_csv(\n",
    "    f\"{p}/lc.dat\",\n",
    "    float_format=\"%.10f\",\n",
    "    sep=' ',\n",
    "    header=False,\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "with open(p / \"used_comps_and_bad_idxs.txt\", \"w\") as f:\n",
    "    f.writelines([f\"{comps_to_use}\\n\", f\"{i_not_used}\"])\n",
    "    \n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.pkl_load(\n",
    "    \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_reductions/ut190313_a15_25_noflat_LBR/LCs_bins_stevenson_combined.pkl\"\n",
    ")\n",
    "\n",
    "# Identify bad time idxs\n",
    "wbins_range = range(0, 38)\n",
    "bins = np.array(data[\"wbins\"])[wbins_range]\n",
    "time = data['t']\n",
    "bad_idxs = '[4,5,11,12]' #'[4:6, 51, 53, 54, 56:59, 64, 66, 68, 69, 72, 77:80, 87:94, 96:98, 101, 108:119, 120, 129:131, 133, 174:181]'\n",
    "bad_idxs = utils._bad_idxs(bad_idxs)\n",
    "if bad_idxs is not None:\n",
    "    idxs_used = np.delete(range(len(time)), bad_idxs)\n",
    "else:\n",
    "    idxs_used = range(len(time))\n",
    "    \n",
    "# Get target flux\n",
    "flux_target = np.c_[data[\"oLCw\"]]\n",
    "\n",
    "# Select comps\n",
    "cNames = data[\"cNames\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 11), sharex=True, sharey=True)\n",
    "ax_left, ax_middle, ax_right = axes\n",
    "\n",
    "########\n",
    "# Left\n",
    "########\n",
    "comps_to_use = [\"c01\"] #cNames\n",
    "comps_to_use_idxs = [cNames.index(cName) for cName in comps_to_use]\n",
    "flux_comps_used = np.c_[data[\"cLCw\"][:, comps_to_use_idxs, :]]\n",
    "flux_comps_used_sum = np.c_[np.sum(flux_comps_used, axis=1)]\n",
    "\n",
    "# Divide target flux by sum of chosen comp sum\n",
    "flux_div_sum = flux_target / flux_comps_used_sum\n",
    "flux_div_sum /= np.median(flux_div_sum, axis=0)\n",
    "fluxes = flux_div_sum[idxs_used, :][:, wbins_range]\n",
    "N_bins = fluxes.shape[1]\n",
    "\n",
    "offs = 0.008\n",
    "p_left = utils.plot_binned(\n",
    "        ax_left,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=bins, \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0}\n",
    "    )\n",
    "p_left.set_title(\"HAT-P-26 / c01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Middle\n",
    "########\n",
    "comps_to_use = [\"c03\"] #cNames\n",
    "comps_to_use_idxs = [cNames.index(cName) for cName in comps_to_use]\n",
    "flux_comps_used = np.c_[data[\"cLCw\"][:, comps_to_use_idxs, :]]\n",
    "flux_comps_used_sum = np.c_[np.sum(flux_comps_used, axis=1)]\n",
    "\n",
    "# Divide target flux by sum of chosen comp sum\n",
    "flux_div_sum = flux_target / flux_comps_used_sum\n",
    "flux_div_sum /= np.median(flux_div_sum, axis=0)\n",
    "fluxes = flux_div_sum[idxs_used, :][:, wbins_range]\n",
    "N_bins = fluxes.shape[1]\n",
    "\n",
    "offs = 0.008\n",
    "p_middle = utils.plot_binned(\n",
    "        ax_middle,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=bins, \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0}\n",
    "    )\n",
    "p_middle.set_title(\"HAT-P-26 / c03\")\n",
    "\n",
    "########\n",
    "# Right\n",
    "########\n",
    "p_right = utils.plot_binned(\n",
    "        ax_right,\n",
    "        idxs_used,\n",
    "        np.ones_like(fluxes),\n",
    "        utc=False,\n",
    "        bins=bins, \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        annotate=True,\n",
    "        annotate_kwargs={\"fontsize\":8, \"ha\":\"center\"},\n",
    "        annotate_rms_kwargs = {\n",
    "            \"fontsize\":8, \n",
    "            \"horizontalalignment\":'left',\n",
    "            \"path_effects\":[PathEffects.withStroke(linewidth=1, foreground=\"k\")],\n",
    "        }\n",
    "    )\n",
    "p_right.set_title(\"Bins\")\n",
    "\n",
    "trans = transforms.blended_transform_factory(\n",
    "            p_right.transAxes, p_right.transData\n",
    "        )\n",
    "\n",
    "ax_left.set_ylabel(\"Normalized flux + offset\")\n",
    "fig.text(0.5, 0, 'Index', ha='left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig(\"/Users/mango/Desktop/binned_lc.png\", dpi=250, bbox_inches=\"tight\")\n",
    "utils.savepng(\"/home/mango/Desktop/bad_region\")\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/raw_blcs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        ax_left,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=bins, \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        ax_left,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=bins, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.pkl_load(\n",
    "    \"/home/mango/ACCESS_notebook/Projects/HATP26b/data_reductions/ut190313_a15_25_noflat_LBR/LCs_bins_stevenson_combined.pkl\"\n",
    ")\n",
    "\n",
    "# Identify bad time idxs\n",
    "time = data['t']\n",
    "bad_idxs = '[4,5,11,12]' #'[4:6, 51, 53, 54, 56:59, 64, 66, 68, 69, 72, 77:80, 87:94, 96:98, 101, 108:119, 120, 129:131, 133, 174:181]'\n",
    "bad_idxs = utils._bad_idxs(bad_idxs)\n",
    "if bad_idxs is not None:\n",
    "    idxs_used = np.delete(range(len(time)), bad_idxs)\n",
    "else:\n",
    "    idxs_used = range(len(time))\n",
    "    \n",
    "# Get target flux\n",
    "flux_target = np.c_[data[\"oLCw\"]]\n",
    "\n",
    "# Select comps\n",
    "cNames = data[\"cNames\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 11), sharex=True, sharey=True)\n",
    "ax_left, ax_middle, ax_right = axes\n",
    "\n",
    "wbins_idxs = slice(0, 10)\n",
    "########\n",
    "# Left\n",
    "########\n",
    "comps_to_use = [\"c01\"] #cNames\n",
    "comps_to_use_idxs = [cNames.index(cName) for cName in comps_to_use]\n",
    "flux_comps_used = np.c_[data[\"cLCw\"][:, comps_to_use_idxs, :]]\n",
    "flux_comps_used_sum = np.c_[np.sum(flux_comps_used, axis=1)]\n",
    "\n",
    "# Divide target flux by sum of chosen comp sum\n",
    "flux_div_sum = flux_target / flux_comps_used_sum\n",
    "flux_div_sum /= np.median(flux_div_sum, axis=0)\n",
    "fluxes = flux_div_sum[idxs_used, :]\n",
    "N_bins = fluxes.shape[1]\n",
    "\n",
    "offs = 0.008\n",
    "p_left = utils.plot_binned(\n",
    "        ax_left,\n",
    "        idxs_used[wbins_idxs],\n",
    "        fluxes[wbins_idxs],\n",
    "        utc=False,\n",
    "        bins=np.array(data[\"wbins\"]), \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0}\n",
    "    )\n",
    "p_left.set_title(\"c01\")\n",
    "\n",
    "########\n",
    "# Middle\n",
    "########\n",
    "comps_to_use = [\"c03\"] #cNames\n",
    "comps_to_use_idxs = [cNames.index(cName) for cName in comps_to_use]\n",
    "flux_comps_used = np.c_[data[\"cLCw\"][:, comps_to_use_idxs, :]]\n",
    "flux_comps_used_sum = np.c_[np.sum(flux_comps_used, axis=1)]\n",
    "\n",
    "# Divide target flux by sum of chosen comp sum\n",
    "flux_div_sum = flux_target / flux_comps_used_sum\n",
    "flux_div_sum /= np.median(flux_div_sum, axis=0)\n",
    "fluxes = flux_div_sum[idxs_used, :][wbins_idxs]\n",
    "N_bins = fluxes.shape[1][wbins_idxs]\n",
    "\n",
    "offs = 0.008\n",
    "p_middle = utils.plot_binned(\n",
    "        ax_middle,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=np.array(data[\"wbins\"]), \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0}\n",
    "    )\n",
    "p_middle.set_title(\"c03\")\n",
    "\n",
    "########\n",
    "# Right\n",
    "########\n",
    "p_right = utils.plot_binned(\n",
    "        ax_right,\n",
    "        idxs_used,\n",
    "        np.ones_like(fluxes),\n",
    "        utc=False,\n",
    "        bins=np.array(data[\"wbins\"]), \n",
    "        offset=offs,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        annotate=True,\n",
    "        annotate_kwargs={\"fontsize\":8, \"ha\":\"center\"},\n",
    "        annotate_rms_kwargs = {\n",
    "            \"fontsize\":8, \n",
    "            \"horizontalalignment\":'left',\n",
    "            \"path_effects\":[PathEffects.withStroke(linewidth=1, foreground=\"k\")],\n",
    "        }\n",
    "    )\n",
    "p_right.set_title(\"Bins\")\n",
    "\n",
    "trans = transforms.blended_transform_factory(\n",
    "            p_right.transAxes, p_right.transData\n",
    "        )\n",
    "\n",
    "ax_left.set_ylabel(\"Normalized flux + offset\")\n",
    "fig.text(0.5, 0, 'Index', ha='left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig(\"/Users/mango/Desktop/binned_lc.png\", dpi=250, bbox_inches=\"tight\")\n",
    "\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/raw_blcs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offs = 0\n",
    "for BMA_val in BMA_vals:\n",
    "    p_right.annotate(\n",
    "        ', '.join(f\"{v:.3f}\" for v in BMA_val),\n",
    "        xy=(0.25, 1.002*(1 + offs)),\n",
    "        xycoords=trans,\n",
    "        fontsize=8,\n",
    "        color='y',\n",
    "    )\n",
    "    offs += 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['idx_usable_wl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['optimal spectra']['wavelengths']#[data['idx_usable_wl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['idx_usable_wl'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "data = np.c_[time[idxs_used], fluxes]\n",
    "p = pathlib.Path(\"xo/WASP43/ut180603/binned_free_rho_star\")\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "np.save(f\"{p}/lc_w.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(p / \"lc_w.npy\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detrending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\n",
    "    \"./Projects/HATP26b/data_detrending/out_wa/HATP26/hp26_190313_wa/white-light/comps.da\",\n",
    "    unpack=True,\n",
    ")\n",
    "for i in range(len(data)):\n",
    "    x = (data[i] - np.mean(data[i])) / np.sqrt(np.var(data[i]))\n",
    "    if i == 0:\n",
    "        Xc = x\n",
    "    else:\n",
    "        Xc = np.vstack((Xc, x))\n",
    "\n",
    "Xc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\n",
    "    \"./Projects/HATP26b/data_detrending/out_wa/HATP26/hp26_190313_wa/eparams.dat\",\n",
    "    unpack=True,\n",
    ")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = utils.pkl_load(\n",
    "    \"./Projects/HATP26b/data_detrending/out_st/HATP26/hp26_190313_st/white-light/PCA_2/posteriors_trend_george.pkl\"\n",
    ")\n",
    "post[\"posterior_samples\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post[\"posterior_samples\"][\"mmean\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMA = utils.pkl_load(\n",
    "    \"./Projects/HATP26b/data_detrending/out_st/HATP26/hp26_190313_st/white-light/BMA_posteriors.pkl\"\n",
    ")\n",
    "BMA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_params = {\n",
    "    'ld_law': 'logarithmic',\n",
    "    'q1': 0.5,\n",
    "    'q2': 0.5,\n",
    "    't0': 2457561.8458,\n",
    "    'P': 1.2128867,\n",
    "    'p': 0.1113,\n",
    "    'a': 4.26,\n",
    "    'inc': 85.10,\n",
    "}\n",
    "\n",
    "t = np.linspace(np.min(t), np.max(t), 100)\n",
    "lc_model = utils.get_transit_model(t, lc_params)\n",
    "plt.plot(t, lc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External params\n",
    "\n",
    "# Get median of FWHM, background flux, accross all wavelengths, and trace position of zero point.\n",
    "# First, find chips-names of target:\n",
    "target = b\"HATP23\"\n",
    "names = []\n",
    "for name in data['fwhm'].keys():\n",
    "    if target in name:\n",
    "        names.append(name)\n",
    "if len(names) == 1:\n",
    "    Xfwhm = data['fwhm'][names[0]]\n",
    "    Xsky = data['sky'][names[0]]\n",
    "else:\n",
    "    Xfwhm = np.hstack((data['fwhm'][names[0]],data['fwhm'][names[1]]))\n",
    "    Xsky = np.hstack((data['sky'][names[0]],data['sky'][names[1]]))\n",
    "\n",
    "fwhm = np.zeros(Xfwhm.shape[0])\n",
    "sky = np.zeros(Xfwhm.shape[0])\n",
    "trace = np.zeros(Xfwhm.shape[0])\n",
    "target = \"HATP23\"\n",
    "for i in range(len(fwhm)):\n",
    "    idx = np.where(Xfwhm[i,:]!=0)[0]\n",
    "    fwhm[i] = np.median(Xfwhm[i,idx])\n",
    "    idx = np.where(Xsky[i,:]!=0)[0]\n",
    "    sky[i] = np.median(Xsky[i,idx])\n",
    "    trace[i] = np.polyval(data['traces'][target][i],Xfwhm.shape[1]/2)\n",
    "    \n",
    "eparams = np.c_[data['t'] - 2457000, data['Z'], data[\"deltas\"][f\"{target}_final\"], fwhm, sky, trace]\n",
    "eparams = eparams[i_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Time', 'Airmass', 'Delta_Wav', 'FWHM', 'Sky_Flux', 'Trace_Center']\n",
    "df_eparams = pd.DataFrame(eparams, columns=columns)\n",
    "\n",
    "df_eparams[\"Instrument\"] = [\"MAGELLAN\"] * df_eparams.shape[0]\n",
    "df_eparams.to_csv(\n",
    "    \"juliet/hatp23_test/GP_lc_regressors.dat\",\n",
    "    sep=' ',\n",
    "    index=False,\n",
    "    header=False,\n",
    "    float_format=\"%.10f\",\n",
    ")\n",
    "df_eparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMA WLC + components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import batman\n",
    "import george\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.constants import G as const_G\n",
    "\n",
    "# User inputs\n",
    "out_folder = \"./Projects/HATP26b/data_detrending/out_st/HATP26/hp26_190313_st/white-light\"\n",
    "\n",
    "# Constants\n",
    "G = const_G.cgs.value\n",
    "\n",
    "BMA_WLC = utils.detrend_BMA_WLC(out_folder)\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=FIG_LARGE, sharex=True)\n",
    "\n",
    "phase = range(len(BMA_WLC[\"LC_det\"]))#utils.get_phases(*(BMA_WLC[k] for k in (\"t\", \"P\", \"t0\")))\n",
    "axes[0].errorbar(\n",
    "    phase,\n",
    "    BMA_WLC[\"LC_det\"],\n",
    "    yerr=BMA_WLC[\"LC_det_err\"],\n",
    "    fmt='.',\n",
    "    lw=0.5,\n",
    "    zorder=1,\n",
    ")\n",
    "axes[0].plot(\n",
    "    phase,\n",
    "    BMA_WLC[\"LC_transit_model\"],\n",
    "    c='k',\n",
    "    lw=3,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axes[0].annotate(\n",
    "    \"BMA detrended\",\n",
    "    c=\"C0\",\n",
    "    xy=(0.7, 0.3),\n",
    "    xycoords=axes[0].transAxes,\n",
    ")\n",
    "\n",
    "axes[1].plot(phase, BMA_WLC[\"comp_model\"], c=\"C1\")\n",
    "axes[1].annotate(\n",
    "    \"comp model\",\n",
    "    c=\"C1\",\n",
    "    xy=(0.7, 0.3),\n",
    "    xycoords=axes[1].transAxes,\n",
    ")\n",
    "\n",
    "axes[2].plot(phase, BMA_WLC[\"LC_systematics_model\"], c=\"C2\")\n",
    "axes[2].annotate(\n",
    "    \"systematics model\",\n",
    "    c=\"C2\",\n",
    "    xy=(0.7, 0.3),\n",
    "    xycoords=axes[2].transAxes,\n",
    ")\n",
    "\n",
    "axes[3].plot(phase, BMA_WLC[\"pred_mean\"], c=\"C3\")\n",
    "axes[3].annotate(\n",
    "    \"pred mean\",\n",
    "    c=\"C3\",\n",
    "    xy=(0.7, 0.3),\n",
    "    xycoords=axes[3].transAxes,\n",
    ")\n",
    "#axes[3].set_xlabel(\"Phase (hours)\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes[4].plot(phase, tep_data[\"etimes\"][idxs_used], c=\"C4\")\n",
    "axes[4].annotate(\n",
    "    \"exposure time\",\n",
    "    c=\"C4\",\n",
    "    xy=(0.7, 0.3),\n",
    "    xycoords=axes[4].transAxes,\n",
    ")\n",
    "axes[4].set_xlabel(\"Phase (hours)\")\n",
    "\n",
    "#utils.savepng(\"/home/mango/Desktop/BMA_WLC_components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tep_data = utils.pkl_load(\n",
    "    \"Projects/HATP26b/data_reductions/ut190313_a15_25_noflat_LBR/LCs_bins_stevenson_combined.pkl\"\n",
    ")\n",
    "tep_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = tep_data[\"t\"]\n",
    "bad_idxs = utils._bad_idxs(\"[4, 5, 11, 12]\")\n",
    "idxs_used = np.delete(range(len(time)), bad_idxs)\n",
    "idxs_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMA WLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_theme('paper')\n",
    "# data = {\n",
    "#     #'Transit 1':'160621',\n",
    "#     #'Transit 2':'170609',\n",
    "#     #'Transit 3':'180603',\n",
    "#     #'Transit 4':'180620',\n",
    "#     'Transit 5':'180821',\n",
    "# }\n",
    "data_dir = \"HATP26b/data_detrending\"\n",
    "data = {\n",
    "    \"Transit 1\":f\"data_detrending/HATP26b/out_p/HATP26b/hp26_190313_st/white-light\"\n",
    "}\n",
    "\n",
    "for i, (transit_name, transit_path) in enumerate(data.items()):\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 1,\n",
    "        sharex=True,\n",
    "        gridspec_kw={'height_ratios':[5, 1]}\n",
    "    )\n",
    "    ax_top, ax_bottom = axes\n",
    "    \n",
    "    # Compute BMA_WLC\n",
    "    BMA_WLC = utils.detrend_BMA_WLC(transit_path)\n",
    "    phase = utils.get_phases(*(BMA_WLC[k] for k in (\"t\", \"P\", \"t0\")))\n",
    "    #phase = range(len(phase))\n",
    "    #phase *= 24 # Convert to hours\n",
    "    \n",
    "    # Plot BMA WLC and transit model \n",
    "    axes[0].errorbar(\n",
    "        phase,\n",
    "        BMA_WLC[\"LC_det\"],\n",
    "        yerr=BMA_WLC[\"LC_det_err\"],\n",
    "        fmt='.',\n",
    "        lw=0.5,\n",
    "        zorder=1,\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        phase,\n",
    "        BMA_WLC[\"LC_transit_model\"],\n",
    "        c='k',\n",
    "        lw=3,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    \n",
    "    # Residuals\n",
    "    resids = BMA_WLC[\"LC_det\"] - BMA_WLC[\"LC_transit_model\"]\n",
    "    ax_bottom.plot(phase, resids * 1e6, '.', mew=0)\n",
    "    trans = transforms.blended_transform_factory(\n",
    "            ax_bottom.transData, ax_bottom.transAxes\n",
    "        )\n",
    "    ax_bottom.axhline(0, c='k', lw=3, alpha=0.5)\n",
    "\n",
    "    rms = np.std(resids) * 1e6\n",
    "    ax_bottom.annotate(\n",
    "        f\"{int(rms)}\",\n",
    "        xy=(1.02*phase[-1], 0.55),\n",
    "        xycoords=trans,\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "    #ax_top.legend(loc=4, frameon=True)\n",
    "    #ax_top.set_title(title)\n",
    "    #fig.text(0.5, 0, 'Phase (hours)', ha='left')\n",
    "    ax_bottom.set_xlabel('Phase')\n",
    "    #ax_top.set_xlim(-1., 1.)\n",
    "    #ax_top.set_ylim(0.990, 1.002)\n",
    "    #ax_bottom.set_ylim(-2000, 2000)\n",
    "    ax_top.set_ylabel(\"Normalized flux\")\n",
    "    ax_bottom.set_ylabel('ppm')\n",
    "    #ax.xaxis.set_major_locator(HOURS)\n",
    "    #ax.set_xlim(2.457561e6 + 0.76, 2.457561e6 + 0.92)\n",
    "    #ax.set_ylim(0.982, 1.00143)\n",
    "\n",
    "    fig.set_size_inches(FIG_WIDE)\n",
    "    fig.tight_layout()\n",
    "    title = transit_name.lower().replace(' ', '_') + '_detr_wlcs'\n",
    "    #utils.savefig(f'projects/HATP23b/paper/figures/detrended_wlcs/{title}.pdf')\n",
    "\n",
    "    #plt.savefig(\"/Users/mango/Desktop/wlc_gpts_ut160621.png\", dpi=250, bbox_inches=\"tight\")\n",
    "    #utils.savepng(\"/home/mango/Desktop/wlc_det\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detLC = pd.read_table(\n",
    "    \"Projects/HATP26b/data_detrending/out_c3/HATP26/hp26_190313_st/white-light/PCA_1/detrended_lc.dat\",\n",
    "    sep=\"\\s+\",\n",
    "    escapechar='#',\n",
    ")\n",
    "plt.plot(detLC[\"DetFlux\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/data_detrending/HATP23_c'\n",
    "binsize = 'custom'\n",
    "data_dict = {\n",
    "    'Transit 1':\n",
    "    f'{data_dir}/hp23b_160621_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 2':\n",
    "    f'{data_dir}/hp23b_170609_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 3':\n",
    "    f'{data_dir}/hp23b_180603_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 4':\n",
    "    f'{data_dir}/hp23b_180620_{binsize}/white-light/results.dat',\n",
    "    \n",
    "    'Transit 5':\n",
    "    f'{data_dir}/hp23b_180821_{binsize}/white-light/results.dat',\n",
    "}\n",
    "\n",
    "# truths from Sada and Ramon (2016) + GAIA DR2\n",
    "with open(f'{data_dir}/truth.json', 'rb') as f:\n",
    "    parameters = json.load(f)\n",
    "\n",
    "parameters['d'] = {\n",
    "    'symbol': '$\\delta$',\n",
    "    'truth': [0.1113**2 * 1e6, 0.001**2 * 1e6, 0.0009**2 * 1e6],\n",
    "    'definition': 'transit depth (ppm)'\n",
    "}\n",
    "\n",
    "# holds results from each transit\n",
    "df_results = {}\n",
    "for transit, fpath in data_dict.items():\n",
    "    df_results[transit] = pd.read_table(fpath, sep='\\s+',index_col='Variable')\n",
    "    df_results[transit].loc['t0']['Value'] -= 2450000\n",
    "    p_val, p_u, p_d = df_results[transit].loc['p'].values.T\n",
    "    df_results[transit].loc['d'] = p_val**2 * 1e6, p_u**2 * 1e6, p_d**2 * 1e6\n",
    "    \n",
    "def write_latex(param, df):\n",
    "    v, vu, vd = df.loc[param]\n",
    "    return f'{v:.5f}^{{+{vu:.5f}}}_{{-{vd:.5f}}}'\n",
    "\n",
    "# Create summary table of all transits\n",
    "results_dict = {}\n",
    "results_dict['parameter'] = [p[\"symbol\"] for p in parameters.values()]\n",
    "#results_dict['definition'] = [p[\"definition\"] for p in parameters.values()]\n",
    "for transit, results in df_results.items():\n",
    "    results_dict[transit] = []\n",
    "    for param, param_info in parameters.items():\n",
    "        results_dict[transit].append(write_latex(param, results))\n",
    "        \n",
    "results_table = pd.DataFrame(results_dict)\n",
    "results_table#.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"Transit 1\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.weighted_mean_uneven_errors(*get_params_and_uncs(\"p\"))[0]**2*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.weighted_mean_uneven_errors(*get_params_and_uncs(\"d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_params_and_uncs(\"p\")[0]**2*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_params_and_uncs(\"d\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transits = [f\"Transit {i}\" for i in range(1, 6)]\n",
    "\n",
    "def get_params_and_uncs(param):\n",
    "    ps, p_us, p_ds = [], [], []\n",
    "    for transit in transits:\n",
    "        df_transit = df_results[transit]\n",
    "        p, p_u, p_d = df_transit.loc[param][[\"Value\", \"SigmaUp\", \"SigmaDown\"]]\n",
    "        ps.append(p)\n",
    "        p_us.append(p_u)\n",
    "        p_ds.append(p_d)\n",
    "    return np.array(ps), np.array(p_us), np.array(p_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.constants as c\n",
    "\n",
    "#set_theme('paper')\n",
    "# Load\n",
    "data_dir = \"data_detrending/HATP26b/out_np/HATP26b/hp26_190313_st\"\n",
    "fpath_truths = f\"{data_dir}/../../../truth.json\"\n",
    "with open(fpath_truths) as f:\n",
    "    params_dict = json.load(f)\n",
    "\n",
    "def write_latex(row):\n",
    "    v, vu, vd = row\n",
    "    return f'{v:.4f}^{{+{vu:.4f}}}_{{-{vd:.4f}}}'\n",
    "\n",
    "data_dict = {\n",
    "    \"Transit 1\":\n",
    "    f\"{data_dir}/white-light/BMA_posteriors.pkl\",\n",
    "}\n",
    "\n",
    "# Plot\n",
    "fig = None # Initialize figure\n",
    "for t_i, (transit_name, fpath) in enumerate(data_dict.items()):\n",
    "    # Load\n",
    "    data = utils.pkl_load(fpath)\n",
    "    if 'rho' not in data.keys():\n",
    "        G = c.G.cgs.value\n",
    "        aR = data['aR']\n",
    "        P = data['P']\n",
    "        data['rho'] = 3.0*np.pi * aR**3 / (G*(P*86400.0)**2)\n",
    "    samples = pd.DataFrame({k:v for (k, v) in data.items() if \"xc\" not in k})[params_dict.keys()]\n",
    "    if 'WASP43' not in data_dir:\n",
    "        samples['t0'] -= 2450000\n",
    "    \n",
    "    mins = np.min(np.array([samples.min(), samples.min()]), axis=0)\n",
    "    maxs = np.min(np.array([samples.max(), samples.max()]), axis=0)\n",
    "    ranges = list(zip(mins, maxs))\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = utils.plot_corner(\n",
    "        samples,\n",
    "        fpath_truths,\n",
    "        c=f'C{t_i}',\n",
    "        fig=fig,\n",
    "        ranges=ranges,\n",
    "    )\n",
    "    \n",
    "    # Custom titles\n",
    "    ps = [0.16, 0.5, 0.84]\n",
    "    ps_strs = [f'{p*100:.0f}%' for p in ps]\n",
    "    df_stats = samples.describe(percentiles=ps).loc[ps_strs]\n",
    "    df_latex = pd.DataFrame(columns=df_stats.columns)\n",
    "    df_latex.loc['p'] = df_stats.loc['50%']\n",
    "    df_latex.loc['p_u'] = df_stats.loc['84%'] - df_stats.loc['50%']\n",
    "    df_latex.loc['p_d'] = df_stats.loc['50%'] - df_stats.loc['16%']\n",
    "    \n",
    "    titles = df_latex.apply(write_latex, axis=0).to_list()\n",
    "    \n",
    "    ndim = samples.shape[1]\n",
    "    axes = np.array(fig.axes).reshape((ndim, ndim))\n",
    "    for i, (param_key, param_data) in enumerate(params_dict.items()):\n",
    "        ax = axes[i, i] # select 1d hist\n",
    "        ax.annotate(\n",
    "            f'${titles[i]}$',\n",
    "            xy=(0.0, 1.1 + t_i/4.0),\n",
    "            xycoords='axes fraction',\n",
    "            ha=\"left\",\n",
    "            color=f'C{t_i}',\n",
    "            fontsize=14,\n",
    "        )\n",
    "    \n",
    "# Label custom titles\n",
    "for i, (param_key, param_data) in enumerate(params_dict.items()):\n",
    "    ax = axes[i, i] # select 1d hist\n",
    "    ax.annotate(\n",
    "        f'{param_data[\"symbol\"]}',\n",
    "        xy=(0.5, 1.1 + (t_i+1)/4.0),\n",
    "        xycoords='axes fraction',\n",
    "        ha='center',\n",
    "        #color='w',\n",
    "    )  \n",
    "    p_mean, p_u, p_d = param_data[\"truth\"] # Unpack mean +/-\n",
    "    ax.axvspan(p_mean - p_u, p_mean + p_u, alpha=0.75, color='grey',\n",
    "               lw=0, zorder=0)\n",
    "    ax.axvline(p_mean, color='w')\n",
    "\n",
    "# True values\n",
    "with open(fpath_truths) as f:\n",
    "    params_dict = json.load(f)\n",
    "truths = [v['truth'][0] for v in params_dict.values()]\n",
    "ndim = len(truths)\n",
    "for yi in range(ndim):\n",
    "    for xi in range(yi):\n",
    "        ax = axes[yi, xi]\n",
    "        ax.plot(truths[xi], truths[yi], \"P\", ms=10, mec=\"grey\", mfc=\"w\")\n",
    "\n",
    "# Custom legend\n",
    "handles, labels = [], []\n",
    "for transit_name in list(data_dict.keys()):\n",
    "    dummy, = plt.plot([], [], 'D', ms=12, mfc='none', mew=2, label=transit_name)\n",
    "    handles.append(dummy)\n",
    "    labels.append(transit_name)\n",
    "fig.legend(handles, labels, loc=1, fontsize=18, ncol=len(data_dict)+1)  \n",
    "\n",
    "fig.set_size_inches(14, 14)\n",
    "# Save\n",
    "#utils.savefig(f\"projects/HATP23b/paper/figures/detrended_wlcs_corners/corner_wlcs.pdf\")\n",
    "#title = data_dir.split('/')[-1]\n",
    "#utils.savepng(\"/home/mango/Projects/HATP26b/journal/figures/wlc_corner\")\n",
    "#utils.savepng(\"/home/mango/Desktop/wlc_corner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 2],\n",
    "          [3, 4],\n",
    "          [5, 6]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1],\n",
    "        [2],\n",
    "        [3]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2, 3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantiles(dist,alpha = 0.68, method = 'median'):\n",
    "    \"\"\" \n",
    "    get_quantiles function\n",
    "    DESCRIPTION\n",
    "        This function returns, in the default case, the parameter median and the error% \n",
    "        credibility around it. This assumes you give a non-ordered \n",
    "        distribution of parameters.\n",
    "    OUTPUTS\n",
    "        Median of the parameter,upper credibility bound, lower credibility bound\n",
    "    \"\"\"\n",
    "    ordered_dist = dist[np.argsort(dist)]\n",
    "    param = 0.0 \n",
    "    # Define the number of samples from posterior\n",
    "    nsamples = len(dist)\n",
    "    nsamples_at_each_side = int(nsamples*(alpha/2.)+1)\n",
    "    if(method == 'median'):\n",
    "        med_idx = 0 \n",
    "        if(nsamples%2 == 0.0): # Number of points is even\n",
    "            med_idx_up = int(nsamples/2.)+1\n",
    "            med_idx_down = med_idx_up-1\n",
    "            param = (ordered_dist[med_idx_up]+ordered_dist[med_idx_down])/2.\n",
    "            return param,ordered_dist[med_idx_up+nsamples_at_each_side],\\\n",
    "                   ordered_dist[med_idx_down-nsamples_at_each_side]\n",
    "        else:\n",
    "            med_idx = int(nsamples/2.)\n",
    "            param = ordered_dist[med_idx]\n",
    "            return param,ordered_dist[med_idx+nsamples_at_each_side],\\\n",
    "                   ordered_dist[med_idx-nsamples_at_each_side]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1.2128867\n",
    "sigma = 0.0000002\n",
    "x1 = 1.21288287\n",
    "x2 = mu + 2*sigma\n",
    "\n",
    "z1 = ( x1 - mu ) / sigma\n",
    "z2 = ( x2 - mu ) / sigma\n",
    "\n",
    "x = np.arange(z1, z2, 0.001) # range of x in spec\n",
    "x_all = np.arange(-10, 10, 0.001) # entire range of x, both in and out of spec\n",
    "# mean = 0, stddev = 1, since Z-transform was calculated\n",
    "y = sp.stats.norm.pdf(x, 0, 1)\n",
    "y2 = sp.stats.norm.pdf(x_all, 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.axvline(z1)\n",
    "ax.axvline(z2)\n",
    "ax.plot(x_all,y2)\n",
    "ax.fill_between(x, y, 0, alpha=0.3, color='b')\n",
    "#ax.fill_between(x_all, y2, 0, alpha=0.1)\n",
    "#ax.set_xlim([-4,4])\n",
    "ax.set_xlabel('# of Standard Deviations Outside the Mean')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('Normal Gaussian Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.212880 - 3*0.000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [0.16, 0.5, 0.84]\n",
    "ps_strs = [f'{p*100:.0f}%' for p in ps]\n",
    "df_stats = samples_new.describe(percentiles=ps).loc[ps_strs]\n",
    "df_latex = pd.DataFrame(columns=df_stats.columns)\n",
    "df_latex.loc['p'] = df_stats.loc['50%']\n",
    "df_latex.loc['p_u'] = df_stats.loc['84%'] - df_stats.loc['50%']\n",
    "df_latex.loc['p_d'] = df_stats.loc['50%'] - df_stats.loc['16%']\n",
    "df_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_quantiles(samples_new['inc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = sorted(glob.glob('data/data_detrending/HATP23_*'))\n",
    "\n",
    "for data_dir in data_dirs:\n",
    "    print(data_dir)\n",
    "    fpaths = glob.glob(f'{data_dir}/hp*/white-light/PCA_*/posteriors_trend_george.pkl')\n",
    "\n",
    "    for fpath in sorted(fpaths):\n",
    "        lnZ = utils.pkl_load(fpath)['lnZ']\n",
    "        print(lnZ)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = utils.pkl_load(\n",
    "    \"Projects/HATP26b/data_detrending/out_st/HATP26/hp26_190313_st/wavelength/wbin13/PCA_2/posteriors_trend_george.pkl\"\n",
    ")\n",
    "post[\"posterior_samples\"][\"xc1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Read in data\n",
    "##############\n",
    "data = {\"Transit 1\":\"190313\"}\n",
    "# data = {\n",
    "#     'Transit 1':'160621',\n",
    "#     'Transit 2':'170609',\n",
    "#     'Transit 3':'180603',\n",
    "#     'Transit 4':'180620',\n",
    "#     'Transit 5':'180821',\n",
    "# }\n",
    "#binsize = \"custom\"\n",
    "for title, date in data.items():\n",
    "    #GPT_dir = f\"data/data_detrending/HATP23_c/hp23b_{date}_{binsize}\"\n",
    "    GPT_dir = \"./Projects/HATP26b/data_detrending/out_st/HATP26/hp26_190313_st\"\n",
    "    def wbin_num(fpath):\n",
    "        # Extracts <num> from fpath = .../wbin<num>/...\n",
    "        tokens = fpath.split('/')\n",
    "        for token in tokens:\n",
    "            if \"wbin\" in token: # Do the extraction\n",
    "                bin_str = token.split(\"wbin\")[-1]\n",
    "                bin_num = int(bin_str)\n",
    "                return(bin_num)\n",
    "    wbin_paths = sorted(glob.glob(f'{GPT_dir}/wavelength/wbin*'), key=wbin_num)\n",
    "    PCA_list = []\n",
    "    for wbin_path in wbin_paths:\n",
    "        PCA_paths = glob.glob(f'{wbin_path}/PCA*')\n",
    "        PCAs = [path.split('/')[-1] for path in PCA_paths]\n",
    "        PCA_list.append(PCAs)\n",
    "\n",
    "    common_PCAs = set(PCA_list[0])\n",
    "    for s in PCA_list[1:]:\n",
    "        common_PCAs.intersection_update(s)\n",
    "\n",
    "    PCA_max = max(common_PCAs, key=lambda s: int(s.split('_')[-1]))\n",
    "    PCA_num = int(PCA_max.split('_')[-1])\n",
    "    print(f'max common PCA = {PCA_num}')\n",
    "\n",
    "    # getting t0 from WLC data\n",
    "    def get_result(fpath, key=\"t0\", unc=True):\n",
    "        data = np.genfromtxt(fpath, encoding=None, dtype=None)\n",
    "        for line in data:\n",
    "            if key in line: \n",
    "                if unc: return line\n",
    "                else: return line[1]\n",
    "\n",
    "        print(f\"'{key}' not found. Check results.dat file.\")        \n",
    "    fpath = f\"{GPT_dir}/white-light/results.dat\"\n",
    "    t0 = float(get_result(fpath, key=\"t0\", unc=False))\n",
    "    P = float(get_result(fpath, key=\"P\", unc=False))\n",
    "\n",
    "    # Get wavelength bins\n",
    "    fpath = f\"{GPT_dir}/transpec.csv\"\n",
    "    wbins = np.loadtxt(fpath, skiprows=1, usecols=[0, 1], delimiter=',')\n",
    "\n",
    "    # Glob doesn't automatically sort, but instead follows your local filesystem's \n",
    "    # rules, which can be very system dependent. \n",
    "    # To avoid potential cross-platform issues, I just sort based on an explicit\n",
    "    # rule that is passed to `sorted`. In this case, the rule is: \n",
    "    # sort based on the <num> part in wbin<num> of each file path.\n",
    "    dirpath = f\"{GPT_dir}/wavelength\"\n",
    "    detrended_files = f\"{dirpath}/wbin*/PCA_{PCA_num}/detrended_lc.dat\"\n",
    "    BMA_files = f\"{dirpath}/wbin*/BMA_posteriors.pkl\"\n",
    "    fpaths = sorted(glob.glob(detrended_files), key=wbin_num)\n",
    "    fpaths_BMA = sorted(glob.glob(BMA_files), key=wbin_num)\n",
    "    \n",
    "    # Store final data in <# of wavelength bins> x <length of timeseries> arrays \n",
    "    detfluxes, models, resids = [], [], []\n",
    "    BMA_vals = []\n",
    "    BMA_keys = [\"max_var\", \"jitter\"]\n",
    "    for fpath, fpath_BMA in zip(fpaths, fpaths_BMA):\n",
    "        time, detflux, detfluxerr, model = np.loadtxt(fpath, unpack=True)\n",
    "        BMA = utils.pkl_load(fpath_BMA)\n",
    "        BMA_vals.append([BMA[k].mean() * 1e6 for k in BMA_keys])\n",
    "        detfluxes.append(detflux)\n",
    "        models.append(model)\n",
    "        resids.append(detflux - model + 1)\n",
    "    BMA_vals = np.array(BMA_vals)\n",
    "    detfluxes = np.array(detfluxes).T\n",
    "    models = np.array(models).T\n",
    "    #resids = np.array(resids).T\n",
    "    resids = (detfluxes / np.median(detfluxes, axis=0)) - fluxes + 1\n",
    "    phase = utils.get_phases(time, P, t0)\n",
    "    time_rel = phase*24 #(time - t0)*24 # Convert to hours\n",
    "\n",
    "    ###################################\n",
    "    # Plot detrended flux and residuals\n",
    "    ###################################\n",
    "    # Plot configs\n",
    "    N = detfluxes.shape[1] # number of wavelength bins\n",
    "    colors = np.array(sns.color_palette(\"Spectral_r\", N))\n",
    "\n",
    "    offset = 0.008 # 0.01 # spacing betweem binned lcs\n",
    "    # Optional bins to highlight\n",
    "    species = {\n",
    "        'Na I-D':5892.9,\n",
    "        #'HÎ±':6564.6,\n",
    "        'K I':7682.0,\n",
    "        'Na I-8200':8189.0\n",
    "    }\n",
    "    scatter_plot_kwargs = {\n",
    "        \"marker\":\".\", \n",
    "        \"lw\":0, \n",
    "        \"mew\":0, # Make non-zero to show marker outlines\n",
    "        #\"mec\":'k', # Won't show if `mew`=0\n",
    "    }\n",
    "    annotate_kwargs = {\n",
    "        \"fontsize\":8, \n",
    "        \"horizontalalignment\":'right',\n",
    "        \"path_effects\":[PathEffects.withStroke(linewidth=1, foreground=\"k\")],\n",
    "    }\n",
    "    annotate_rms_kwargs = {\n",
    "        \"fontsize\":8, \n",
    "        \"horizontalalignment\":'left',\n",
    "        \"path_effects\":[PathEffects.withStroke(linewidth=1, foreground=\"k\")],\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 11), sharex=True, sharey=True)\n",
    "    ax_left, ax_right = axes.flatten()\n",
    "\n",
    "    # detrended flux\n",
    "    ax_left.set_title('Detrended flux')\n",
    "    p_det = utils.plot_binned(ax_left, time_rel, detfluxes, wbins, offset, colors, \n",
    "                              plot_kwargs=scatter_plot_kwargs, models=models)\n",
    "\n",
    "    # residual flux\n",
    "#     ax_right.set_title('Residuals')\n",
    "    ax_right.set_title('DetFlux/median(DetFlux) - Divided BLCS')\n",
    "    baselines = np.ones_like(resids)\n",
    "    p_res = utils.plot_binned(\n",
    "        ax_right,\n",
    "        time_rel,\n",
    "        resids,\n",
    "        wbins,\n",
    "        offset,\n",
    "        colors, \n",
    "        plot_kwargs=scatter_plot_kwargs,\n",
    "        models=baselines,\n",
    "        annotate=True,\n",
    "        annotate_kwargs=annotate_kwargs,\n",
    "        annotate_rms_kwargs=annotate_rms_kwargs,\n",
    "        species=species,\n",
    "    )\n",
    "    \n",
    "    trans = transforms.blended_transform_factory(\n",
    "                ax_right.transData, ax_right.transData\n",
    "            )\n",
    "    offs = 0\n",
    "    for BMA_val in BMA_vals:\n",
    "        ax_right.annotate(\n",
    "            ', '.join(f\"{v:.3f}\" for v in BMA_val),\n",
    "            xy=(-0.23, 1.002*(1 + offs)),\n",
    "            xycoords=trans,\n",
    "            fontsize=8,\n",
    "            color='y',\n",
    "        )\n",
    "        offs += offset\n",
    "        \n",
    "    ax_left.set_ylabel(\"Normalized flux + offset\")\n",
    "    fig.text(0.47, 0, 'Phase (hours)', ha='left')\n",
    "\n",
    "    ax_left.set_xlim(-0.6, 0.6)\n",
    "\n",
    "    fig.set_size_inches(8, 8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    #plt.savefig(\"/Users/mango/Desktop/wlc_access.png\", dpi=250, bbox_inches=\"tight\")\n",
    "\n",
    "    title = title.lower().replace(' ', '_') + '_detr_blcs'\n",
    "    #utils.savefig(f\"projects/HATP23b/paper/figures/detrended_blcs/{title}.pdf\")\n",
    "    #utils.savepng(\"/home/mango/Projects/HATP26b/journal/blcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i = 10\n",
    "plt.plot((detfluxes[:, i] / np.median(detfluxes[:, i])) - fluxes[:, i], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(detfluxes / np.median(detfluxes, axis=0)) - fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.pkl_load(\n",
    "    \"./Projects/HATP26b/data_detrending/out_wa/HATP26/hp26_190313_wa/wavelength/wbin0/BMA_posteriors.pkl\"\n",
    ")\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(1, 4, size=(5, 3, 4))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, a in enumerate(x):\n",
    "    print(a)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmission spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.constants as c\n",
    "set_theme(\"dark\")\n",
    "\n",
    "data_paths_glob = \"data_detrending/HATP26b/out_c1/HATP26b/hp26_190313_st\"\n",
    "#data_paths_glob = \"Projects/HATP26b/data_detrending/out_st_using_mdwarf_c03/HATP26/hp26_190313_st\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=FIG_WIDE, sharex=True)\n",
    "ax_top, ax_bottom = axes\n",
    "\n",
    "utils.plot_binned_BMA(ax_top, data_paths_glob)\n",
    "\n",
    "p, tspec_data, wlc_data = utils.plot_tspec(\n",
    "    ax_bottom,\n",
    "    data_paths_glob,\n",
    "    combine=False,\n",
    ")\n",
    "\n",
    "#ax.set_xlim(5_000, 9_200)\n",
    "ax_top.set_ylim(0, 5)\n",
    "ax_bottom.set_ylim(4_000, 7_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transit 1\n",
      "(17,)\n",
      "Transit 2\n",
      "(17,)\n",
      "Transit 3\n",
      "(17,)\n",
      "Transit 4\n",
      "(17,)\n",
      "Transit 5\n",
      "(17,)\n",
      "offsets: [-360.38370533 -228.91794043  626.00316194  259.30348806 -113.60920387]\n",
      "offsets (% mean wlc depth): [-2.78392137 -1.76836393  4.83580017  2.00308868 -0.87761762]\n",
      "Saving tspec to: Projects/HATP23b/data_detrending/out_c/HATP23b/tspec.csv\n",
      "mean WLC depth: 12945.182608127869 2.168930318004236\n",
      "Rs (Rsun): 0.96 solRad\n",
      "Rp (Rj): 1.0628938158690115 jupiterRad\n",
      "gp (m/s^2): 29.618942962205868 m / s2\n"
     ]
    }
   ],
   "source": [
    "set_theme(\"paper\")\n",
    "\n",
    "base_dir = \"Projects/HATP23b/data_detrending/out_c/HATP23b\"\n",
    "binsize = \"custom\"\n",
    "data_dict = {\n",
    "    \"Transit 1\":f\"{base_dir}/hp23b_160621_custom\",\n",
    "    \"Transit 2\":f\"{base_dir}/hp23b_170609_custom\",\n",
    "    \"Transit 3\":f\"{base_dir}/hp23b_180603_custom\",\n",
    "    \"Transit 4\":f\"{base_dir}/hp23b_180620_custom\",\n",
    "    \"Transit 5\":f\"{base_dir}/hp23b_180821_custom\",\n",
    "}\n",
    "\n",
    "# Use first entry for wavelength\n",
    "transit_0, dirpath_0 = \"Transit 1\", data_dict[\"Transit 1\"]\n",
    "fpath = f'{dirpath_0}/transpec.csv'\n",
    "df_wavs = pd.read_csv(fpath)[['Wav_d', 'Wav_u']]\n",
    "wav = np.mean(df_wavs, axis=1)\n",
    "\n",
    "depth_wlc_stats = []\n",
    "tspec_stats = []\n",
    "for transit, dirpath in data_dict.items():\n",
    "    print(transit)\n",
    "    # WLCs\n",
    "    fpath = f'{dirpath}/white-light/results.dat'\n",
    "    #p_stats = pd.read_table(fpath, sep='\\s+', escapechar='#').query('` Variable` == \"p\"')\n",
    "    results = pd.read_table(\n",
    "        fpath,\n",
    "        sep='\\s+',\n",
    "        escapechar='#',\n",
    "        index_col=\"Variable\",\n",
    "    )\n",
    "    p, p_u, p_d = results.loc[\"p\"]\n",
    "    wlc_depth = p**2 * 1e6\n",
    "    wlc_depth_u = p_u**2 * 1e6\n",
    "    wlc_depth_d = p_d**2 * 1e6\n",
    "    depth_wlc_stats.append([wlc_depth, wlc_depth_u, wlc_depth_d])\n",
    "    \n",
    "    # Tspec\n",
    "    fpath = f'{dirpath}/transpec.csv'\n",
    "    df_tspec = pd.read_csv(fpath)[\n",
    "        ['Depth (ppm)', 'Depthup (ppm)', 'DepthDown (ppm)']\n",
    "    ]\n",
    "        \n",
    "    if transit == \"Transit 1\" and binsize==\"custom\":\n",
    "        tspec, tspec_u, tspec_d = df_tspec.values.T\n",
    "    else:\n",
    "        tspec, tspec_u, tspec_d = df_tspec.values[1:-1, :].T\n",
    "        \n",
    "    print(tspec.shape)\n",
    "    tspec_stats.append([tspec, tspec_u, tspec_d])\n",
    "    \n",
    "# Compute offset\n",
    "depth_wlc_stats = np.array(depth_wlc_stats)\n",
    "depth_wlc, depth_wlc_u, depth_wlc_d = depth_wlc_stats.T\n",
    "mean_wlc_depth, mean_wlc_depth_unc = utils.weighted_mean_uneven_errors(\n",
    "    depth_wlc, depth_wlc_u, depth_wlc_d\n",
    ")\n",
    "\n",
    "wlc_offsets = depth_wlc - mean_wlc_depth\n",
    "#wlc_offsets *= 0\n",
    "print(f\"offsets: {wlc_offsets}\")\n",
    "print(f\"offsets (% mean wlc depth): {wlc_offsets*100/mean_wlc_depth}\")\n",
    "tspec_stats = np.array(tspec_stats) # transits x (depth, u, d) x wavelength\n",
    "tspec_stats[:, 0, :] -= wlc_offsets[np.newaxis].T\n",
    "\n",
    "tspec_depths = tspec_stats[:, 0, :]\n",
    "tspec_us = tspec_stats[:, 1, :]\n",
    "tspec_ds = tspec_stats[:, 2, :]\n",
    "\n",
    "######\n",
    "# Plot\n",
    "######\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "ax.axhline(mean_wlc_depth, color=\"darkgrey\", zorder=0, ls='--')\n",
    "\n",
    "# Species\n",
    "species = {\n",
    "    'Na I-D':5892.9, \n",
    "    #'HÎ±':6564.6, \n",
    "    'K I_avg':7682.0, \n",
    "    'Na I-8200_avg':8189.0\n",
    "}\n",
    "[ax.axvline(wav, ls='--', lw=0.5, color='grey', zorder=0) for name, wav in species.items()]\n",
    "\n",
    "tspec_tables = {} # Each entry will hold Table(Transit, Depth, Up , Down)\n",
    "# For combining into latex later\n",
    "#colors = ['C0', 'C2', 'C4']\n",
    "#for transit, tspec, tspec_d, tspec_u, c in zip(\n",
    "for transit, tspec, tspec_d, tspec_u, in zip(\n",
    "    data_dict.keys(),\n",
    "    tspec_depths,\n",
    "    tspec_ds,\n",
    "    tspec_us,\n",
    "    #colors,\n",
    "):\n",
    "    ax.errorbar(\n",
    "        wav,\n",
    "        tspec,\n",
    "        #xerr=[wav - df_wavs['Wav_d'], df_wavs['Wav_u'] - wav],\n",
    "        yerr=[tspec_d, tspec_u],\n",
    "        fmt='o',\n",
    "        alpha=1.0,\n",
    "        mew=0,\n",
    "        label=transit,\n",
    "        barsabove=False,\n",
    "        #color=c,\n",
    "    )\n",
    "    \n",
    "    BMA_keys = [\"max_var\"]\n",
    "    BMA_vals = []\n",
    "    for i, (w, flux) in enumerate(zip(wav, tspec)):\n",
    "        BMA = utils.pkl_load(\n",
    "            f\"{dirpath}/wavelength/wbin{i}/BMA_posteriors.pkl\",\n",
    "        )\n",
    "        vals = [BMA[k].mean() * 1e6 for k in BMA_keys]\n",
    "        BMA_vals.append(vals)\n",
    "#         ax.annotate(\n",
    "#             \"\\n\".join(f\"{v:.3f}\" for v in vals),\n",
    "#             xy=(w, flux*(1 - 0.4)),\n",
    "#             fontsize=8,\n",
    "#             ha=\"center\",\n",
    "#         )\n",
    "    data_i = {}\n",
    "    data_i['Depth (ppm)'] = tspec\n",
    "    data_i['Depthup (ppm)'] = tspec_u\n",
    "    data_i['DepthDown (ppm)'] = tspec_d\n",
    "    df = pd.DataFrame(data_i)\n",
    "    tspec_tables[transit] = df\n",
    "\n",
    "tspec_combined = []\n",
    "tspec_combined_unc = []\n",
    "tspec_combined_max = []\n",
    "tspec_combined_unc_max = []\n",
    "for i in range(len(tspec_stats[0, 0, :])):\n",
    "    tspec_comb, tspec_comb_unc = utils.weighted_mean_uneven_errors(\n",
    "        tspec_stats[:, 0, i],\n",
    "        tspec_stats[:, 1, i],\n",
    "        tspec_stats[:, 2, i],\n",
    "    )\n",
    "    tspec_combined.append(tspec_comb)\n",
    "    tspec_combined_unc.append(tspec_comb_unc)\n",
    "        \n",
    "    # single errorbar way\n",
    "    uncs_max = np.max([tspec_stats[:, 1, i], tspec_stats[:, 2, i]], axis=0)\n",
    "    weights = 1 / uncs_max**2\n",
    "    tspec_comb_max = np.average(tspec_stats[:, 0, i], weights=weights)\n",
    "    tspec_comb_max_unc = utils.weighted_err(uncs_max)\n",
    "    tspec_combined_max.append(tspec_comb_max)\n",
    "    tspec_combined_unc_max.append(tspec_comb_max_unc)\n",
    "\n",
    "# Combined\n",
    "tspec_combined = np.array(tspec_combined)\n",
    "tspec_combined_unc = np.array(tspec_combined_unc)\n",
    "p = ax.errorbar(\n",
    "    wav,\n",
    "    tspec_combined,\n",
    "    yerr=tspec_combined_unc,\n",
    "    c='w',\n",
    "    mec='k',\n",
    "    fmt='o',\n",
    "    zorder=10,\n",
    "    label=\"combined\",\n",
    "    ecolor='k',\n",
    "    lw=4,\n",
    ")\n",
    "#fpath = \"projects/HATP23b/data/tspec/tspec_combined.dat\"\n",
    "#fpath = \"/home/mango/Desktop/yea.dat\"\n",
    "#np.savetxt(fpath, np.c_[wav/1e4, tspec_combined*1e-6, tspec_combined_unc*1e-6])\n",
    "\n",
    "# Write to table\n",
    "tspec_table = pd.DataFrame()\n",
    "tspec_table['Wavelength (Ã…)'] = df_wavs.apply(utils.write_latex_wav, axis=1)\n",
    "# Transmission spectra\n",
    "for transit, df_tspec in tspec_tables.items():\n",
    "    tspec_table[transit] = df_tspec.apply(utils.write_latex_row, axis=1)\n",
    "data = np.array([tspec_combined, tspec_combined_unc]).T\n",
    "df_combined = pd.DataFrame(data, columns=[\"Combined\", \"Unc\"])\n",
    "tspec_table['Combined'] = df_combined.apply(utils.write_latex_single, axis=1)\n",
    "# Save table\n",
    "out_path_tspec = f\"{base_dir}/tspec.csv\"\n",
    "print(f\"Saving tspec to: {out_path_tspec}\")\n",
    "tspec_table.to_csv(out_path_tspec, index=False)\n",
    "\n",
    "ax.legend(ncol=6, loc=1, fontsize=12, frameon=True)\n",
    "#ax.set_xlim(5106.55, 9362.45)\n",
    "#ax.set_ylim(9_000, 17_000)\n",
    "\n",
    "# Inset plots\n",
    "if binsize==\"species\":\n",
    "    margin=10\n",
    "    utils.plot_inset(\n",
    "        ax,\n",
    "        species_slc=slice(0,5),\n",
    "        box_lims=[0.3, 0.15, 0.2, 0.2],\n",
    "        lims=(5780.40-margin, 6005.40+margin),\n",
    "    )\n",
    "    utils.plot_inset(\n",
    "        ax,\n",
    "        species_slc=slice(5,10),\n",
    "        box_lims=[0.38, 0.65, 0.2, 0.2],\n",
    "        lims=(7657-margin, 7707+margin),\n",
    "    )\n",
    "    utils.plot_inset(\n",
    "        ax,\n",
    "        species_slc=slice(10,15),\n",
    "        box_lims=[0.78, 0.15, 0.2, 0.2],\n",
    "        lims=(8089-margin, 8289+margin),\n",
    "    )\n",
    "\n",
    "title = \"tspec\"\n",
    "if binsize == \"species\":\n",
    "    title = \"tspec_species\"\n",
    "    # Plot inset for species fig\n",
    "    # [x0, y0, width, height] relative to lower left corner\n",
    "    # Shortcut to zoom in on last instrument\n",
    "    #axins.set_xlim(p.get_xlim())\n",
    "    #axins.set_ylim(p.get_ylim())\n",
    "    #plot_model(axins, model, model_kwargs=model_kwargs, fill_kwargs=fill_kwargs)\n",
    "    \n",
    "\n",
    "# # Forward model\n",
    "# wav_fm, flux_fm = np.genfromtxt(\n",
    "#     \"Projects/HATP23b/forward_modeling/HAT-P-23_DR2_best_fit_model.txt\",\n",
    "#     unpack=True,\n",
    "# )\n",
    "# ax.plot(wav_fm*1e4, flux_fm*1e6)\n",
    "\n",
    "    \n",
    "# Overplot literature tspec\n",
    "# tspec_lit = pd.read_csv(\"./Projects/HATP26b/data_detrending/tspec_stevenson.txt\")\n",
    "# ax.errorbar(\n",
    "#     tspec_lit[\"wav_cen\"],\n",
    "#     tspec_lit[\"depth\"],\n",
    "#     yerr=tspec_lit[\"depth_unc\"],\n",
    "#     fmt='o',\n",
    "#     label=\"Stevenson et al. (2016)\",\n",
    "# )\n",
    "ax.legend(loc=1, ncol=6, frameon=True, fontsize=11)\n",
    "#ax.set_title(\"ACCESS Magellan/IMACS Transit Spectra of HAT-P-23\")\n",
    "#ax.set_xlim(3_000, 10_000)\n",
    "ax.set_ylim(9_500, 16_500)\n",
    "#ax.set_xlim(5106.55, 9362.45)\n",
    "ax.set_ylim(9_000, 17_000)\n",
    "ax.set_xlabel('Wavelength (Ã…)')\n",
    "ax.set_ylabel(r'Transit Depth (ppm)')\n",
    "#fig.set_size_inches(FIG_WIDE)\n",
    "fig.tight_layout()\n",
    "#utils.savefig(f'projects/HATP23b/paper/figures/tspec/{title}.pdf')\n",
    "#utils.savepng('/home/mango/Projects/HATP26b/journal/figures/tspec')\n",
    "#utils.savepng(\n",
    "#    \"/home/mango/ACCESS_notebook/Projects/HATP26b/journal/figures/tspec_wakeford\"\n",
    "#)\n",
    "#plt.savefig(\"/home/mango/Desktop/tspec_stevenson_jitter.jpg\", dpi=50, bbox_inches=\"tight\")\n",
    "\n",
    "print(\"mean WLC depth:\", mean_wlc_depth, mean_wlc_depth_unc)\n",
    "Rs = 0.96 * u.solRad\n",
    "Rp = np.sqrt(mean_wlc_depth*1e-6 * Rs**2)\n",
    "Mp = 1.35 * u.jupiterMass\n",
    "gp = c.G * Mp  /Rp**2\n",
    "print(\"Rs (Rsun):\", Rs.to(\"Rsun\"))\n",
    "print(\"Rp (Rj):\", Rp.to(\"Rjupiter\"))\n",
    "print(\"gp (m/s^2):\", gp.to(\"m/s^2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transit, table in tspec_tables.items():\n",
    "    mi = min(table[['Depthup (ppm)', 'DepthDown (ppm)']].min(axis=0)),\n",
    "    ma = max(table[['Depthup (ppm)', 'DepthDown (ppm)']].max(axis=0)),\n",
    "    print(transit, mi, ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspec_table.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max = np.array([tspec_combined_max, tspec_combined_unc_max]).T\n",
    "df_combined_max = pd.DataFrame(data_max, columns=[\"Combined Max\", \"Unc Max\"])\n",
    "def write_latex(row):\n",
    "    v, v_unc = row\n",
    "    return f'{v:.5f} \\pm {v_unc:.5f}'\n",
    "#df_combined.apply(write_latex, axis=1)\n",
    "df_combined_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    '#Wlow':df_wavs['Wav_d'],\n",
    "    'Wup':df_wavs['Wav_u'],\n",
    "    'Depth':df_combined['Combined'],\n",
    "    'ErrUp':df_combined['Unc'],\n",
    "    'ErrLow':df_combined['Unc'],\n",
    "    'Instrument':'Magellan/IMACS',\n",
    "    'Offset?':'NO',\n",
    "}\n",
    "df_retrieval = pd.DataFrame(data)\n",
    "df_retrieval.to_csv(\n",
    "    'projects/HATP23b/data/retrieval/tspec_hp23_c.csv',\n",
    "    index=False,\n",
    ")\n",
    "df_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_fm, flux_fm = np.genfromtxt(\n",
    "    \"Projects/HATP23b/forward_modeling/HAT-P-23_DR2_best_fit_model.txt\",\n",
    "    unpack=True,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "\n",
    "ax.axhline(mean_wlc_depth,color=\"darkgrey\", zorder=0, ls='--')\n",
    "ax.plot(\n",
    "    wav_fm*1e4,\n",
    "    flux_fm*1e6,\n",
    "    c=\"C5\",\n",
    "    label=\"local cond. T=2500, g=20, Z=+1.0 C/O=0.25, Haze=0001 Cloud=0.00\",\n",
    ")\n",
    "ax.errorbar(\n",
    "    wav,\n",
    "    tspec_combined,\n",
    "    yerr=tspec_combined_unc,\n",
    "    c='w',\n",
    "    mec='k',\n",
    "    fmt='o',\n",
    "    zorder=10,\n",
    "    label=\"combined transmission spectrum\",\n",
    "    ecolor='k',\n",
    "    lw=4,\n",
    ")\n",
    "\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_xlim(3_000, 10_000)\n",
    "ax.set_ylim(12_000, 14_500)\n",
    "ax.set_xlabel(\"Wavelength (Ã…)\")\n",
    "ax.set_ylabel(r\"Transit Depth (ppm)\")\n",
    "\n",
    "utils.savefig(f\"Projects/HATP23b/paper/figures/tspec/tspec_fm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Projects/HATP23b/data_detrending/out_c/HATP23b'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"xo/HATP23/ut180603/wlc\"\n",
    "lc = np.load(f\"{dirpath}/lc.npy\")\n",
    "map_soln = utils.pkl_load(f\"{dirpath}/map_soln.pkl\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "ax.plot(map_soln[\"light_curve\"] + 1.0020465216919012, label=\"MAP\")\n",
    "ax.plot(lc[:, 1], '.', label=dirpath)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"xo/HATP23/ut180603/wlc_bak/lc.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"xo/HATP23/ut180603/wlc_bak\"\n",
    "fig, axes = utils.plot_exoplanet_WLC(dirpath, figsize=FIG_LARGE)\n",
    "#fig.suptitle(dirpath)\n",
    "#plt.savefig(\"/Users/mango/Desktop/HATP23_ut180603.png\", dpi=250, bbox_inches=\"tight\")\n",
    "#plt.savefig(\"/Users/mango/Desktop/w43_ut180603_xo_wlc.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"xo/HATP23/ut1806\"\n",
    "fig, axes, df_samples = utils.plot_corner(\n",
    "    dirpath=dirpath,\n",
    "    title=\"\"\" \"truth\" values from Sada & RamÃ³n-Fox (2016) \"\"\",\n",
    "    #title=\"\"\" \"truth\" values from Weaver et al. (2020) \"\"\",\n",
    ")\n",
    "\n",
    "#xlims = np.array([[ax.get_xlim() for ax in ax_row] for ax_row in axes])\n",
    "#ylims = np.array([[ax.get_ylim() for ax in ax_row] for ax_row in axes])\n",
    "\n",
    "\"\"\"\n",
    "for ax_row, xlim_row, ylim_row in zip(axes, xlims, ylims):\n",
    "    for ax, xlim, ylim in zip(ax_row, xlim_row, ylim_row):\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "\"\"\"\n",
    "        \n",
    "#plt.savefig(f\"{dirpath}/corner.png\", dpi=250, bbox_inches=\"tight\")\n",
    "#plt.savefig(f\"/Users/mango/Desktop/corner_hp23_ut180603.png\", dpi=250, bbox_inches=\"tight\")\n",
    "plt.savefig(f\"/Users/mango/Desktop/hp23_ut180603_xo_wlc_corner.png\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"xo/WASP43/ut180603/wl_bak/trace.pkl\"\n",
    "trace = utils.pkl_load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_traces = [trace[\"trace\"][i]['r'] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = sorted(glob.glob(\"xo/WASP43/ut180603/binned_free_rho_star/wbin_*/detrended.csv\"))\n",
    "columns = {\"flux\", \"lc_model\"}\n",
    "DT_list = [dt.fread(fpath, columns=columns) for fpath in fpaths]\n",
    "phase = dt.fread(fpaths[0], columns={\"phase\"}).to_numpy()\n",
    "fluxes = dt.cbind(*[DT[\"flux\"] for DT in DT_list]).to_numpy()\n",
    "models = dt.cbind(*[DT[\"lc_model\"] for DT in DT_list]).to_numpy()\n",
    "resids = fluxes - models + 1.\n",
    "#df_list = [DT.to_pandas() for DT in DT_list]\n",
    "#fluxes = dt.cbind(*DT_list).to_numpy()\n",
    "#models = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_tepspec = \"data/data_reductions/WASP43/ut180603_a9_24_noflat_LBR/LCs_w43_kreidberg.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(11, 11), sharex=True, sharey=True)\n",
    "ax_left, ax_right = axes\n",
    "N_bins = fluxes.shape[1]\n",
    "wbins = utils.pkl_load(fpath_tepspec)[\"wbins\"]\n",
    "wbins = np.array(wbins)\n",
    "idxs_used = phase\n",
    "\n",
    "# Plot binned light curves\n",
    "p_left = utils.plot_binned(\n",
    "        ax_left,\n",
    "        idxs_used,\n",
    "        fluxes,\n",
    "        utc=False,\n",
    "        bins=wbins, \n",
    "        offset=0.01,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0},\n",
    "        models=models,\n",
    "    )\n",
    "p_left.set_title(\"detrended flux - exoplanet\")\n",
    "\n",
    "# TODO: Try detrending with `exoplanet`\n",
    "# Plot residuals\n",
    "p_right = utils.plot_binned(\n",
    "        ax_right,\n",
    "        idxs_used,\n",
    "        resids,\n",
    "        utc=False,\n",
    "        bins=wbins, \n",
    "        offset=0.01,\n",
    "        colors=np.array(sns.color_palette(\"Spectral_r\", N_bins)),\n",
    "        plot_kwargs={\"marker\":'.', \"mew\":0, \"lw\":0},\n",
    "        annotate=True,\n",
    "        annotate_kwargs={\"fontsize\":10, \"ha\":\"center\"},\n",
    "    )\n",
    "p_right.set_title(\"Residuals\")\n",
    "\n",
    "ax_left.set_ylabel(\"Normalized flux + offset\")\n",
    "fig.text(0.5, 0, 'Time (JD)', ha='left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\"/Users/mango/Desktop/binned_xo.png\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmission spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = sorted(glob.glob(\"xo/WASP43/ut180603/binned_free_rho_star/wbin_*/summary.csv\"))\n",
    "columns = slice(0, 3) #{\"C0\", \"mean\", \"sd\"}\n",
    "DT_list = [dt.fread(fpath, columns=columns)[dt.f[\"C0\"] == \"r\", :][:, [\"mean\",\"sd\"]] for fpath in fpaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspec = dt.rbind(*DT_list).to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "ax.errorbar(range(len(df[\"Rp/Rs\"])), df[\"Rp/Rs\"], yerr=df[\"Rp/RsErrUp\"], fmt='o',\n",
    "            label=\"GPTS (square_exp)\", color='b', alpha=0.5)\n",
    "ax.errorbar(range(len(tspec[:, 0])), tspec[:, 0], yerr=tspec[:, 1], fmt='o',\n",
    "            label=\"exoplanet-quick (matern)\", color='C1', alpha=0.5)\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_ylabel(r\"$R_p/R_s$\")\n",
    "ax.grid(axis=\"x\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"/Users/mango/Desktop/tspec.png\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\"flux\", \"lc_model\"}\n",
    "DT_list = [dt.fread(fpath, columns=columns) for fpath in fpaths]\n",
    "phase = dt.fread(fpaths[0], columns={\"phase\"}).to_numpy()\n",
    "fluxes = dt.cbind(*[DT[\"flux\"] for DT in DT_list]).to_numpy()\n",
    "models = dt.cbind(*[DT[\"lc_model\"] for DT in DT_list]).to_numpy()\n",
    "resids = fluxes - models + 1.\n",
    "#df_list = [DT.to_pandas() for DT in DT_list]\n",
    "#fluxes = dt.cbind(*DT_list).to_numpy()\n",
    "#models = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(1e-6*12_945 * 1.152**2) * 9.731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common directory\n",
    "dirpath = \"projects/HATP23b/data\"\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"generic_local_001_056_0001_000.dat\":\"normal scattering, clear\",\n",
    "    \"generic_local_001_056_0001_001.dat\":\"normal scattering, cloudy\",\n",
    "    \"generic_local_001_056_1100_000.dat\":\"enhanced scattering, clear\",\n",
    "    \"generic_local_001_056_1100_001.dat\":\"enhanced scattering, cloudy\",\n",
    "    \"hatp23b_solar_noTiOVO.dat\":\"cold (no TiO/VO)\",\n",
    "    \"generic_detr.dat\":\"detr\",\n",
    "}\n",
    "\n",
    "# Plot models\n",
    "fig, ax = plt.subplots(figsize=FIG_WIDE)\n",
    "for model, l in models.items():\n",
    "    fpath = f\"{dirpath}/forward_model/{model}\"\n",
    "    wav_model, flux_model = np.loadtxt(fpath, unpack=True)\n",
    "    ax.plot(wav_model*1e4, flux_model*1e6, label=l)\n",
    "\n",
    "# Load data\n",
    "data = \"tspec/tspec_combined.dat\"\n",
    "fpath = f\"{dirpath}/{data}\"\n",
    "wav_data, flux_data, flux_data_err = np.loadtxt(fpath, unpack=True)\n",
    "\n",
    "# Plot data\n",
    "ax.plot(wav_data, flux_data, 'o')\n",
    "ax.errorbar(\n",
    "    wav_data*1e4,\n",
    "    flux_data*1e6,\n",
    "    yerr=flux_data_err*1e6,\n",
    "    c='w',\n",
    "    mec='k',\n",
    "    fmt='o',\n",
    "    zorder=10,\n",
    "    label=\"this study\",\n",
    "    ecolor='k',\n",
    "    lw=2,\n",
    ")\n",
    "\n",
    "ax.legend(fontsize=12, ncol=3)\n",
    "ax.set_xlim(5106.55, 9362.45)\n",
    "ax.set_ylim(9_000, 17_000)\n",
    "ax.set_xlabel(\"Wavelength (Ã…)\")\n",
    "ax.set_ylabel(\"Transit depth (ppm)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exoretrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme('paper')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "########\n",
    "# Models\n",
    "########\n",
    "dirpath = \"data/retrievals/HATP23_wider\"\n",
    "model_key_name = \"Na+K+TiO (haze)\"\n",
    "models = {\n",
    "    \"K (clear)\":f\"{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_NoHaze_fitR0_K\",\n",
    "    f\"{model_key_name}\":f\"{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_Haze_fitR0_Na_K_TiO\",\n",
    "}\n",
    "\n",
    "instruments = {\n",
    "    'Magellan_IMACS': {\n",
    "        'c': 'w', 'mec':'k', 'fmt': 'o', \n",
    "        'ecolor':'k', \n",
    "        #'lw':4,\n",
    "        'label': 'Magellan/IMACS',\n",
    "        'zorder':10,\n",
    "    },\n",
    "}\n",
    "colors = [\"grey\", \"C5\"]\n",
    "for i, (model_name, model_path) in enumerate(models.items()):\n",
    "    # Plot model\n",
    "    model = ascii.read(f'{model_path}/retr_model.txt')\n",
    "    model_kwargs = {'label':model_name, \"alpha\":1}\n",
    "    fill_kwargs = {'alpha':0.125, \"color\":colors[i]}\n",
    "    _, p = utils.plot_model(\n",
    "        ax, model, model_kwargs=model_kwargs, fill_kwargs=fill_kwargs,\n",
    "    )\n",
    "    \n",
    "    # Plot sampled points\n",
    "    for instrument in instruments.keys():\n",
    "        instr_sampled = ascii.read(f'{model_path}/retr_model_sampled_{instrument}.txt')\n",
    "        sampled_kwargs = {'marker':'s', 'color':p[0].get_color(), 'lw':0, \"alpha\":1}\n",
    "        utils.plot_instrument(\n",
    "            ax, instr_sampled=instr_sampled, sampled_kwargs=sampled_kwargs,\n",
    "        )\n",
    "\n",
    "#############\n",
    "# Instruments\n",
    "#############\n",
    "# Dict of instr_kwargs\n",
    "instruments = {\n",
    "    'Magellan_IMACS': {\n",
    "        'c': 'w', 'mec':'k', 'fmt': 'o', \n",
    "        'ecolor':'k', \n",
    "        #'lw':4,\n",
    "        'label': 'Magellan/IMACS',\n",
    "        'zorder':10,\n",
    "    },\n",
    "}\n",
    "model_path = models['K (clear)'] # Instrument sampling identical for all models\n",
    "for instrument, instr_kwargs in instruments.items():\n",
    "    instr = ascii.read(f'{model_path}/retr_{instrument}.txt')\n",
    "    instrument_name = instrument.replace('_', '/')\n",
    "    utils.plot_instrument(\n",
    "        ax, instr, sampled=False, instr_kwargs=instr_kwargs,\n",
    "    )\n",
    "    \n",
    "####################\n",
    "# Annotate Delta lnZ\n",
    "####################\n",
    "fpath = f'{models[model_key_name]}/retrieval.pkl'\n",
    "fpath_flat = f'{models[\"K (clear)\"]}/retrieval.pkl'\n",
    "DlnZ, DlnZ_unc, lnZ, lnZ_unc = utils.get_Delta_lnZ(fpath, fpath_flat)\n",
    "s = f\"$\\Delta \\ln(Z) = {DlnZ:.2f} \\pm {DlnZ_unc:.2f}$\"\n",
    "ax.annotate(s, (0.02, 0.05), xycoords='axes fraction')\n",
    "\n",
    "\"\"\"\n",
    "# Plot inset\n",
    "axins = ax.inset_axes([0.5, 0.5, 0.5, 0.5])\n",
    "# Shortcut to zoom in on last instrument\n",
    "p = plot_instrument(axins, instr, instr_sampled, instr_kwargs=configs, sampled_kwargs=sampled_kwargs)\n",
    "axins.set_xlim(p.get_xlim())\n",
    "axins.set_ylim(p.get_ylim())\n",
    "plot_model(axins, model, model_kwargs=model_kwargs, fill_kwargs=fill_kwargs)\n",
    "ax.indicate_inset_zoom(axins, alpha=1.0, edgecolor='w')\n",
    "\"\"\"\n",
    "\n",
    "ax.set_xlim(0.5, 0.95)\n",
    "#ax.set_ylim(25000, 27000)\n",
    "ax.set_ylim(11_000, 16_000)\n",
    "\n",
    "ax.set_xlabel(r'Wavelength $(\\mu\\mathrm{m})$')\n",
    "ax.set_ylabel('Transit depth (ppm)')\n",
    "ax.legend(loc=1, ncol=3)\n",
    "\n",
    "#########\n",
    "# Species\n",
    "#########\n",
    "species = {\n",
    "    'Na I-D':5892.9, \n",
    "    #'HÎ±':6564.6, \n",
    "    'K I_avg':7682.0, \n",
    "    'Na I-8200_avg':8189.0\n",
    "}\n",
    "[ax.axvline(wav/10000, lw=0.5, ls='--', color='grey', zorder=0) for name, wav in species.items()]\n",
    "\n",
    "#ax.annotate(f\"Python 2\", (0.05, 0.9), xycoords='axes fraction')\n",
    "\n",
    "#plt.savefig('/Users/mango/Desktop/exoretrievals_py2.png', dpi=250, bbox_inches='tight')\n",
    "\n",
    "fig.set_size_inches(FIG_WIDE)\n",
    "#fig.tight_layout()\n",
    "#utils.savefig('projects/HATP23b/paper/figures/retrievals/retrieval.pdf')\n",
    "plt.savefig(f'/Users/mango/Desktop/tspec_haze_mid.pdf', bbox_inches='tight')\n",
    "#plt.savefig(f'../retrieval/kreidberg/{species}/tspec/retr_{basename}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "p = ax.fill_between([1,2,3,4,5], [5,5,5,5,5], [1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.get_facecolor()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath.split('E1_')[-1].split('FitP0')[0] + dirpath.split('/')[-1].split('R0_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "def test(x, y, **kwargs): \n",
    "    return x + y\n",
    "    \n",
    "plt.plot([1,2,3], **{})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirpath = 'data/retrievals/HATP23'\n",
    "species = [\"Na\", \"K\", \"TiO\", \"Na_K\", \"Na_TiO\", \"K_TiO\", \"Na_K_TiO\"]\n",
    "\n",
    "data_dict = {\n",
    "    sp:{\n",
    "        'clear':f'{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_NoHaze_fitR0_{sp}',\n",
    "        'haze':f'{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_Haze_fitR0_{sp}',\n",
    "        'spot':f'{dirpath}/HATP23_E1_Het_FitP0_NoClouds_NoHaze_fitR0_{sp}',\n",
    "        'spot+haze':f'{dirpath}/HATP23_E1_Het_FitP0_NoClouds_Haze_fitR0_{sp}',\n",
    "    }\n",
    "    for sp in species\n",
    "}\n",
    "\n",
    "#dirpath_flat = f'{dirpath}/HATP23_E1_NoHet_FlatLine'\n",
    "dirpath_flat = f'{dirpath}/HATP23_E1_NoHet_FitP0_NoClouds_NoHaze_fitR0_K'\n",
    "fpath_flat = f'{dirpath_flat}/retrieval.pkl'\n",
    "data = {}\n",
    "for species, model_info in data_dict.items():\n",
    "    data[species] = {}\n",
    "    for model, dirpath in model_info.items():\n",
    "        fpath = f'{dirpath}/retrieval.pkl'\n",
    "        Delta_lnZ, Delta_lnZ_unc, lnZ, lnZ_unc = utils.get_Delta_lnZ(\n",
    "            fpath, fpath_flat\n",
    "        )\n",
    "        data[species][model] = utils.write_latex2(\n",
    "            Delta_lnZ, Delta_lnZ_unc)\n",
    "#         data[species][model] = (lnZ, lnZ_unc)\n",
    "\n",
    "df_retr = pd.DataFrame(data)\n",
    "df_retr#.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retr.min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_theme(\"paper\")\n",
    "fpath = 'data/retrievals/HATP23/HATP23_E1_Het_FitP0_NoClouds_NoHaze_fitR0_Na_K_TiO/retrieval.pkl'\n",
    "post = utils.pkl_load(fpath)\n",
    "\n",
    "df = pd.DataFrame(post['samples']) \n",
    "\n",
    "params = {\n",
    "    'logP0':r'$\\log P_0$',\n",
    "    'T':r'$T_\\mathrm{p}$',\n",
    "#     'logH2O':r'$\\log \\mathrm{H}_2\\mathrm{O}$',\n",
    "    'logNa':r'$\\log \\mathrm{Na}$',\n",
    "    'logK':r'$\\log \\mathrm{K}$',\n",
    "    'logTiO':r'$\\log \\mathrm{TiO}$',\n",
    "    'f':r'$f$',\n",
    "}\n",
    "\n",
    "if \"_Haze\" in fpath:\n",
    "    params['loga'] = r'$\\log a$'\n",
    "    params['gamma'] = r'$\\gamma_\\mathrm{haze}$'\n",
    "\n",
    "if \"_Het\" in fpath:\n",
    "    params['Tocc'] = r'$T_\\mathrm{star}$'\n",
    "    params['Thet'] = r'$T_\\mathrm{het}$'\n",
    "    params['Fhet'] = r'$f_\\mathrm{het}$'\n",
    "\n",
    "df_params = df[params.keys()]\n",
    "\n",
    "corner_kwargs = {\n",
    "    'show_titles':True,\n",
    "}\n",
    "hist_kwargs = {'histtype':'stepfilled', 'lw':2, 'density':True,}\n",
    "fig, axes = utils.plot_corner(\n",
    "    df_params,\n",
    "    params=params,\n",
    "    c=f'C5',\n",
    "    corner_kwargs=corner_kwargs,\n",
    "    hist_kwargs=hist_kwargs,\n",
    ")\n",
    "\n",
    "fig.set_size_inches(18, 18)\n",
    "\n",
    "utils.savefig('projects/HATP23b/paper/figures/retrievals/retrieval_corner.pdf')\n",
    "#plt.savefig(f'../retrieval/kreidberg/{species}/corner/corner_{basename}.pdf', bbox_inches='tight')\n",
    "#plt.savefig(f'/Users/mango/Desktop/corner_{source}_all.pdf', bbox_inches='tight')\n",
    "#plt.savefig(f\"/Users/mango/Desktop/corner_test.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHIMERA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmisson Spectrum File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, h = fits.getdata(fpath, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puts transmission into format that can be read by CHIMERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../WASP43/retrieval/kreidberg/GP_kr_noffsH.dat\"\n",
    "df_exoretrievals = pd.read_csv(fpath, sep='\\s+')\n",
    "df_exoretrievals.rename({\"#Wlow\":\"Wlow\"}, axis=1, inplace=True)\n",
    "\n",
    "# create CHIMERA datatable\n",
    "df_CHIMERA = pd.DataFrame()\n",
    "\n",
    "# add mid-wavelength column\n",
    "wav_low_AA, wav_up_AA = df_exoretrievals[[\"Wlow\", \"Wup\"]].T.values\n",
    "df_CHIMERA[\"wl [um]\"] = (wav_low_AA + wav_up_AA)/2 * 1e-4\n",
    "df_CHIMERA[\"wl [um]\"] = df_CHIMERA[\"wl [um]\"].apply(lambda x: f\"{x:.18e}\")\n",
    "\n",
    "# add (Rp/Rstar)^2\n",
    "depth = df_exoretrievals[\"Depth\"]\n",
    "df_CHIMERA[\"(Rp/Rstar)^2\"] = depth*1e-6\n",
    "df_CHIMERA[\"(Rp/Rstar)^2\"] = df_CHIMERA[\"(Rp/Rstar)^2\"].apply(lambda x: f\"{x:.18e}\")\n",
    "\n",
    "\n",
    "# add (Rp/Rstar)^2 err\n",
    "errup_ppm, errlow_ppm = df_exoretrievals[[\"ErrUp\", \"ErrLow\"]].T.values\n",
    "err_ppm = (errlow_ppm + errlow_ppm)/2\n",
    "df_CHIMERA[\"(Rp/Rstar)^2 err\"] = err_ppm * 1e-6\n",
    "df_CHIMERA[\"(Rp/Rstar)^2 err\"] = df_CHIMERA[\"(Rp/Rstar)^2 err\"].apply(lambda x: f\"{x:.18e}\")\n",
    "\n",
    "# write to txt file\n",
    "fpath = \"/Users/mango/Desktop/w43b_trans.txt\"\n",
    "\n",
    "with open(fpath, 'w') as file:\n",
    "    header = \"#Weaver et al. 2019\\n#wl [um]\\t\\t\\t(Rp/Rstar)^2\\t\\t(Rp/Rstar)^2 err\\n\"\n",
    "    file.write(header)\n",
    "    df_CHIMERA.to_csv(file, sep=\" \", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpath = \"../data/WASP43/test/spectral_samples_trans_pmn_wfc3_cc.pic\"\n",
    "fpath = \"../data/WASP43/test/pmn_transmission_wfc3_cc.pic\"\n",
    "data = utils.pkl_load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:, 0])"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "884px",
    "width": "296px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "623px",
    "left": "176px",
    "top": "133px",
    "width": "165px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
